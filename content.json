{"pages":[{"title":"关于我","text":"非典型 喜欢热血的动漫, 但是貌似二次元的世界不是那么懂 喜欢玩游戏(LOL), 天生手残, 玩啥都很菜.在青铜白银无限循环 喜欢听歌, 但是歌名都记不住 口算心算完全是硬伤, 不知道我理科是怎么过来的 英语GG就算了, 连普通话都是NRL不分 有时候情绪总是不稳定, 会焦虑, 会急躁, 会愤怒 可是我会去感受自己所享受的一切 家里虽然很穷, 但是至少全家都健康安康 有一个很好的女票(手动滑稽脸) 有一群很好的基友 运到的人感觉都还都不错, 相处都很开心. 总觉得自己就是咸鱼一条, 不知道未来会怎么样? 但是我一直相信自己未来不会太差, 哈哈! 感谢 Hexo Icarus主题 Gitee","link":"/blog/about/index.html"}],"posts":[{"title":"docker基础","text":"本文主要有docker入门，docker-compose，Dockerfile等知识 docker推荐Gitbooks感谢2 常用命令仓库12345docker pull #从远程仓库拉取镜像到本地docker push #推送本地镜像到远程仓库docker search #在仓库搜索镜像docker login #登录到官方仓库Docker Hubdocker logout #退出登录 镜像12345678910111213docker build #从Dockerfile构建镜像docker pull #从远程仓库拉取镜像到本地docker push #推送本地镜像到远程仓库docker history #显示镜像的历史信息docker images #列出镜像docker rmi #删除镜像docker tag [id] [名字:tag名] #给镜像打上tag标签docker run #创建容器并启动容器docker create #创建容器docker commit #将修改后的容器生成镜像docker load #从压缩包中加载镜像docker import #从归档文件中创建镜像docker save #将镜像保存到压缩文件 容器1234567891011121314151617181920212223docker attach #依附到一个正在运行的容器中docker exec #进到正在运行的容器中执行命令docker cp #在容器和本地系统间复制文件docker update #将一个容器内所有的进程从暂停状态中恢复docker ps #列出主机中的容器docker port #查找一个nat到私有网口的公共口docker top #查看一个容器中正在运行的进程信息docker logs #查看日志文件docker diff #检查容器内文件系统的修改docker status #输出容器的资源使用统计信息docker wait #阻塞直到容器终止docker start #启动已创建的容器docker pause #暂停运行中的容器docker unpause #使暂停的容器恢复运行docker stop #停止容器运行docker rename #容器改名docker restart #容器重启docker kill #关闭运行中的容器docker rm #删除容器docker export #导出容器内容为tar包docker run #创建容器并启动容器docker create #创建容器docker commit #将修改后的容器生成镜像 其他1234docker events #从服务端获取实时的事件docker info #查看系统相关信息docker inspect #显示Docker对象的具体配置信息，包括容器，镜像，网络等docker version #输出Docker的版本信息 管理1234567891011docker container #容器管理docker image #镜像管理docker network #网络管理docker node #节点管理docker plugin #插件管理docker secret #管理敏感数据及普通服务配置项docker service #服务管理docker stack #栈管理docker swarm #集群管理docker system #管理系统信息docker volume #卷管理 交互式运行ctrl+p之后ctrl+q 退出之后就是还在后台运行docker attach id 进入后台运行的容器 docker run -d centos bash 也是后台运行 容器日志docker logs -f -t –tail 容器名-f –follows=true|false,默认false-t –timestamps=true|false,默认false–tail=”all” 返回所有日志–tail 10 只显示最新的10条 run参数 -a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt; -P: 映射所有端口 -p: 端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； –name=”nginx-lb”: 为容器指定一个名称； –dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致； –dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致； -h “mars”: 指定容器的hostname； -e username=”ritchie”: 设置环境变量； –env-file=[]: 从指定文件读入环境变量； –cpuset=”0-2” or –cpuset=”0,1,2”: 绑定容器到指定CPU运行； -m :设置容器使用内存最大值； –net=”bridge”: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； –link=[]: 添加链接到另一个容器； –expose=[]: 开放一个端口或一组端口； Dockerfile执行cd到Dockerfile目录下docker build -t [镜像名] . 栗子 123456789101112131415161718FROM openjdk:8-jre-alpineMAINTAINER xx@gmail.comENV TZ=Asia/ShanghaiENV JAVA_OPTS=&quot;-Xms128m -Xmx256m -Djava.security.egd=file:/dev/./urandom&quot;RUN ln -sf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezoneRUN mkdir -p /pisces-gatewayWORKDIR /pisces-gatewayEXPOSE 9999ADD ./target/pisces-gateway.jar ./CMD sleep 120;java $JAVA_OPTS -jar pisces-gateway.jar FROM: 基础镜像FROM openjdk:8-jre-alpine MAINTAINER: 维护者信息(废用)MAINTAINER xx@gmail.com LABEL: 维护者信息LABEL authors=&quot;hjr&quot; ENV: 设置环境变量$来使用 ARG: 设置环境变量，但是只要容器构建过一次，环境变量就会失效 WORKDIR: 指定工作目录，不存在会自动创建WORKDIR /app COPY: 拷贝文件到镜像中COPY package.json /usr/src/app/ ADD: 和COPY一样，但是会自动解压tar VOLUME: 设置匿名卷VOLUME /data $ docker run -d -v mydata:/data xxxx EXPOSE: 声明容器端口，不会映射。需要映射必须docker run -p USER: 略 HEALTHCHECK: 略 ONBUILD: 略 SHELL指令 RUN: 用来执行命令行命令并且构建镜像，如果前面存在cmd会将其覆盖 CMD：启动容器后会默认执行的命令，只能存在一个。这个是默认的，如果run启动时指定了或者ENTRYPOINT就会覆盖CMD ENTRYPOINT：如果前面使用了CMD，那么CMD的内容会作为参数传递给ENTRYPOINT docker-compose build : 可以基于Dockerfile来构建每个docker, 这里就是指定Dockerfile的路径 123build: context: ./mysql # 在当前目录下的mysql文件夹内 dockerfile: Dockerfile-alternate # 指定dockerfile文件 image : 指定image container_name : 容器名称 depends_on : 用于指定服务依赖，一般是mysql、redis等。 指定了依赖，将会优先于服务创建并启动依赖 restart : always 表示如果服务启动不成功会一直尝试 ports : 用于暴露端口 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; extra_hosts : 添加主机名的标签，就是往/etc/hosts文件中添加一些记录 12extra_hosts: - &quot;bigbing:127.0.0.1&quot; volumes : 挂载目录 123volumes: - /var/lib/mysql - cache/:/tmp/cache expose : 提供container之间的端口访问，不会暴露给主机使用 links : 用于链接另一容器服务，如需要使用到另一容器的mysql服务。可以给出服务名和别名；也可以仅给出服务名，这样别名将和服务名相同。 1234links: - db - db:mysql - redis env_file : 从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 指定了模板文件，则 env_file 中路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则以后者为准。 12345env_file: .envenv_file:- ./common.env- ./apps/web.env- /opt/secrets.env environment : 添加环境变量 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET command : mvn clean spring-boot:run -Dspring-boot.run.profiles=docker: 表示以这个命令来启动项目 由于默认的bridge桥接网络，重启容器后会改变ip地址。在一些场景下我们希望固定容器IP地址。 gateway : 网关地址 subnet : 网络号段 extnetwork : 自定义的网络名称 看一波示例docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657version: '2'services: nginx: image: nginx:1.13.12 container_name: nginx restart: always networks: extnetwork: ports: - 80:80 volumes: - '/nginx/conf.d:/etc/nginx/conf.d' nginx2: image: nginx:1.13.12 container_name: nginx2 restart: always networks: extnetwork: ipv4_address: 172.19.0.2 db: image: mysql:5.7 container_name: db volumes: - /var/lib/mysql:/var/lib/mysql restart: always networks: extnetwork: ports: - 3306:3306 environment: MYSQL_ROOT_PASSWORD: wordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: image: wordpress:latest container_name: wordpress depends_on: - db ports: - &quot;8000:80&quot; restart: always networks: extnetwork: environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_NAME: wordpress WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpressnetworks: extnetwork: ipam: config: - subnet: 172.19.0.0/16 gateway: 172.19.0.1 启动关闭命令 1234$ docker-compose help # docker-compose 命令帮助$ docker-compose up # 创建并启动 docker 编排服务$ docker-compose down # 停止并移除 docker 编排服务 (更改配置文件时建议使用)$ docker-compose exec javaweb-compose bash # ssh 登入 java 容器 参考 : 使用docker-compose定制Javaweb环境:tomcat、jre、mysql、activemq、redis, 不知道可以多看看这个练手 纯洁的微笑 - Spring Boot 2 (五)：Docker Compose + Spring Boot + Nginx + Mysql 实践 忽略下载镜像可以去https://hub.docker.com/上面找 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162docker pull centosdocker images# 一个是 -i：交互式操作，一个是 -t 终端, 这里我们希望有个交互式 Shell，因此用的是 bash(等于/bin/bash)# 7583是images的id, 也可以用名字docker run -d --name centos --privileged=true -v /Users/hjr/docker/centos:/data --net=host centos /usr/sbin/initdocker exec -it centos /bin/bash# 进入centos之后安装service命令yum install initscripts# mysqldocker pull mysqldocker run -d --name mysql -v D:\\docker\\mysql:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root mysqldocker exec -it mysql bashmysql -u root -pmysql&gt; ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'root';mysql&gt; flush privileges;# redis#redis-server --appendonly yes : 在容器执行redis-server启动命令，并打开redis持久化配置docker run --name redis -p 6379:6379 -v D:\\docker\\redis:/data -d redis redis-server --appendonly yes# rabbitmq 这里我们下载包含management的tag镜像docker pull rabbitmq:3-managementdocker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq d69# zookeeperdocker run -d --name zookeeper2181 -it -p 2181:2181 -p 2888:2888 -p 3888:3888 zookeeper- 2181 端口号时 zookeeper client 端口- 2888端口号是zookeeper服务之间通信的端口- 3888端口是zookeeper与其他应用程序通信的端口docker run -it --rm --link zookeeper2181:zookeeper zookeeper zkCli.sh -server zookeeper# 启动一个 zookeeper 镜像, 并运行这个镜像内的 zkCli.sh 命令, 命令参数是 &quot;-server zookeeper&quot;# 将我们先前启动的名为 zookeeper2181 的容器连接(link) 到我们新建的这个容器上, 并将其主机名命名为 zookeeper# 当我们执行了这个命令后, 就可以像正常使用 ZK 命令行客户端一样操作 ZK 服务了.# elasticsearchdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.4.2 //我也不知道为什么直接拉去laster无效docker run -p --name elasticsearch 9200:9200 -p 9300:9300 -e “discovery.type=single-node” docker.elastic.co/elasticsearch/elasticsearch:7.4.2//运行http://127.0.0.1:9200/ 看看是不是成功docker exec -it elasticsearch /bin/bash //安装插件cd binls plugin install mobz/elasticsearch-head//运行http://127.0.0.1:9200/_plugin/head/ 看看插件是否安装成功//ik分词器docker exec -it elasticsearch /bin/bashcd plugins/yum -y install wgetwget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.4.2/elasticsearch-analysis-ik-7.4.2.zipunzip elasticsearch-analysis-ik-67.4.2.zip//Kibana安装docker pull docker.elastic.co/kibana/kibana:7.4.2docker run -it -d -e ELASTICSEARCH_URL=http://自己的IP:9200 --name kibana -p 5601:5601 docker.elastic.co/kibana/kibana:7.4.2","link":"/blog/2019/03/01/docker-1.%E5%AD%A6%E4%B9%A0/"},{"title":"Elasticsearch-入门","text":"来源于阅读Elasticsearch: 权威指南基于版本Elasticsearch 2.x Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎.基于Lucene库来实现的. 使用JSON作为文档存储格式.它被用作全文检索、结构化搜索、分析以及这三个功能的组合. 简单搜索和原理 结构化搜索 到 控制相关度 使用分析器和查询来处理人类语言 聚合（aggregations Elasticsearch 支持的两种地理位置检索方式 Elasticsearch关联关系处理 到 扩容设计 监控 到 部署后 将讨论生产环境上线的重要配置、监控点 安装当你准备在生产环境安装 Elasticsearch 时，你可以在 官网下载地址 找 到 Debian 或者 RPM 包，除此之外，你也可以使用官方支持的 Puppet module 或者 Chef cookbook 12cd elasticsearch-&lt;version&gt;./bin/elasticsearch 如果你想把 Elasticsearch 作为一个守护进程在后台运行，那么可以在后面添加参数 -d windows如果你是在 Windows 上面运行 Elasticseach，你应该运行 bin\\elasticsearch.bat 而不是 bin\\elasticsearch 测试是否成功http://localhost:9200 安装ik中文分词器: https://github.com/medcl/elasticsearch-analysis-ik/releases/, 解压重命名ik, 放到plugins目录下 下载kibana对应的版本, 下载解压放到elasticsearch-7.3.2目录下(只是为了方便寻找), 运行elasticsearch-7.3.2\\kibana-7.3.2-windows-x86_64\\bin\\kibana.bat, 打开http://localhost:5601运行报错重启一下es 跑起来了可以初试一下, 在Kibana中的Dev Tools里面 123456789DELETE /*GET /*GET /_analyze{ &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我要做你爸爸&quot;} 基本概念123456789101112131415{ &quot;_index&quot; : &quot;megacorp&quot;, //索引 = 库 &quot;_type&quot; : &quot;employee&quot;, //文档 = 表 &quot;_id&quot; : &quot;1&quot;, //主键, 文档唯一标识 &quot;_version&quot; : 1, //版本号 &quot;found&quot; : true, //已经被找到 &quot;_score&quot; : 1.4508328, //相关度评分 &quot;_source&quot; : { //字段, 注意: 字段名可以是任何合法字符串, 但是不能包含英文句号. &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ] }} _index(索引): 只是一个命名空间, 实际索引和查询都是在分片上的, 但是我们应用只用关系索引就好了. 索引名必须小写, 不能以下划线开头, 不能包含逗号 _type(类型): 可能有不同的字段，但最好能够非常相似. 命名可以大写或者小写, 但是不能以下划线或者句号开头, 不应该包含逗号, 并且长度限制为256个字符. _id(唯一索引): PUT的时候可以手动指定, 不指定自动生成 增删改增删改全部version会+1 PUT如果数据不存在, 就新增; 存在就更新. 12345678910111213141516171819202122232425PUT /megacorp/employee/1 { &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]}PUT /megacorp/employee/2{ &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]}PUT /megacorp/employee/3{ &quot;first_name&quot; : &quot;Douglas&quot;, &quot;last_name&quot; : &quot;Fir&quot;, &quot;age&quot; : 35, &quot;about&quot;: &quot;I like to build cabinets&quot;, &quot;interests&quot;: [ &quot;forestry&quot; ]} POST如果PUT时候数据不存在是更新全部的数据进去, 不会只更新相应字段.如果要更新相应的字段要用POST,_id没有找到报错 存在的字段就更新, 不存在的字段就新增字段 1234POST /megacorp/employee/3/_update{ &quot;doc&quot;:{&quot;age&quot;: 36, &quot;about&quot;: &quot;I like to build cabinets, haha&quot;}} DELETE不会立即将文档从磁盘中删除, 只是标记成删除状态.随着你不断的索引更多的数据, Elasticsearch 将会在后台清理标记为已删除的文档 1DELETE megacorp/employee/1 并发问题更新很容易出现并发问题, 比如库存更新, 两个同时更新-1, 就可能导致只有一个更新成功. 悲观处理就是每一个POST操作都锁住,乐观处理就是用_version字段 比如: 只有文档version=1的时候才会更新成功, 否则更新失败 12345PUT /website/blog/1?version=1 { &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Starting to get the hang of this...&quot;} 我们也可以用外部的version控制, 外部版本号不仅在索引和删除请求是可以指定, 而且在创建新文档时也可以指定 12345PUT /website/blog/2?version=5&amp;version_type=external{ &quot;title&quot;: &quot;My first external blog entry&quot;, &quot;text&quot;: &quot;Starting to get the hang of this...&quot;} 查询1234567891011121314151617181920GET _cat/indices?v //查询有多少个索引GET /megacorp/employee/_search //查询全部GET /_search?size=5&amp;from=10 //分页GET /megacorp/employee/_search?q=last_name:Smith&amp;q=first_name:Jane//只能支持一个条件,match里面只能单个条件GET /megacorp/employee/_search { &quot;query&quot; : { &quot;match&quot; : {&quot;last_name&quot; : &quot;Smith&quot;} }}//可以多个字段执行相同查询GET /megacorp/employee/_search { &quot;multi_match&quot;: { &quot;query&quot;: &quot;full text search&quot;, &quot;fields&quot;: [ &quot;title&quot;, &quot;body&quot; ] }} /_search 在所有的索引中搜索所有的类型 /gb/_search 在 gb 索引中搜索所有的类型 /gb,us/_search 在 gb 和 us 索引中搜索所有的文档 /g*,u*/_search 在任何以 g 或者 u 开头的索引中搜索所有的类型 /gb/user/_search 在 gb 索引中搜索 user 类型 /gb,us/user,tweet/_search 在 gb 和 us 索引中搜索 user 和 tweet 类型 /_all/user,tweet/_search 在所有的索引中搜索 user 和 tweet 类型 bool查询布尔查询是一种联合查询，可以对多个查询条件进行组合 must 查询的结果必须匹配查询条件，并计算score filter 查询的结果必须匹配查询条件，和must不同不会计算score. 不想影响评分的全部用这个 should 查询结果必须符合查询条件中的一个或多个 must_not 查询结果必须不符合查询条件 1234567891011121314151617181920212223242526272829303132333435363738//一个查询GET /megacorp/employee/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: {&quot;match&quot;:{&quot;last_name&quot; : &quot;smith&quot; }} } }}GET /megacorp/employee/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;match&quot;:{&quot;last_name&quot; : &quot;smith&quot; }}, {&quot;match&quot;:{&quot;first_name&quot; : &quot;John&quot; }}, {&quot;range&quot;: {&quot;age&quot;: {&quot;gte&quot;: 25,&quot;lte&quot;: 25}}} ] } }}//这个查询不会计算filter的相关度, 只会计算must的相关度GET /megacorp/employee/_search{ &quot;query&quot; : { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot; : {&quot;last_name&quot; : &quot;smith&quot; } }, &quot;filter&quot;: { &quot;range&quot; : { &quot;age&quot; : { &quot;gt&quot; : 30 } } } } }} match_all 查询简单的匹配所有文档 match 查询是你可用的标准查询, 时间数字就是精确查询, string就是全文查询 multi_match 查询可以在多个字段上执行相同的 match 查询 range 查询找出那些落在指定区间内的数字或者时间 term 查询被用于精确值匹配 terms 查询和 term 查询一样, 但它允许你指定多值进行匹配. 如果这个字段包含了指定值中的任何一个值, 那么这个文档满足条件 exists 查询和 missing 查询被用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档. 这与SQL中的 IS_NULL (missing) 和 NOT IS_NULL (exists) 在本质上具有共性 More 显示指定字段1234567GET /megacorp/employee/_search{ &quot;query&quot;: { &quot;match_all&quot; : {} }, &quot;_source&quot;:[&quot;interests&quot;]} 排序+分页排序: 只能数字和日期分页: 从第0条开始查询,每页2条 注意: 不要深度分页.比如分页显示0-10的数据, 有主副分片总共10个, 那么会每个分片都去查询0-10的记录,再把所有的10 * 10的数据全部返回到协调节点, 协调节点排序后去0-10条之后返回给客户端.所以深度分页很消耗性能.在分布式系统中, 对结果排序的成本随分页的深度成指数上升. 这就是 web 搜索引擎对任何查询都不要返回超过1000个结果的原因 1234567891011GET /megacorp/employee/_search{ &quot;query&quot; : { &quot;match_all&quot; : {} }, &quot;sort&quot;:{ &quot;age&quot;: &quot;desc&quot; }, &quot;from&quot;: 0, &quot;size&quot;: 2} 全文搜索全文搜索会先分割, 再去匹配单词, 所以单词中间多几个空格还是可以搜索到 12345678910111213141516171819//这里会获取到三个记录, 前两个因为都有to rock任意一个单词. //排序 + 分页GET /megacorp/employee/_search { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;match&quot;:{&quot;about&quot; : &quot;to rock&quot; }} ] } }, &quot;sort&quot;:{ &quot;age&quot;: &quot;desc&quot; }, &quot;from&quot;: 0, &quot;size&quot;: 2} 短语搜索只能查询到rock和albums紧挨着的数据 12345678GET /megacorp/employee/_search{ &quot;query&quot; : { &quot;match_phrase&quot; : { &quot;about&quot; : &quot;rock albums&quot; } }} 高亮搜索很多应用喜欢从每个搜索结果中**高亮(highlight)**匹配到的关键字，这样用户可以知道为什么这些文档和查询相匹配。在Elasticsearch中高亮片段是非常容易的。 让我们在之前的语句上增加highlight参数： pre_tags 前缀标签post_tags 后缀标签fields 高亮字段 123456789101112131415GET /megacorp/employee/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;about&quot;: &quot;like to&quot; } }, &quot;highlight&quot;:{ &quot;pre_tags&quot;: &quot;&lt;b style='color:red'&gt;&quot;, &quot;post_tags&quot;: &quot;&lt;/b&gt;&quot;, &quot;fields&quot;: { &quot;about&quot;: {} } }} 批量处理123456789101112131415GET /_mget{ &quot;docs&quot;:[ { &quot;_index&quot;:&quot;megacorp&quot;, &quot;_type&quot;:&quot;employee&quot;, &quot;_id&quot;:4 }, { &quot;_index&quot;:&quot;megacorp&quot;, &quot;_type&quot;:&quot;employee&quot;, &quot;_id&quot;:2 } ]} 索引类型都一致 1234GET /megacorp/employee/_mget{ &quot;ids&quot; : [ &quot;4&quot;, &quot;2&quot; ]} More TODO 倒排索引Elasticsearch使用一种称为倒排索引的结构, 它适用于快速的全文搜索. 倒排索引是首先将每个文档的content域拆分成单独的词(我们称它为词条或tokens), 创建一个包含所有不重复词条的排序列表, 然后列出每个词条出现在哪个文档. Term Doc1 Doc2I Y Nlike N NMoney Y Y 分析器倒排索引可以很好的全文索引, 但是只能精确索引. 比如i Like 就搜索不到了, 因为大小写不对. 这时候就会需要分析了 分析主要三个步骤: 字符过滤器 字符串按顺序通过每个字符过滤器. 他们的任务是在分词前整理字符串. 一个字符过滤器可以用来去掉HTML, 或者将 &amp; 转化成 and 分词器 字符串被分词器分为单个的词条. 一个简单的分词器遇到空格和标点的时候, 可能会将文本拆分成词条 Token过滤器 词条按顺序通过每个token过滤器. 这个过程可能会改变词条(大小写转化), 删除词条(例如像 a, and, the 等无用词), 或者增加词条(例如像 jump 和 leap 这种同义词) 全文搜索会调用对应的分词器, 精确查找就不会 12345GET /megacorp/_analyze{ &quot;field&quot;: &quot;about&quot;, &quot;text&quot;: &quot;Black-cats&quot; } 映射7.x版本之后映射的单位是以索引为单位, 一个索引一个映射.6.x是强制以索引为单位, 可以修改配置5.x映射是以类型为单位的, 所以很容易导致冲突 1GET /megacorp/_mapping 聚合aggs 使用聚合函数all_interests 使用的别名terms 聚合函数功能 最后，我们还有一个需求需要完成：允许管理者在职员目录中进行一些分析。 Elasticsearch有一个功能叫做**聚合(aggregations)**，它允许你在数据上生成复杂的分析统计。它很像SQL中的GROUP BY但是功能更强大。 举个例子，让我们找到所有职员中最大的共同点（兴趣爱好）是什么： 12345678GET /megacorp/employee/_search{ &quot;aggs&quot;: { &quot;all_interests&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;interests&quot; } } }} 没有优化的字段es默认是禁止聚合/排序操作的 未完TODO","link":"/blog/2018/02/10/elasticsearch-1.%E5%85%A5%E9%97%A8/"},{"title":"harbor搭建","text":"私有镜像仓库harbor安装。 harbor企业级: 支持基于角色的访问控制 RBAC 支持镜像复制策略（PUSH） 支持无用镜像数据的自动回收和删除 支持 LDAP/AD 认证 Web UI 提供审计日志功能 提供 RESTful API，便于扩展 支持中文 &amp; 部署 Easy 搭建需要安装docker和docker-compose https://www.cnblogs.com/a735882640/p/13755428.html 123456789101112131415161718# 移除以前版本dockerrpm -qa | grep docker# 删除显示的软件 yum remove **# 安装dockeryum updateyum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum install docker-cedocker versionsystemctl start dockersystemctl enable dockerdocker run hello-world# 安装docker-composecurl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composedocker-compose --version 安装 Harbor 下载 Habor 离线安装包并解压： 12$ wget https://github.com/goharbor/harbor/releases/download/v2.2.1/harbor-offline-installer-v2.2.1.tgz$ tar -xvf harbor-offline-installer-v1.10.1.tgz -C /opt/ 配置host 12vi /etc/hosts192.168.100.132 registry.jingrui.com 生成ssl 1234567git clone https://github.com/Fishdrowned/ssl.git #将项目下载到本地/gen.cert.sh registry.jingrui.com #生成registry.jingrui.com域名的证书cd out/mkdir -p /data/cert创建证书存放目录mv root.crt /data/cert/server.cert #将证书放到Harbor配置目录下mv root.key.pem /data/cert/server.key #将秘钥放到Harbor配置目录下ll /data/cert #查看目录内容 打开 /opt/harbor/harbor.yml 文件，修改 hostname 域名、https 证书（不用直接注释）等配置信息，具体如下： 1234567891011hostname: registry.jingrui.comhttp: # port for http, default is 80. If https enabled, this port will redirect to https port port: 80# https related confighttps: # https port for harbor, default is 443 port: 443 # The path of cert and key files for nginx certificate: /data/cert/server.cert private_key: /data/cert/server.key 接着执行如下命令进行安装： 12./prepare #重新配置Harbor./install.sh #重新执行Harbor安装，注：此处可能有更好的方式重启 以上安装命令同时安装了 Clair 服务，一个用户镜像漏洞静态分析的工具。如果不需要，可以省略该选项。 安装成功后，可以通过 docker login 命令来测试仓库的连通性，看到如下字样即表示安装成功（也可以通过浏览器访问 Web UI）： 12345$ docker login 192.168.100.132Username: adminPassword: Harbor12345Login Succeeded 或者直接浏览器http://registry.jingrui.com 至此，私有镜像仓库 Harbor 安装完毕。 试一试 Harbor 在 Harbor 中，镜像均以项目的形式组织。我们在页面上创建一个名为 foo 的测试项目，然后将从 Docker Hub 上拉取的 busybox 镜像推送到自己的仓库中： 12docker tag redis:5.0.7 registry.jingrui.com/library/redis:5.0.7docker push registry.jingrui.com/library/redis:5.0.7 这里我使用registry.jingrui.com不行，要使用127.0.0.1才行，应该是https的问题。那这个先不管了吧，正式环境会用真实https证书 感谢：https://www.cnblogs.com/ling-yu-amen/p/11176438.html","link":"/blog/2019/03/02/docker-2.%E6%90%AD%E5%BB%BAharbor/"},{"title":"Elasticsearch-集群","text":"ElasticSearch 的主旨是随时可用和按需扩容, 虽然可以使用更强大的硬件设备垂直扩容.但是ElastiSearch天生就是分布式的, 可以直接添加更多的节点来实现水平扩容. 集群是由一个或者多个拥有相同cluster.name配置的节点组成, 它们共同承担数据和负载的压力.用户可以发送请求到任何节点, 每个节点都可以知道所需文档在哪一个节点上面. 集群搭建集群搭建7.X 修改elasticsearch.yml 12345cluster.name: my-applicationnode.name: node-1 //node-2 node-3network.host: 0.0.0.0http.port: 9200 //9201 9202cluster.initial_master_nodes: [&quot;node-1&quot;, &quot;node-2&quot;, &quot;node-3&quot;] 可以配置上 12node.master: true //是否可以选举成masternode.data: true //是否可以存储数据 原理路由为什么每一个节点都知道分片在哪一个节点上呢?因为分配在哪一个节点和主分片数目有关, 所以主分片数目不能变化. 修改了主分片数目, 路由就找不到了 分片计算公式shard = hash(routing) % number_of_primary_shards routing 默认是_id number_of_primary_shards 主分片数目 水平扩展变化 拥有三个主分片的单节点 node1: Master -&gt; P0 P1 P2 新增一个节点(三个主节点一份副节点) node1: Master -&gt; P0 P1 P2 node2: -&gt; R0 R1 R2这时候就算down了一个主机也可以正常运行 新增一个节点(三个主节点一份副节点) node1: Master -&gt; P1 P2 node2: -&gt; R0 R1 node3: -&gt; P0 R2现在三个主一份副这种设置最多可以支持六个节点, 每个节点一个分片 现在修改副分片设置为2份 node1: Master -&gt; R0 P1 P2 node2: -&gt; R0 R1 R2 node3: -&gt; P0 R1 R2这样就可以down两个节点的情况下可以正常运行 关闭了一个主节点 node2: Master -&gt; R0 R1 P2 node3: -&gt; P0 P1 R2先是失去了node1, 之后选举新主节点node2.在我们关闭 Node1 的同时也失去了主分片1和2, 这时候健康状态为red.之后将node2,node3对应的副分片提升为主分片, 这是健康状态为yellow. 更新文档数据先发送至某一个节点(协调节点, 建议轮询请求每个节点), 节点会根据路由算出在该数据主节点哪一个节点上, 发送到目标节点.目标节点更新文档数据成功之后, 并行转发每个副节点, 所有副节点报告成功之后, 目标节点向协调节点报告成功.安全更新 这个规则可以修改.详情看配置 - 一致性配置 配置集群健康GET _cluster/health查看集群健康, status 字段指示着当前集群在总体上是否工作正常 1234567891011121314151617{ &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;status&quot; : &quot;yellow&quot;, &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 1, &quot;number_of_data_nodes&quot; : 1, &quot;active_primary_shards&quot; : 2, &quot;active_shards&quot; : 2, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 2, &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 0, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 0, &quot;active_shards_percent_as_number&quot; : 50.0} green: 所有的主分片和副本分片都正常运行 yellow: 所有的主分片都正常运行，但不是所有的副本分片都正常运行 red: 有主分片没有正常运行 分片数设置新增索引默认会分配5个主分片, 我们可以手动配置成5个主分片和一份副分片(5个副分片) 1234567PUT /blogs{ &quot;settings&quot; : { &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 }} 索引建立的时候主分片就确定了, 主分片不能改动, 副分片可以随时改变 1234PUT /blogs/_settings{ &quot;number_of_replicas&quot; : 2} 一致性配置consistency一致性 原理 - 更新文档数据 中: 主节点成功后需要返回 one 主分片成功后直接响应成功, 不用等待副分片响应状态 all 主分片成功后需要等待副分片也响应成功, 才算成功 quorum(默认) 大多数成功才算成功, 公式int( (primary + number_of_replicas) / 2 ) + 1, number_of_replicas表示配置中副分片的数目而不是实际活跃的副分片数目","link":"/blog/2018/02/11/elasticsearch-2.%E9%9B%86%E7%BE%A4/"},{"title":"mongodb入门","text":"MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。 优点 High performance, 对数据库高并发读写的需求 Huge Storage, 对海量数据的高效率存储和访问的需求 High Scalability &amp;&amp; High Availability, 对数据库的高可扩展性和高可用性的需求 非常合适: 不需要事务和复杂join支持 新应用, 需求会变, 数据模型无法确定 需要2k-3k以上读写QPS 需要TB甚至PB级别存储 需要快速水平扩展 需要99.999%高可用 需要大量地理位置查询, 文本查询 支持的数据结构非常松散，是一种类似于JSON的格式叫BSON(Binary-JSON) MongoDB的最小存储单位就是文档(document)对象, 文档(document)对象对应于关系型数据库的行. 数据库介绍mysql和mongodb对应: database: database table: collection集合 row: document文档 column: field域 index: index索引 不支持join查询 每个文档自动生成_id主键 支持数据类型: 字符串: {“x” : “foobar”} 主键id(12字节唯一ID): {“X” :ObjectId() } 布尔值: {“x” : true} 数组: {“x” : [1,2,3]} 32为整数和64位整数不支持, 自动转为64浮点数 64位浮点数: {“x”：3.14159，”y”：3} null undefined 正则表达式: {“x” ： /foobar/i} 代码(实现类似存储过程功能): {“x” ： function() {}} 使用整数可以这样: {“x”:NumberInt(“3”)}{“x”:NumberLong(“3”)} 关闭强制关闭 12345678ps -ef |grep mongokill -2 pid//如果数据损坏, 需要修复//1. 删除lock文件rm -f /mongodb/single/data/db/*.lock//2. 修复数据/usr/local/mongodb/bin/mongod --repair --dbpath=/mongodb/single/data/db 标准关闭 12345mongo --port 27017 //#切换到admin库 use admin //关闭服务 db.shutdownServer() 命令数据库操作数据库命名规范: 不能是空字符串（””) 不得含有’ ‘（空格)、.、$、/、\\和\\0 (空字符) 应全部小写 最多64字节 admin: 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库, 这个用户自动继承所有数据库的权限. 一些特定的服务器端命令也只能从这个数据库运行, 比如列出所有的数据库或者关闭服务器 local: 这个数据永远不会被复制, 可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时, config数据库在内部使用, 用于保存分片的相关信息 123456789101112131415//选择和创建数据库//如果不存在就创建, 注意这里创建只会在内存中创建, 要有了一个文档之后才会持久化到磁盘中use articledb//这时候并看不到articledb数据库, 应该没有持久化show dbs/show databases//显示当前使用的数据库, 这时候是articledbdb//如果没有选择数据库, 默认保存到test中//删除当前数据库db.dropDatabase() 集合操作集合的命名规范: 集合名不能是空字符串”” 集合名不能含有\\0字符(空字符), 这个字符表示集合名的结尾 集合名不能以”system.”开头, 这是为系统集合保留的前缀 用户创建的集合名字不能含有保留字符, 有些驱动程序的确支持在集合名里面包含, 这是因为某些系统生成的集合中包含该字符. 除非你要访问这种系统创建的集合, 否则千万不要在名字里出现$ 12345678//显示创建db.createCollection(&quot;person&quot;)//查看show collections / show tables//删除, person为集合名db.person.drop() 文档操作注意: 键值对是有序的 区分大小写 不能有重复的键 文档规范: 键不能含有\\0(空字符), 这个字符用来表示键的结尾 .和$有特别的意义, 只有在特定环境下才能使用 以下划线_开头的键是保留的(不是严格要求的) 插入1234567db.collection.insert( &lt;document or array of documents&gt;, { writeConcern: &lt;document&gt;, ordered: &lt;boolean&gt; }) 12345678910111213//插入//person集合不存在会隐式创建db.person.insert({&quot;name&quot;:&quot;hjr&quot;, &quot;age&quot;:NumberInt(18), &quot;isMan&quot;: true, &quot;money&quot;: null, &quot;create_time&quot;: new Date()})//批量插入db.person.insertMany([{&quot;name&quot;:&quot;张三&quot;, &quot;age&quot;:NumberInt(19), &quot;isMan&quot;: true, &quot;money&quot;: null, &quot;create_time&quot;: new Date()},{&quot;name&quot;:&quot;小红&quot;, &quot;age&quot;:NumberInt(20), &quot;isMan&quot;: false, &quot;money&quot;: null, &quot;create_time&quot;: new Date()}])//排序db.person.find().sort({name:1}) 批量插入还可以用for, 因为mongo的shell是一个JavaScript的shell 1for(var i=0;i&lt;10;i++){db.person.insert({&quot;name&quot; : &quot;帅哥&quot;+i})} 查找db.collection.find(&lt;query&gt;, [projection]) 123456789101112131415//查询所有&gt; db.person.find(){ &quot;_id&quot; : ObjectId(&quot;60114a96e485c39756757d25&quot;), &quot;name&quot; : &quot;hjr&quot;, &quot;age&quot; : 18, &quot;isMan&quot; : true, &quot;money&quot; : null, &quot;create_time&quot; : ISODate(&quot;2021-01-27T11:12:22.332Z&quot;) }{ &quot;_id&quot; : ObjectId(&quot;60114beee485c39756757d26&quot;), &quot;name&quot; : &quot;张三&quot;, &quot;age&quot; : 19, &quot;isMan&quot; : true, &quot;money&quot; : null, &quot;create_time&quot; : ISODate(&quot;2021-01-27T11:18:06.804Z&quot;) }{ &quot;_id&quot; : ObjectId(&quot;60114beee485c39756757d27&quot;), &quot;name&quot; : &quot;小红&quot;, &quot;age&quot; : 20, &quot;isMan&quot; : false, &quot;money&quot; : null, &quot;create_time&quot; : ISODate(&quot;2021-01-27T11:18:06.804Z&quot;) }//查找小红db.person.find({name:'小红'})//查找小红, 只显示age字段, 默认显示_id字段db.person.find({name:'小红'},{age:1}){ &quot;_id&quot; : ObjectId(&quot;60114beee485c39756757d27&quot;), &quot;age&quot; : 20 }//查找小红, 只显示age字段, 不显示_id字段db.person.find({name:'小红'},{age:1,_id:0}) 分页12345//查询个数db.collection.count(query, options)//limit默认20, skip表示前N个不要, 默认0db.collection.find().limit(NUMBER).skip(NUMBER) 排序12//排序1为升序, -1为降序db.person.find().sort({name:1, age:-1}) 执行优先级: sort &gt; skip &gt; limit 正则查询模糊查询是通过正则实现的 12345//模糊查询name为包含张三的db.person.find({name:/张三/})//模糊查询name为以张三开头的db.person.find({name:/^张三/}) 比较查询 $gt: 大于 $lt: 小于 $gte: 大于等于 $lte: 小于等于 $ne: 不等于 12//$gt 大于db.person.find({age:{$gt:NumberInt(19)}}) 包含查询 $in: 包含 $nin: 不包含 1db.person.find({age:{$in:[NumberInt(19), NumberInt(20)]}}) 条件连接查询$and:[ { },{ },{ } ] 1db.person.find({$and:[{age:NumberInt(19)}, {name:&quot;张三&quot;}]}) 更新12345678910111213db.collection.update(query, update, options) //或 db.collection.update( &lt;query&gt;, &lt;update&gt;, { upsert: &lt;boolean&gt;, //默认false, true表示没有匹配到文档自动创建插入 multi: &lt;boolean&gt;, //匹配到多个文件更新多个文档吗? 默认false, 匹配到多个只更新一个 writeConcern: &lt;document&gt;, collation: &lt;document&gt;, arrayFilters: [ &lt;filterdocument1&gt;, ... ], hint: &lt;document|string&gt; // Available starting in MongoDB 4.2 } ) 123456789101112131415//全局更新, 这时候小红的数据直接被替换掉了{ &quot;_id&quot; : ObjectId(&quot;60114beee485c39756757d27&quot;), &quot;age&quot; : 88 }db.person.update({name:&quot;小红&quot;}, {age:NumberInt(88)})//还原回去db.person.update({&quot;_id&quot; : ObjectId(&quot;60114beee485c39756757d27&quot;)}, { &quot;_id&quot; : ObjectId(&quot;60114beee485c39756757d27&quot;), &quot;name&quot; : &quot;小红&quot;, &quot;age&quot; : 20, &quot;isMan&quot; : false, &quot;money&quot; : null, &quot;create_time&quot; : ISODate(&quot;2021-01-27T11:18:06.804Z&quot;) })//局部更新db.person.update({name:&quot;小红&quot;}, {$set:{age:NumberInt(88)}})//批量修改, 所有男性改为帅哥, 比如只想修改一个就去掉{multi:true}db.person.update({isMan:true}, {$set:{name:&quot;帅哥&quot;}},{multi:true})//数值加一使用$incdb.person.update({name:&quot;小红&quot;}, {$inc:{age:NumberInt(1)}}) 删除db.集合名称.remove(条件) 1234db.person.remove({name:&quot;小红&quot;})//删除全部db.person.remove({}) 索引Mongodb使用的B-Tree, mysql使用B+Tree 区别: B+Tree所有关键字存储在叶子节点, 非叶子节点不存储真正的data, 但是B-Tree所有节点都保存data.B+Tree为所有叶子结点都添加一个链指针 索引类型 单字段索引: {age: 1}, 这里升序降序并不重要 复合索引: {name: -1, age: 1}, 这里先将索引name倒序, 再将age正序. 也符合最左原则 地理空间索引 文本索引 哈希索引 (具体查看)[http://www.javaboy.org/2019/0910/mongodb-index-types.html] 索引操作12//查看person集合索引db.person.getIndexes() 创建索引db.collection.createIndex(keys, options) 1234567&gt; db.person.createIndex({name: 1}) &quot;createdCollectionAutomatically&quot; : false, &quot;numIndexesBefore&quot; : 1, &quot;numIndexesAfter&quot; : 2, &quot;ok&quot; : 1} options: background: 默认false, 创建索引过程是否阻塞其他数据库操作 unique: 默认false, 是否唯一索引 name: 索引名称 sparse: 默认false, 对文档不存在的字段不启用索引, 如果为true就查询出不包含对应字段的文档 expireAfterSeconds: 指定一个以秒为单位的数值, 设置集合生存时间 v: 索引版本号 weights: 索引权重值(1~99999之间) default_language: 默认英语. 对于文本索引, 改参数决定了停词器及词干和词器的规则列表 language_override 移除索引 12&gt; db.person.dropIndex({name:1}){ &quot;nIndexesWas&quot; : 2, &quot;ok&quot; : 1 } 移除所有索引 1234567&gt; db.person.dropIndexes() &quot;nIndexesWas&quot; : 1, &quot;msg&quot; : &quot;non-_id indexes dropped for collection&quot;, &quot;ok&quot; : 1}//提示: _id 的字段的索引是无法删除的, 只能删除非_id 字段的索引 执行计划1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt; db.person.find({name:&quot;张三&quot;}).explain() &quot;queryPlanner&quot; : { &quot;plannerVersion&quot; : 1, &quot;namespace&quot; : &quot;hjr.person&quot;, &quot;indexFilterSet&quot; : false, &quot;parsedQuery&quot; : { &quot;name&quot; : { &quot;$eq&quot; : &quot;张三&quot; } }, &quot;queryHash&quot; : &quot;01AEE5EC&quot;, &quot;planCacheKey&quot; : &quot;4C5AEA2C&quot;, &quot;winningPlan&quot; : { &quot;stage&quot; : &quot;FETCH&quot;, &quot;inputStage&quot; : { &quot;stage&quot; : &quot;IXSCAN&quot;, &quot;keyPattern&quot; : { &quot;name&quot; : 1 }, &quot;indexName&quot; : &quot;name_1&quot;, &quot;isMultiKey&quot; : false, &quot;multiKeyPaths&quot; : { &quot;name&quot; : [ ] }, &quot;isUnique&quot; : false, &quot;isSparse&quot; : false, &quot;isPartial&quot; : false, &quot;indexVersion&quot; : 2, &quot;direction&quot; : &quot;forward&quot;, &quot;indexBounds&quot; : { &quot;name&quot; : [ &quot;[\\&quot;张三\\&quot;, \\&quot;张三\\&quot;]&quot; ] } } }, &quot;rejectedPlans&quot; : [ ] }, &quot;serverInfo&quot; : { &quot;host&quot; : &quot;v_jrhe-PC1&quot;, &quot;port&quot; : 27017, &quot;version&quot; : &quot;4.4.3&quot;, &quot;gitVersion&quot; : &quot;913d6b62acfbb344dde1b116f4161360acd8fd13&quot; }, &quot;ok&quot; : 1} stage: IXSCAN(索引扫描), COLLSCAN(全集合扫描) 涵盖查询就是现在只查询索引包括的字段, 就会非常快. 不需要查看文档内部 比如添加索引name, age之后, 查询显示的字段只有这两个. 链接(SpringBoot 集成 Spring Data Mongodb 操作 MongoDB 详解)[http://www.mydlq.club/article/85/#wow8] (MongoDB别人的笔记)[https://github.com/krislinzhao/StudyNotes/tree/master/MongoDB] (MongoDB 学习教程)[https://www.bookstack.cn/read/piaosanlang-mongodb/e1915c2525b12696.md]","link":"/blog/2020/05/02/mongodb-a1.%E5%85%A5%E9%97%A8/"},{"title":"mongodb集群和安全","text":"MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。 副本集(Replica Sets)MongoDB中的副本集是一组维护相同数据集的mongod服务。 副本集可提供冗余和高可用性, 是所有生产部署的基础. 副本集类似于有自动故障恢复功能的主从集群. 主节点(Primary): 一个有且仅有一个, 可读写数据 次要节点(Secondaries): 数据冗余备份节点, 可以读+选举 仲裁者(Arbiter): 不保留任何数据副本, 只有选举作用 如果副本集(主节点+次要节点)是偶数, 建议加一个仲裁者, 形成奇数容易形成大多数投票. 如果是奇数可以不加 环境搭建目的搭建: 一主一副本一仲裁 主节点 创建主节点目录 1mkdir -p /mongodb/replica_sets/myrs_27017/log \\ &amp; mkdir -p /mongodb/replica_sets/myrs_27017/data/db 新建配置文件 12345678910111213141516171819202122232425262728vim /mongodb/replica_sets/myrs_27017/mongod.confsystemLog: #MongoDB发送所有日志输出的目标指定为文件 destination: file #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 path: &quot;/mongodb/replica_sets/myrs_27017/log/mongod.log&quot; #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 logAppend: true storage: #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 dbPath: &quot;/mongodb/replica_sets/myrs_27017/data/db&quot; journal: #启用或禁用持久性日志以确保数据文件保持有效和可恢复 enabled: trueprocessManagement: #启用在后台运行mongos或mongod进程的守护进程模式。 fork: true #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID pidFilePath: &quot;/mongodb/replica_sets/myrs_27017/log/mongod.pid&quot; net: #服务实例绑定所有IP，有副作用，副本集初始化的时候，节点名字会自动设置为本地域名，而不是ip #bindIpAll: true #服务实例绑定的IP bindIp: localhost,192.168.0.2 #bindIp #绑定的端口 port: 27017 replication: #副本集的名称 replSetName: myrs 启动节点服务 1/usr/local/mongodb/bin/mongod -f /mongodb/replica_sets/myrs_27017/mongod.conf 创建副本节点, 同上重复1-3步, 将27017改为27018就好 创建仲裁节点, 同上重复1-3步, 将27017改为27019就好 初始化配置连接想定义的主节点, 这里27017 12345678910111213141516/usr/local/mongodb/bin/mongo --host=180.76.159.126 --port=27017//需要初始化之后才能使用&gt; rs.initiate() { &quot;info2&quot; : &quot;no configuration specified. Using a default configuration for the set&quot;, &quot;me&quot; : &quot;180.76.159.126:27017&quot;, &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1565760476, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1565760476, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } }myrs:SECONDARY&gt; myrs:PRIMARY&gt; “ok”的值为1, 说明创建成功 命令行提示符发生变化, 变成了一个从节点角色, 此时默认不能读写. 稍等片刻, 回车, 变成主节点. 此时主节点可读可写 查看副本集配置rs.conf(configuration), configuration: 可选, 如果没有配置, 则使用默认主节点配置. 查看副本集状态rs.status(), 目前只有一个, 因为从节点还没添加 添加从节点rs.add(host, arbiterOnly) host: 可以是字符串也可以是文档 123456789101112//配置文档{ _id: &lt;int&gt;, host: &lt;string&gt;, // required arbiterOnly: &lt;boolean&gt;, buildIndexes: &lt;boolean&gt;, hidden: &lt;boolean&gt;, priority: &lt;number&gt;, tags: &lt;document&gt;, slaveDelay: &lt;int&gt;, votes: &lt;number&gt; } arbiterOnly: 可选的, 仅在host值为字符串时适用. 如果为true, 则添加的主机是仲裁者 1myrs:PRIMARY&gt; rs.add(&quot;180.76.159.126:27018&quot;) 这时候从节点还是不能读数据, 需要在设置一下rs:SECONDARY&gt; rs.slaveOk() 添加仲裁者rs.addArb(host) 1myrs:PRIMARY&gt; rs.addArb(&quot;180.76.159.126:27019&quot;) 仲裁者也需要设置myrs:ARBITER&gt; rs.slaveOk(), 这里不放任何数据 12345678910myrs:ARBITER&gt; show dbs local 0.000GB myrs:ARBITER&gt; use local switched to db local myrs:ARBITER&gt; show collections replset.minvalid replset.oplogTruncateAfterPoint startup_log system.replset system.rollback.id 选举原则 主节点故障 主节点网络不可达(默认心跳信息为10秒) 人工干预(rs.stepDown(600)) 选举规则: 票数最高: 过半原则 票数相同: 数据新的获胜, 通过操作日志oplog对比 可以通过设置优先级(priority)来设置额外票数. 优先级即权重, 取值为0-1000, 相当于可额外增加0-1000的票数. 默认情况下, 优先级的值是1. 仲裁者是0 修改优先级, 稍等片刻会重新开始选举: 123myrs:SECONDARY&gt; cfg=rs.conf()myrs:SECONDARY&gt; cfg.members[1].priority=2myrs:SECONDARY&gt; rs.reconfig(cfg) 一主一副本一仲裁模式下故障: 从节点故障: 不会出发选举 主节点故障: 27019向27018投了一票, 27018本身自带一票, 因此共两票, 超过了”大多数”. 从变主 仲裁和主故障: 从节点依然是从节点, 因为他自身优先级一票, 没有超过2票大多数 仲裁和从故障: 10s后主节点自动降级为从节点, 副本集不可写数据 从节点故障之后不会出发选举, 重新启动从节点新数据会自动同步. 分片集群(Sharded Cluster)分片(sharding)是一种跨多台机器分布数据的方法, MongoDB使用分片来支持具有非常大的数据集和高吞吐量操作的部署. 将数据拆分分散存储在不同机器上. MongoDB分片群集包含以下组件: 分片(存储): 每个分片包含分片数据的子集. 每个分片都可以部署为副本集. mongos(路由): mongos充当查询路由器, 在客户端应用程序和分片集群之间提供接口 config servers(“调度”的配置): 配置服务器存储群集的元数据和配置设置. 从MongoDB 3.4开始, 必须将配置服务器部署为副本集(CSRS) 分片集群搭建目标: 两个分片节点副本集(3+3), 一个配置节点副本集(3), 两个路由节点(2), 共11个服务节点 副本集12345678910111213141516171819202122mkdir -p /mongodb/sharded_cluster/myshardrs01_27018/log \\ &amp; mkdir -p /mongodb/sharded_cluster/myshardrs01_27018/data/db \\ &amp; mkdir -p /mongodb/sharded_cluster/myshardrs01_27118/log \\ &amp; mkdir -p /mongodb/sharded_cluster/myshardrs01_27118/data/db \\ &amp; mkdir -p /mongodb/sharded_cluster/myshardrs01_27218/log \\ &amp; mkdir -p /mongodb/sharded_cluster/myshardrs01_27218/data/dbvim /mongodb/sharded_cluster/myshardrs01_27018/mongod.conf//和上面一主一副一仲裁类似, 副本集名称为myshardrs01, 角色shardsvr. 如果配置副本集是configsvrreplication: replSetName: myshardrs01 sharding: clusterRole: shardsvrps -ef |grep mongod//之后初始化和创建主节点, 添加从节点和仲裁节点, 和上文类似//第二套副本集只需改一下replSetName: myshardrs02 配置节点123456789101112131415161718192021222324252627282930313233343536373839404142mkdir -p /mongodb/sharded_cluster/myconfigrs_27019/log \\ &amp; mkdir -p /mongodb/sharded_cluster/myconfigrs_27019/data/db \\ &amp; mkdir -p /mongodb/sharded_cluster/myconfigrs_27119/log \\ &amp; mkdir -p /mongodb/sharded_cluster/myconfigrs_27119/data/db \\ &amp; mkdir -p /mongodb/sharded_cluster/myconfigrs_27219/log \\ &amp; mkdir -p /mongodb/sharded_cluster/myconfigrs_27219/data/dbvim /mongodb/sharded_cluster/myconfigrs_27019/mongod.confsystemLog: #MongoDB发送所有日志输出的目标指定为文件 destination: file #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径 path: &quot;/mongodb/sharded_cluster/myconfigrs_27019/log/mongod.log&quot; #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。 logAppend: true storage: #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。 dbPath: &quot;/mongodb/sharded_cluster/myconfigrs_27019/data/db&quot; journal: #启用或禁用持久性日志以确保数据文件保持有效和可恢复。 enabled: true processManagement: #启用在后台运行mongos或mongod进程的守护进程模式。 fork: true #指定用于保存mongos或mongod进程的进程ID的文件位置，其中mongos或mongod将写入其PID pidFilePath: &quot;/mongodb/sharded_cluster/myconfigrs_27019/log/mongod.pid&quot; net: #服务实例绑定所有IP #bindIpAll: true #服务实例绑定的IP bindIp: localhost,192.168.0.2 #绑定的端口 port: 27019 replication: replSetName: myconfigrs sharding: clusterRole: configsvr//一主两副本, 其他两个和上类似 路由节点12345678910111213141516171819202122232425mkdir -p /mongodb/sharded_cluster/mymongos_27017/logvi /mongodb/sharded_cluster/mymongos_27017/mongos.conf//不同之处sharding: #指定配置节点副本集 configDB: myconfigrs/180.76.159.126:27019,180.76.159.126:27119,180.76.159.126:27219//启动mongos/usr/local/mongodb/bin/mongos -f /mongodb/sharded_cluster/mymongos_27017/mongos.conf//登陆mongos, 这是不能写入数据, 因为只是连接了配置节点, 还没有连接分片数据节点/usr/local/mongodb/bin/mongo --host 180.76.159.126 --port 27017//连接分片节点mongos&gt; sh.addShard(&quot;myshardrs01/192.168.0.2:27018,180.76.159.126:27118,180.76.159.126:2 7218&quot;)mongos&gt; sh.addShard(&quot;myshardrs02/192.168.0.2:27318,180.76.159.126:27418,180.76.159.126:2 7518&quot;)//查看分片状态mongos&gt; sh.status()//如果添加分片失败，需要先手动移除分片，检查添加分片的信息的正确性后，再次添加分片use admin db.runCommand( { removeShard: &quot;myshardrs02&quot; } ) 开启分片功能, sh.enableSharding(&quot;库名&quot;) 1sh.enableSharding(&quot;person&quot;) 集合分片sh.shardCollection(namespace, key, unique) namespace: 要(分片)共享的目标集合的命名空间, 格式database.collection shardKey: 片键是每条记录都必须包含的, 且建立了索引的单个字段或复合字段 unique: 当值为true情况下, 片键字段上会限制为确保是唯一索引. 哈希策略片键不支持唯一索引. 默认是false 12345678910//显示集群的详细信息mongos&gt; db.printShardingStatus()//查看均衡器是否工作(需要重新均衡时系统才会自动启动,不用管它)mongos&gt; sh.isBalancerRunning() false//查看当前Balancer状态mongos&gt; sh.getBalancerState() true 再增加一个路由节点123456mkdir -p /mongodb/sharded_cluster/mymongos_27117/logvi /mongodb/sharded_cluster/mymongos_27117/mongos.confsharding: configDB: myconfigrs/180.76.159.126:27019,180.76.159.126:27119,180.76.159.126:27219 之后不需要在配置分片节点了, 就可以直接使用. 因为上一个的配置已经保存到配置节点中了 分片规则 哈希策略, mongos&gt; sh.shardCollection(&quot;articledb.comment&quot;,{&quot;nickname&quot;:&quot;hashed&quot;}) 范围策略, mongos&gt; sh.shardCollection(&quot;articledb.author&quot;,{&quot;age&quot;:1}) 性能对比: 范围分片方式提供了更高效的范围查询,给定一个片键的范围,分发路由可以很简单地确定哪个数据块存储了请求需要的数据,并将请求转发到相应的分片中. 不过分片会不均衡,如果片键所在的字段是线性增长的,一定时间内的所有请求都会落到某个固定的数据块中,最终导致分布在同一个分片中. 哈希分片方式以范围查询性能的损失为代价,保证了集群中数据的均衡.哈希值的随机性使数据随机分布在每个数据块中,因此也随机分布在不同分片中.但是也正由于随机性,一个范围查询很难确定应该请求哪些分片,通常为了返回需要的结果,需要请求所有分片. 如无特殊情况一般推荐使用Hash Sharding 而使用_id作为片键是一个不错的选择, 因为它是必有的, 你可以使用数据文档_id的哈希作为片键.这个方案能够是的读和写都能够平均分布,并且它能够保证每个文档都有不同的片键所以数据块能够很精细. 如果查看状态发现没有分片: 系统繁忙, 正在分片中 数据块(chunk)没有填满, 默认的数据块尺寸(chunksize)是64M, 填满后才会考虑向其他片的数据块填充数据. 为了测试,可以将其改小,这里改为1M 12use config db.settings.save( { _id:&quot;chunksize&quot;, value: 1 } ) 安全认证默认情况MongoDB启动运行是不会启动用户访问权限控制的.使用的是基于角色的访问控制(Role-Based Access Control,RBAC)来管理用户对实例的访问 开启访问控制方法: 在启动时指定参数--auth, 如/usr/local/mongodb/bin/mongod -f /mongodb/single/mongod.conf --auth 配置文件中添加 123security: #开启授权认证 authorization: enabled 角色: 可以显示指定也可以继承别的权限权限: 资源(数据库,集合,部分文档和集群)+操作(CURD) 权限操作Mongodb存储所有的用户信息在admin数据库的集合system.users中, 保存用户名/密码和数据库信息 查询12345678910111213141516171819202122// 查询所有角色权限(仅用户自定义角色) &gt; db.runCommand({ rolesInfo: 1 }) // 查询所有角色权限(包含内置角色) &gt; db.runCommand({ rolesInfo: 1, showBuiltinRoles: true })// 查询当前数据库中的某角色的权限 &gt; db.runCommand({ rolesInfo: &quot;&lt;rolename&gt;&quot; })// 查询其它数据库中指定的角色权限 &gt; db.runCommand({ rolesInfo: { role: &quot;&lt;rolename&gt;&quot;, db: &quot;&lt;database&gt;&quot; } }// 查询多个角色权限 &gt; db.runCommand( { rolesInfo: [ &quot;&lt;rolename&gt;&quot;, { role: &quot;&lt;rolename&gt;&quot;, db: &quot;&lt;database&gt;&quot;}, ... ] } ) 常用内置角色: 数据库用户角色: read, readWrite 所有数据库用户角色: readAnyDatabase, readWriteAnyDatabase,userAdminAnyDatabase, dbAdminAnyDatabase 数据库管理角色: dbAdmin, dbOwner, userAdmin 集群管理角色: clusterAdmin, clusterManager, clusterMonitor, hostManager 备份恢复角色: backup、restore 超级用户角色: root 内部角色: system 新建用户在操作用户时, 启动mongod服务时尽量不要开启授权 12345678910111213141516171819202122use admin//系统超级管理员myrootdb.createUser({user:&quot;myroot&quot;,pwd:&quot;123456&quot;,roles:[&quot;root&quot;]})//或者db.createUser({user:&quot;myroot&quot;,pwd:&quot;123456&quot;,roles:[ { &quot;role&quot; : &quot;root&quot;, &quot;db&quot; : &quot;admin&quot; } ]})//专门管理admin库账号myadmindb.createUser({user:&quot;myadmin&quot;,pwd:&quot;123456&quot;,roles: [{role:&quot;userAdminAnyDatabase&quot;,db:&quot;admin&quot;}]})//查看已经创建了的用户的情况db.system.users.find()//删除用户 db.dropUser(&quot;myadmin&quot;)//修改密码db.changeUserPassword(&quot;myroot&quot;, &quot;123456&quot;)//验证密码db.auth(&quot;myroot&quot;,&quot;123456&quot;) 如果不指定数据库，则创建的指定的权限的用户在所有的数据库上有效, 如{role: &quot;userAdminAnyDatabase&quot;, db:&quot;&quot;} 副本集/分片访问控制副本集和共享集群的各个节点成员之间使用内部身份验证, 可以使用密钥文件或x.509证书.密钥文件比较简单, 官方推荐如果是测试环境可以使用密钥文件,但是正式环境官方推荐x.509证书. 密钥文件的内容必须在6到1024个字符之间, 并且在unix/linux系统中文件所有者必须有对文件至少有读的权限. 略略略","link":"/blog/2020/05/03/mongodb-a2.%E9%9B%86%E7%BE%A4%E5%92%8C%E5%AE%89%E5%85%A8/"},{"title":"mysql-架构和规范","text":"简单介绍mysql架构和规范 架构Mysql各组件和组件功能 外层连接器(connectors) 系统关系和控制工具(Management Serveices &amp; Utilities): DBA操作 连接池(Connection Pool): 管理连接, 权限验证 sql接口(SQL Interface): 接收DML, DDL, 存储过程 解析器(Parser): 词法分析, 语法分析 查询优化器(Optimizer): 生成计划, 选择索引. 比如调整索引, 使用最优索引, 多表关联小结果集驱动大结果集 查询缓存(Caches &amp; Buffers): 以sql语句hash之后为缓存key, 查询结果为value, 8.0之后缓存不再使用 存储引擎(Pluggable Storage Engines): 提供接口, 存取数据 Mysql物理结构物理结构可以分为日志文件和数据索引文件 日志文件: 采用顺序IO方式存储, 只记录首地址, 后面的只记录一个偏移量. 记录速度快, 只能追加, 但是浪费空间, 不能回填 数据索引文件: 采用随机IO, 只记录地址值. 省空间, 但是速度慢 MySQL查询过程我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。 当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？ 客户端/服务端通信协议MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。 客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。 与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT * 以及加上LIMIT限制的原因之一 规范 数据库命名应该和项目名一致 数据库编码为utf8mb4, 真正的UTF-8是每个字符最多四个字节, 而MySQL的utf8只支持每个字符最多三个字节. 所以之前遇到一个问题就是微信或者qq昵称之类包含一些表情符号插入的时候就会报错. 注意: 一定要用utf8mb4 表设计表名 表名(全部小写)一般应该为业务_表名, 比如sys_user,upms_role, 通用的表可以tab_dictionary. 表名不以复数形式呈现 存储引擎MYISAM不支持外键, 不支持事务, 访问速度快. 支持全文索引, 表锁. 对于事务完整性没有要求的, 只以select和insert为主的选择这个引擎. 比如日志表等 InnoDB支持外键, 支持事务, 行锁, 不支持全文索引. 默认引擎 不要在事务中混合使用到两种引擎的表, 因为myisam不会回滚 字段 每个表必须要有主键ID, 建议类型为bigint unsigned. 如果特殊情况高并发情况下自增对效率影响比较大, 可以考虑通过程序计算出来的唯一值 主键ID和业务没有任何关系 是否字段的话统一为is_xxx, 类型unsigned tinyint, 一般0表示否, 1表示是. 比如is_deleted中, 1表示删除, 0表示不删除 字段不要太多, 单条记录不要超过8k. 文章之类的长内容需要单独存一张表 字段类型 确定整数的添加unsigned. 可以避免负数, 扩大表示范围. 可以用数字保存的就不用char或者varchar, 提升比对效率 固定长度的可以直接使用char, 比如32位salt之类的. varchar是可变长度, 长度最好不要超过5000, 他会使用一个字节来记录字符串长度. 金额可以使用long来保存分, 尽量不要使用bigdecimal, 因为占用空间太大了. 不能使用float和double, 因为计算会丢失精度. tinyint(2)表示未满两位用零填充, 长度还是-128~127 不建议使用enum,set类型, 使用tinyint代替 如果只记录年就用year类型. 如果只是单纯记录时间或者日期, 直接使用date或dateTime. 而timestamp用于可以根据时区不同来记录时间 尽量全部字段都为NOT NULL, 如果真的有NULL字段, 判断需要用IS NULL或IS NOT NULL 数据库配置1234567891011121314151617181920212223242526272829################### 公共参数默认值max_connections = 151#同时处理最大连接数，推荐设置最大连接数是上限连接数的80%左右 sort_buffer_size = 2M#查询排序时缓冲区大小，只对order by和group by起作用，可增大此值为16Mquery_cache_limit = 1M #查询缓存限制，只有1M以下查询结果才会被缓存，以免结果数据较大把缓存池覆盖query_cache_size = 16M #查看缓冲区大小，用于缓存SELECT查询结果，下一次有同样SELECT查询将直接从缓存池返回结果，可适当成倍增加此值open_files_limit = 1024 #打开文件数限制，如果show global status like 'open_files'查看的值等于或者大于open_files_limit值时，程序会无法连接数据库或卡死################### MyISAM参数默认值key_buffer_size = 16M#索引缓存区大小，一般设置物理内存的30-40%,越大越好. 只做数据库的话可以80%read_buffer_size = 128K #读操作缓冲区大小，推荐设置16M或32M################### InnoDB参数默认值innodb_buffer_pool_size = 128M#索引和数据缓冲区大小，一般设置物理内存的60%-70%, 越大越好. 只做数据库的话可以80%innodb_buffer_pool_instances = 1 #缓冲池实例个数，推荐设置4个或8个innodb_flush_log_at_trx_commit = 1 #关键参数，0代表大约每秒写入到日志并同步到磁盘，数据库故障会丢失1秒左右事务数据。1为每执行一条SQL后写入到日志并同步到磁盘，I/O开销大，执行完SQL要等待日志读写，效率低。2代表只把日志写入到系统缓存区，再每秒同步到磁盘，效率很高，如果服务器故障，才会丢失事务数据。对数据安全性要求不是很高的推荐设置2，性能高，修改后效果明显。innodb_file_per_table = OFF #默认是共享表空间，共享表空间idbdata文件不断增大，影响一定的I/O性能。推荐开启独立表空间模式，每个表的索引和数据都存在自己独立的表空间中，可以实现单表在不同数据库中移动。innodb_log_buffer_size = 8M #日志缓冲区大小，由于日志最长每秒钟刷新一次，所以一般不用超过16M 语法 https://www.w3school.com.cn/sql/index.asp 详细教程 https://github.com/jaywcjlove/mysql-tutorial 中国地区表和内容 https://github.com/kakuilan/china_area_mysql 一千行sql https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/%E4%B8%80%E5%8D%83%E8%A1%8CMySQL%E5%91%BD%E4%BB%A4.md","link":"/blog/2020/01/01/mysql-1.%E6%9E%B6%E6%9E%84%E5%92%8C%E8%A7%84%E8%8C%83/"},{"title":"mysql-索引","text":"索引使用和原理 优点: 可以提高数据检索的效率，降低数据库的IO成本，类似于书的目录 通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗 缺点: 占据磁盘空间 降低数据修改的效率, 比如增删改 语法创建索引 12CREATE INDEX index_name ON table(column(length)) ;ALTER TABLE table_name ADD INDEX index_name (column(length)) ; 唯一索引 12CREATE UNIQUE INDEX index_name ON table(column(length)) ;alter table table_name add unique index index_name(column); 全文索引 12CREATE FULLTEXT INDEX index_name ON table(column(length)) ;alter table table_name add fulltext index_name(column) 组合索引 1ALTER TABLE article ADD INDEX index_titme_time (title(50),time(10)) ; 删除索引 1DROP INDEX index_name ON table 查看索引 1SHOW INDEX FROM table_name \\G 原理索引储存结构 索引是在存储引擎中实现的，也就是说不同的存储引擎，会使用不同的索引 MyISAM(非聚簇索引)和InnoDB(聚簇索引)：只支持B+ TREE索引 MEMORY/HEAP存储引擎：支持HASH和BTREE索引 非聚簇索引MyISAM使用非聚簇索引 索引文件(mdi)和数据文件(ibd)是两个文件, 索引文件中叶子结点保存了索引key和数据文件中的指针值 主键索引(Primary Key): 通过索引树找到索引之后拿到数据的指针值, 找到数据文件对应记录 辅助索引(Secondary Key): 和主键索引逻辑一样, 但是他们保存的指针值都是不一样的. 各自维护数据文件的指针值 正因为使用的是非聚簇索引, 索引key和数据记录不在同一个文件中, 所以不支持事务 聚簇索引InnoDB使用聚簇索引 索引和文件保存在一起, 叶子结点保存了索引key和数据记录 主键索引(Primary Key): 通过索引树找到索引key和数据记录 辅助索引(Secondary Key): 通过索引树找到索引key和数据记录, 这是的数据记录是主键key, 再拿主键去找主键索引数, 拿到数据记录(回表操作). 提示: 如果select的字段就是辅助索引中存在的key, 那么直接返回不需要回表操作. 比如, 建立了一个组合索引为A+B, 这时候查询需要的字段正好就是A+B, 那么这就是覆盖索引, 不需要回表 知识点: 更新(增删改)主键代价很高, 因为需要进行排序, 而且叶子结点还带有数据记录, 这就是我们需要加自增主键, 并且不去修改自增主键的原因. 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据(回表操作, 重点)。二级索引的叶节点存储的是主键值. 回表操作: 假设select A,B , 但是这个表有一个组合索引刚好是A,B, 这样的话是不会回表操作. 因为组合索引已经有了所有的列, 不需要在根据主键去查一遍. 覆盖索引: 只是特定于具体select语录而言的联合索引。也就是说一个联合索引对于某个select语句，通过索引可以直接获取查询结果，而不再需要回表查询啦，就称该联合索引覆盖了这条select语句 聚簇索引优点: 取一定范围值的数据比非聚簇快 比非聚簇少一次IO, 因为叶子结点直接存放数据 使用覆盖索引扫描的查询可以直接使用页节点中的主键值 B+Tree首先B+Tree是平衡二叉树, 所以他有平衡二叉树的特点. 左边节点比右边节点小 任何节点的两个子树的高度差不能大于1 看图就知道为什么需要平衡二叉树了 那为什么索引不能直接用平衡二叉树呢? 因为树的深度太大了, 几百万的节点, 树的深度会很高, IO进行的次数就会很多. 一种行之有效的解决方法是减少树的深度，将二叉树变为m叉树（多路搜索树），而B+Tree就是一种多路搜索树。理解B+Tree时，只需要理解其最重要的两个特征即可：第一，所有的关键字（可以理解为数据）都存储在叶子节点（Leaf Page），非叶子节点（Index Page）并不存储真正的数据，所有记录节点都是按键值大小顺序存放在同一层叶子节点上。其次，所有的叶子节点由指针连接。如下图为高度为2的简化了的B+Tree。 怎么理解这两个特征？MySQL将每个节点的大小设置为一个页的整数倍（原因下文会介绍），也就是在节点空间大小一定的情况下，每个节点可以存储更多的内结点，这样每个结点能索引的范围更大更精确。所有的叶子节点使用指针链接的好处是可以进行区间访问，比如上图中，如果查找大于20而小于30的记录，只需要找到节点20，就可以遍历指针依次找到25、30。如果没有链接指针的话，就无法进行区间查找。这也是MySQL使用B+Tree作为索引存储结构的重要原因。MySQL为何将节点大小设置为页的整数倍，这就需要理解磁盘的存储原理。磁盘本身存取就比主存慢很多，在加上机械运动损耗（特别是普通的机械硬盘），磁盘的存取速度往往是主存的几百万分之一，为了尽量减少磁盘I/O，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，预读的长度一般为页的整数倍。 页是计算机管理存储器的逻辑块，硬件及OS往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）。主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后一起返回，程序继续运行。 MySQL巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了读取一个节点只需一次I/O。假设B+Tree的高度为h，一次检索最多需要h-1次I/O（根节点常驻内存），复杂度O(h) = O(logmN)。实际应用场景中，M通常较大，常常超过100，因此树的高度一般都比较小，通常不超过3。 最后简单了解下B+Tree节点的操作，在整体上对索引的维护有一个大概的了解，虽然索引可以大大提高查询效率，但维护索引仍要花费很大的代价，因此合理的创建索引也就尤为重要。 仍以上面的树为例，我们假设每个节点只能存储4个内节点。首先要插入第一个节点28，如下图所示。 接着插入下一个节点70，在Index Page中查询后得知应该插入到50 - 70之间的叶子节点，但叶子节点已满，这时候就需要进行也分裂的操作，当前的叶子节点起点为50，所以根据中间值来拆分叶子节点，如下图所示。 最后插入一个节点95，这时候Index Page和Leaf Page都满了，就需要做两次拆分，如下图所示。 拆分后最终形成了这样一颗树。 B+Tree为了保持平衡，对于新插入的值需要做大量的拆分页操作，而页的拆分需要I/O操作，为了尽可能的减少页的拆分操作，B+Tree也提供了类似于平衡二叉树的旋转功能。当Leaf Page已满但其左右兄弟节点没有满的情况下，B+Tree并不急于去做拆分操作，而是将记录移到当前所在页的兄弟节点上。通常情况下，左兄弟会被先检查用来做旋转操作。就比如上面第二个示例，当插入70的时候，并不会去做页拆分，而是左旋操作。 通过旋转操作可以最大限度的减少页分裂，从而减少索引维护过程中的磁盘的I/O操作，也提高索引维护效率。需要注意的是，删除节点跟插入节点类似，仍然需要旋转和拆分操作，这里就不再说明。 B树高度一般在2-4, 树的高度影响IO读写次数 如果高度3可以支持数据达到20G, 4层可以达到几十T B+Tree相对于B-Tree有几点不同： 非叶子节点只存储键值信息。 所有叶子节点之间都有一个链指针。 数据记录都存放在叶子节点中。 在版本8.0.16和5.7.18上, 主键索引如果使用not in, not exists, !=, &lt;&gt;, &lt;, &gt; 都会使用索引, 类型为range. 辅助索引使用not in, not exists, != , &lt;&gt;一定不走索引, 使用&gt; &lt; between and要看查询到的范围, 范围很大不走索引, 范围很小走索引, 类型range. 其他 count (*) 找普通索引 ,找到最小的那棵树来遍历 包含空值 count（字段） 走缓存 不包含空值 count(1) 忽略字段 包含空值 临时表(Temporary) 使用union会用到, 因为他要用临时表唯一性去重. 如果union all就直接合并结果返回(5.7版本以上) group by如果没有索引的话需要建立临时表去重和排序 一般情况下mysql会创建内存临时表,如果内存超过配置值会将内存临时表导出为磁盘临时表。用到临时表表示性能一般 直接使用磁盘临时表情况： 直接包含text、blob列 group by、distinct子句包含长度大于512字节的列 union、union all子句包含长度大于512字节的列 也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表 索引下推索引下推（index condition pushdown ）简称ICP，在Mysql5.6的版本上推出，用于优化查询。 索引下推就是尽量利用索引信息，来尽可量的减少回表的次数（哪怕不符合最左匹配原则），即减少随机I/O的开销。 比如设置联合索引INDEX(zipcode, lastname, firstname) 1234SELECT * FROM people WHERE zipcode='95054' AND lastname LIKE '%etrunia%' AND address LIKE '%Main Street%'; 如果不用ICP，那么只能使用联合索引的zipcode，回表记录不能有效去除。 使用ICP，除了匹配zipcode的条件之外，额外匹配联合索引的lastname，看其是否符合where条件中的’%etrunia%’，然后进行回表。如此一来，使用联合索引就可以尽可量排除不符合where条件的记录。这就是ICP优化的真谛。 Explain sql 语句时的输出项的Extra会显示Using index condition 来自https://zhuanlan.zhihu.com/p/351446942","link":"/blog/2020/01/02/mysql-2.%E7%B4%A2%E5%BC%95/"},{"title":"mysql-主从复制","text":"简单介绍mysql主从复制 主从复制 master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；salve服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件.同时master为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志.在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。 注意: master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能 slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了 Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。 Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本. master和slave两节点间时间需同步 条件: 开启Binlog功能 主库要建立账号 从库要配置master.info（CHANGE MASTER to…相当于配置密码文件和Master的相关信息. start slave 开启复制功能 保证主从服务器之间网络互通，能使用对方授权信息连接到对方数据库 防火墙开启3306端口 同步数据之前，双方数据库中需要同步的数据要保持一致 解除主从关系: stop slave; reset slave; 或直接删除master.info和relay-log.info这两个文件； 修改my.cnf删除主从相关配置参数。 主从不一致问题 网络延迟. 由于mysql主从复制是基于binlog的一种异步复制，通过网络传送binlog文件，理所当然网络延迟是主从不同步的绝大多数的原因，特别是跨机房的数据同步出现这种几率非常的大，所以做读写分离，注意从业务层进行前期设计。 主从两台机器的负载不一致，由于mysql主从复制是主数据库上面启动1个io线程，而从上面启动1个sql线程和1个io线程，当中任何一台机器的负载很高，忙不过来，导致其中的任何一个线程出现资源不足，都将出现主从不一致的情况。 max_allowed_packet设置不一致，主数据库上面设置的max_allowed_packet比从数据库大，当一个大的sql语句，能在主数据库上面执行完毕，从数据库上面设置过小，无法执行，导致的主从不一致。 自增键不一致，key自增键开始的键值跟自增步长设置不一致引起的主从不一致。 同步参数设置问题，mysql异常宕机情况下，如果未设置sync_binlog=1或者innodb_flush_log_at_trx_commit=1很有可能出现binlog或者relaylog文件出现损坏，导致主从不一致。 主库binlog格式未Statement，同步到从库执行后可能造成主从不一致。 主库执行更改前有执行set sql_log_bin=0，会使主库不记录binlog，从库也无法变更这部分数据。 从节点未设置只读，误操作写入数据 主库或从库意外宕机，宕机可能会造成binlog或者relaylog文件出现损坏，导致主从不一致 主从实例版本不一致，特别是高版本是主，低版本是从的情况下，主数据库上面支持的功能从数据库上面可能不支持 MYSQL自身bug导致 https://www.cnblogs.com/jinlei92131/p/13597304.html 操作master数据库部署1. 创建需要同步的数据库1234567mysql -u root -p123456mysql&gt; create database nongkaige;mysql&gt; use nongkaige;mysql&gt; create table if not exists nong(id int(10),name varchar(20));mysql&gt; insert into nongkaige.nong values(1,&quot;nongkaige&quot;),(2,&quot;huanglihua&quot;),(3,&quot;nongziyi&quot;);mysql&gt; select * from nongkaige.nong; 2. 配置my.cnf12345678vim /etc/mysql/my.cnf在[mysqld]下添加：server-id=1 #数据库唯一ID，主从的标识号绝对不能重复log-bin=mysql-bin-master #启用二进制日志，并指定前缀名，可自定义binlog-do-db=nongkaige #需要同步的数据库，如果多个，则另写几行即可，如果不指定对哪个库进行同步，就去掉此行，表示同步所有库（除了ignore忽略的库. binlog-ignore-db=mysql #不同步mysql系统库，如果多个，则另写几行即可sync-binlog=1 #确保binlog日志写入后与硬盘同步，此参数不是强制要求写入 sync_binlog参数: sync_binlog=0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。 sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。 在MySQL中系统默认的设置是sync_binlog=0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失。而当设置为“1”的时候，是最安全但是性能损耗最大的设置。因为当设置为1的时候，即使系统Crash，也最多丢失binlog_cache中未完成的一个事务，对实际数据没有任何实质性影响。对于高并发事务的系统来说，“sync_binlog”设置为0和设置为1的系统写入性能差距可能高达5倍甚至更多。 3. 导出master需要同步的数据库，然后导入到slave数据库，保证双方在同步之前数据一致 导出之前先锁定只读数据库，防止导出的时候有数据写入，unlock tables命令解除锁定 1234mysql&gt; flush tables with read lock;mysqldump -u root -p123456 -B nongkaige &gt; nongkaige.sqlscp nongkaige.sql 192.168.10.29:/root/ 4. 设置数据同步权限1234mysql -u root -p123456mysql&gt; grant replication slave on *.* to slave@'192.168.10.29' identified by &quot;123456&quot;;mysql&gt; flush privileges; 查看权限方式： mysql&gt; show grants for slave@'192.168.10.29'; 5. 检测slave数据库能不能使用授权的用户密码登录到master数据库上mysql -u slave -p123456 -h 192.168.10.27 6. 重启master数据库，查看主服务器master状态（注意，是重启，reload也不顶用）1234service mysqld restartmysql -u root -p123456mysql&gt; show master status; slave数据库部署1. 配置my.cnf12345vim /etc/mysql/my.cnf在[mysqld]下添加：server-id=2slave-skip-errors=all #跳过所有的错误，继续执行复制操作，此参数不是必须写入参数。 2. 重启slave数据库1service mysqld restart 3. 导入从master传过来的数据123456mysql -u root -p123456（要先创建nongkaige库，和master上的一样，否则一会导入会报错）mysql&gt; create database nongkaige;mysql&gt; use nongkaige;mysql&gt; source /root/nongkaige.sql; 也可以不登录mysql导入：mysql -u root -p123456 nongkaige &lt; nongkaige.sql 查看一下是否导入成功 4. 配置主从同步指令执行同步之前，要先关闭slave 1234mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.10.27',master_user='slave',master_password='123456';mysql&gt; start slave;mysql&gt; show slave status \\G Slave_IO_Running ：一个负责与主机的io通信 Slave_SQL_Running：负责自己的slave mysql进程 如上，当IO和SQL线程的状态均为Yes，则表示主从同步已经实现了！ 测试主从 先在master数据库上写入数据（先解锁只读数据，否则无法写入） 12mysql&gt; unlock tables;mysql&gt; insert into nongkaige.nong values(100,&quot;pipixia&quot;); 在slave数据库上查看，发现master上新写入的数据已经同步过来了 1mysql&gt; select * from nongkaige.nong; Mysql主从中继同步M-S-S部署master -&gt; slave中继 -&gt; slave 这样的架构可以缓解master的磁盘I/O压力。使用一台slave作为中继，分担master的压力，slave中继需要开启bin-log，并配置log-slave-updates，slave中继可使用Black-hole存储引擎，不会把数据存储到磁盘，只记录二进制日志。 和配置主从一样, 按照指向来一步步配置. 最后一步, 修改中继slave中继表的存储引擎为blackhole. 先关闭日志记录再修改，否则一会把这个操作也同步到slave从服务上边了 123mysql&gt; set sql_log_bin=off;mysql&gt; alter table nongkaige.nong ENGINE=blackhole;mysql&gt; set sql_log_bin=on; 感谢Mysql双主互备M-M部署 docker搭建主从目录结构 1234567- E:\\DOCKER\\MYSQL-READ-WRITE - mysql-master(目录) - mysql-slave(目录) - docker-compose.yml - master.my.cnf - slave1.my.cnf - slave2.my.cnf docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: '2'services: mysql-master: image: docker.io/mysql networks: jznet: ipv4_address: 172.18.4.24 volumes: - E://DOCKER//MYSQL-READ-WRITE//mysql-master:/var/lib/mysql - E://DOCKER//MYSQL-READ-WRITE//master.my.cnf:/etc/mysql/my.cnf ports: - &quot;33066:3306&quot; environment: - MYSQL_DATABASE=root - MYSQL_ROOT_PASSWORD=root mysql-slave1: image: docker.io/mysql networks: jznet: ipv4_address: 172.18.4.25 volumes: - E://DOCKER//MYSQL-READ-WRITE//mysql-slave1:/var/lib/mysql - E://DOCKER//MYSQL-READ-WRITE//slave1.my.cnf:/etc/mysql/my.cnf ports: - &quot;33067:3306&quot; environment: - MYSQL_DATABASE=root - MYSQL_ROOT_PASSWORD=root mysql-slave2: image: docker.io/mysql networks: jznet: ipv4_address: 172.18.4.26 volumes: - E://DOCKER//MYSQL-READ-WRITE//mysql-slave2:/var/lib/mysql - E://DOCKER//MYSQL-READ-WRITE//slave2.my.cnf:/etc/mysql/my.cnf ports: - &quot;33068:3306&quot; environment: - MYSQL_DATABASE=root - MYSQL_ROOT_PASSWORD=rootnetworks: jznet: driver: bridge ipam: driver: default config: - subnet: 172.18.4.0/26 master.my.cnf 12345678[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysqlsecure-file-priv= NULLserver-id=1# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0 slave1.my.cnf 123456789[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysqlsecure-file-priv= NULLserver-id=2relay_log_recovery=0# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0 slave2.my.cnf 123456789[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysqlsecure-file-priv= NULLserver-id=3relay_log_recovery=0# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0 docker中执行docker-compose up -d 这里可能是mysql禁止外部连接, 如果遇到这种情况 12345docker exec -it containerId bashmysql -u root -puse mysql;update user set host = '%' where user = 'root';FLUSH PRIVILEGES; 连接主从库 现在主库中建立用户 12CREATE USER 'repl'@'%' IDENTIFIED WITH mysql_native_password BY 'Ron_master_1';GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; 查看主库的状态show master status; 从库连接主库, 这边配置要按照之前的修改,MASTER_LOG_FILE和MASTER_LOG_POS按照之前查看的主库的状态来配置 123456CHANGE MASTER TOMASTER_HOST='172.18.4.24',MASTER_USER='repl',MASTER_PASSWORD='Ron_master_1',MASTER_LOG_FILE='binlog.000002',MASTER_LOG_POS=658; 开启从库start slave; 查看show slave status;, 这时候Slave_IO_Running和Slave_SQL_Running应该为Yes. Slave_SQL_Running_State应该为Slave has read all relay log; waiting for more updates 之后再主库中增删改查, 从库会同步过来","link":"/blog/2020/01/04/mysql-4.%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"title":"mysql-组复制MGR","text":"mysql组复制MGR MySQL Group Replication(MGR)是MySQL官方在5.7.17版本引进的一个数据库高可用与高扩展的解决方案, 以插件形式提供, 实现了分布式下数据的最终一致性.总结MGR特点如下: 高一致性: 基于分布式paxos协议实现组复制, 保证数据一致性 高容错性: 自动检测机制, 只要不是大多数节点都宕机就可以继续工作, 内置防脑裂保护机制 高扩展性: 节点的增加与移除会自动更新组成员信息, 新节点加入后, 自动从其他节点同步增量数据, 直到与其他节点数据一致 高灵活性: 提供单主模式和多主模式, 单主模式在主库宕机后能够自动选主, 所有写入都在主节点进行, 多主模式支持多节点写入 替代主从复制的方案, 解决了主从复制写操作只能在master上和master宕机之后需要手动选择新的master. MySQL Group Replication有两种模式 单主模式single-primary mode 多主模式multi-primary mode 在同一个group内, 不允许两种模式同时存在, 并且若要切换到不同模式, 必须修改配置后重新启动集群 原理单主模式在单主模式下, 只有一个节点可以读写, 其他节点提供只读服务.group-replication-enforce-update-everywhere-checks必须将此选项设置为 FALSE.支持外键 当主节点宕掉, 自动会根据服务器的group_replication_member_weight(优先选择, 越高越好,默认50, 范围0-100)变量值和server_uuid(第二选项, 根据数据字典排序, 最前面为主节点)变量, 选择下一个slave谁作为主节点 在单主模式下，只有一个节点可以读写，其他节点提供只读服务(自动设置super-read-only=ON)。 单主模式中发现当前的主服务器, 该值VARIABLE_VALUE为实例节点的server_uuid 1SELECT VARIABLE_VALUE FROM performance_schema.global_status WHERE VARIABLE_NAME= 'group_replication_primary_member'; 多主模式多主模式下, 在组复制中通过Group Replication Protocol协议及Paxos协议, 形成的整体高可用解决方案. 同时增加了certify的概念, 负责检查事务是否允许提交, 是否与其它事务存在冲突, Group Replication是由多个节点共同组成一个数据库集群, 每个节点都可以单独执行事务, 但是read-write(rw)的操作只有在组内验证后才可以commit. Read-only (RO)事务是不需要验证可以立即执行, 当一个事务在一个节点上提交之前, 会在组内自动进行原子性的广播, 告知其他节点变更了什么内容/执行了什么事务, 然后为该事物建立一个全局的排序. 最终, 这意味着所有的服务器都以相同的顺序接收相同的事务集. 因此, 所有服务器都按照相同的顺序应用相同的变更集, 因此它们在组中保持一致. 在多主模式下, 所有自动设置为读写模式. 不允许外键 不支持SERIALIZABLE事务隔离级别 可能导致死锁, 比如select …for update在不同节点执行, 由于多节点锁无法共享, 很容易导致死锁 对同一个对象进行并发的有冲突的ddl和dml操作导致这种冲突在部分成员节点中无法检测到, 最终可能导致数据不一致 冲突检测MGR多主模式下, 一个事务在执行时, 并不会做前置的检查, 但是在提交阶段, 会和其他节点通信对该事务是否能够提交达成一个决议. 在多个节点同对相同记录的修改, 在提交时会进行冲突检测, 首先提交的事务将获得优先权. 例如对同一条记录的修改, t1事务先于t2事务, 那么t1事务在冲突检测后获得执行权, 顺利提交, 而t2事务进行回滚. 显然这种多点写入条件下, 对于同一条记录的并发修改, 由于大量的回滚, 导致性能很低, 因此MySQL官方建议, 这种对于同一条记录的修改, 应该放在同一个节点执行, 这样可以利用节点本地锁来进行同步等待, 减少事务回滚, 提高性能. 新节点加入过程新节点申请加入组, 会在组中生成一个View_change事件, 组内所有online节点将该事件写入到binlog, 同时申请加入组的新节点也会记录这个View_change事件.之后该节点会进入下面两个阶段: 第一阶段, 新节点会从组内online的节点中选择一个作为贡献者(donor), 通过标准的异步复制通道, 拉取贡献者的binlog, 并应用这些binlog. 与此同时, 新节点也会获取当前组内正在交换的事务信息, 并将其缓存到队列中, 当binlog应用完成, 也就是应用到View_change事件处, 异步复制通道关闭. 第二阶段, 新节点处理缓存在队列中的组内事务信息, 当队列中的事务信息处理完成, 即缓存队列长度为0时, 新节点在组内状态变为online. 在第一阶段, 遇到任何错误, 新节点会自动从组内选择另外一个online节点作为贡献者. 如果仍然遇到异常, 会继续选择其他online节点, 直到所有online节点枚举完毕.如果这时仍然报错, 会sleep一段时间之后, 再次重试. 12group-replication-recovery-retry-count=10 //重试次数, 默认10, 范围0-31536000group-replication-recovery-reconnect-interval=60 //全部重试完还没成功之后的睡眠时间, 默认60 要求使用限制 仅支持innodb存储引擎. 能够创建非innodb引擎的表, 但是无法写入数据, 向非innodb表写数据直接报错. 为了保证整个组的一致性, 使用事务作为编排, 所以只能用InnoDB 表必须有主键，或者非Null的唯一键. 使系统能够通过确定每个事务已修改哪些行来确定哪些事务发生冲突. 只支持IPv4网络 网络性能 最好网络性能都是差不多, 因为同步数据如果一个节点很慢, 会拖慢整组服务 忽略表锁和命名锁. 在MGR中lock tables、unlock tables、get_lock、release_lock等这些表锁和命名锁将被忽略 不支持超大事务 不支持复制过滤, 如果有节点设置了复制过滤, 将影响节点间决议的达成 MGR最多支持9个节点, 大于9个节点, 将拒绝新节点的加入 节点配置要求 log_bin=binlog 组复制复制二进制日志内容，因此需要打开二进制日志才能运行 log_slave_updates=ON 组中的服务器需要记录它们从组中接收和应用的所有事务 binlog_format=ROW 组复制依赖于基于行的复制格式来在组中的服务器之间一致地传播更改 gtid_mode=ON 使用全局事务标识符来精确地跟踪每个服务器实例上已经提交了哪些事务 master_info_repository=TABLE 将主信息日志写入mysql.slave_master_info表中 relay_log_info_repository=TABLE 将中继日志信息日志写入到mysql.slave_relay_log_info表中 transaction_write_set_extraction=XXHASH64 并行复制 slave_parallel_type=LOGICAL_CLOCK slave_preserve_commit_order=1 slave_parallel_workers=[N] binlog_checksum=NONE transaction_isolation=READ-COMMITTED #官方推荐在MGR中隔离级别设置为RC http://www.searchdoc.cn/rdbms/mysql/dev.mysql.com/doc/refman/5.7/en/group-replication-requirements.com.coder114.cn.html MGR单主模式部署先给出my.cnf文件, 其中server_id, loose-group_replication_local_address需要修改, loose-group_replication_group_seeds需要改为自己组的全部ip 1234567891011121314151617181920212223242526272829[mysqld]secure_file_priv=/var/lib/mysqldatadir=/var/lib/mysql/data#socket=/tmp/mysql.sockuser=mysql# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0#Group Replicationserver_id = 1 #服务IDgtid_mode = ON #全局事物enforce_gtid_consistency = ON #强制GTID的一致性master_info_repository = TABLE #将master.info元数据保存在系统表中relay_log_info_repository = TABLE #将relay.info元数据保存在系统表中binlog_checksum = NONE #禁用二进制日志事件校验log_slave_updates = ON #级联复制log_bin = binlog #开启二进制日志记录binlog_format= ROW #以行的格式记录transaction_write_set_extraction = XXHASH64 #使用哈希算法将其编码为散列loose-group_replication_group_name = 'ce9be252-2b71-11e6-b8f4-00212844f856' #加入的组名loose-group_replication_start_on_boot = off #不启用自动复制集群功能loose-group_replication_local_address = 'group1:33066' #以本机3306端口接收来自组成员的传入连接loose-group_replication_group_seeds ='group1:33066,group2:33066,group3:33066' #组中成员访问列表loose-group_replication_bootstrap_group = off #不启用引导组[mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid group1/2/3创建network 1docker network create mysql_group 根据group*改不同的参数 1docker run --name mysql_group1 -v /Users/hjr/docker/mysql_mgr/group1/data:/var/lib/mysql -v /Users/hjr/docker/mysql_mgr/group1/conf/my.cnf:/etc/mysql/my.cnf --privileged=true -e MYSQL_ROOT_PASSWORD=root -p 3307:3306 --network mysql_group --network-alias group1 -d mysql 12345docker exec -it mysql_group1 /bin/bashmysql -u root -p rootshow variables like 'plugin_dir'; //搜索一下我们需要的MGR插件group_replication.so是否存在install PLUGIN group_replication SONAME 'group_replication.so';//安装插件 show plugins; //看是否安装成功 123456789101112131415#主才需要启动引导,从都请忽略这一步mysql&gt; set global group_replication_bootstrap_group=ON;#创建一个用户来做同步的用户,并授权,所有集群内的服务器都需要做mysql&gt; create user 'group'@'%' identified by 'group';mysql&gt; grant REPLICATION SLAVE on *.* to 'group'@'%' with grant option;#清空所有旧的GTID信息,避免冲突mysql&gt; reset master;#创建同步规则认证信息,就是刚才授权的那个用户,和一般的主从规则写法不太一样mysql&gt; CHANGE MASTER TO MASTER_USER='group', MASTER_PASSWORD='group' FOR CHANNEL 'group_replication_recovery';#启动MGRmysql&gt; start group_replication;#查看是否启动成功,看到online就是成功了mysql&gt; select* from performance_schema.replication_group_members;#这个时候,就可以先关闭引导了mysql&gt; set global group_replication_bootstrap_group=OFF; 感谢 https://www.93bok.com/MySQL%E9%9B%86%E7%BE%A4MGR%E6%9E%B6%E6%9E%84for%E5%8D%95%E4%B8%BB%E6%A8%A1%E5%BC%8F/ https://www.jianshu.com/p/43c80b5e8764","link":"/blog/2020/01/05/mysql-5.%E7%BB%84%E5%A4%8D%E5%88%B6/"},{"title":"mysql-分表分库","text":"mysql分表分库 分表分库分表: 对于访问极为频繁且数据量巨大的单表来说，我们首先要做的就是减少单表的记录条数，以便减少数据查询所需要的时间，提高数据库的吞吐.分库: 如果全部表放在一个服务器上, 对于带宽, 连接数, cpu, io等压力都很大. 对数据库进行拆分，从而提高数据库写入能力 分库分表计算策略: 中间变量 = user_id % (分库数量 * 每个库的表数量) 库 = 取整数 (中间变量 / 每个库的表数量) 表 = 中间变量 % 每个库的表数量 阿里巴巴《Java 开发手册》提出单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表 假设现有有订单2000w数据, 想要单表控制在100w, 所以需要拆分成20个表, 准备每个库5个表, 所以准备4个库 分表分库工具: shardingsphere, 比较轻量级, 需要改代码 mycat, 需要部署和维护, 并且网络也会过这一段, 不需要改代码, 适合项目很大很杂的 步骤: 根据容量(当前容量和增长量)评估分库或分表个数 选key(均匀), 分表规则(hash或range等) 执行(一般双写) 扩容问题(尽量减少数据的移动) Sharding Sphere实现详细可看官网 假设本来有订单表t_user, t_user_detail, t_order, t_order_item, t_dic, 感谢: https://www.cnblogs.com/tiancai/p/11698826.html https://www.cnblogs.com/littlecharacter/p/9342129.html#_lab2_4_0 美团订单分库逻辑","link":"/blog/2020/01/06/mysql-6.%E5%88%86%E8%A1%A8%E5%88%86%E5%BA%93/"},{"title":"mysql-隔离级别设置","text":"mysql隔离级别设置优化 mysql binlog三种模式row模式日志中会记录每一行数据被修改的形式 优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息，仅仅只需要记录那一条被修改。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。不会出现某些特定的情况下的存储过程或function，以及trigger的调用和触发无法被正确复制的问题 缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，会产生大量的日志内容。 Statement（默认）每一条会修改数据的sql都会记录到master的bin-log中。slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql来再次执行 优点：statement level下的优点首先就是解决了row level下的缺点，不需要记录每一行数据的变化，减少bin-log日志量，节约IO，提高性能，因为它只需要在Master上锁执行的语句的细节，以及执行语句的上下文的信息。 缺点：由于只记录语句，所以在statement level下 已经发现了有不少情况会造成MySQL的复制出现问题，主要是修改数据的时候使用了某些定的函数或者功能的时候会出现。 Mixed自动模式在Mixed模式下，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志格式，也就是在Statement和Row之间选择一种。如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。 企业场景如何选择binlog模式 选择Statement: 互联网公司，使用MySQL的功能相对少（存储过程、触发器、函数） 选择Mixed: 公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数） 选择row: 公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数）又希望数据最大化一致 mysql选择隔离级别隔离级别是读未提交(Read UnCommitted) , 读已提交(Read Commited) , 可重复读(Repeatable Read), 串行化(Serializable) , 默认可重复读. 可重复读可以避免幻读. 先说明为什么默认是可重复读? mysql在5.0之前binlog只有statement模式. 而这种模式在读已提交的隔离级别下面是有bug的. 假设现在有session1和session1同时执行, 并且隔离级别都是读已提交 1234567Session1 Session2insert id=1;begin; begin;delete id&lt;10; insert id=2; commit;commit; 在主从复制的时候master顺序为先删在后入, 但是binlog日志为先先插后删. 解决方式: 设置隔离级别为可重复读, 这样session1删除的时候因为间隙锁session2会被阻塞. binlog设置为row模式, 就不会出现sql执行顺序不一致. 但是5.1才引入row模式. 因为历史原因mysql默认隔离界别为可重复读 我们项目中改为了读已提交. 原因如下几点: 1234567891011121314CREATE TABLE `test` (`id` int(11) NOT NULL,`color` varchar(20) NOT NULL,PRIMARY KEY (`id`)) ENGINE=InnoDB+----+-------+| id | color |+----+-------+| 1 | red || 2 | white || 5 | red || 7 | white |+----+-------+ RR隔离级别下, 存在间隙锁, 导致死锁的概率比RC大得多. RR隔离级别下, 条件未命中索引会升级为锁表. 123update test set color = 'blue' where color = 'white';// 如果是RC下, 先走聚簇索引, 先全部加锁. 但是mysql做了优化, 然后会把不满足条件的锁放开, 只加white的锁.//如果在RR下, 先走聚簇索引, 先全部加锁. 因为间隙锁white的间隙都会锁上, 不会放开锁. 在RC下, 半一致性读(emi-consistent)增加了update的并发性. 比如update的where条件是id=1 and id=2, 一般会锁住1和2, 但是现在会判断锁住的1和2是不是符合where条件. 而在RR下这个特性无效. 那么在RC级别下, 不可重复读问题需要解决么? 不需要, 毕竟数据已经提交了, 读出来本身没太大问题. oracle也是读已提交, 你们有改过这个隔离级别么 结论: 可以使用row格式, 并且改为RC","link":"/blog/2020/01/07/mysql-7.%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E8%AE%BE%E7%BD%AE/"},{"title":"mysql-触发器","text":"mysql触发器 SQL触发器是存储在数据库目录中的一组SQL语句。每当与表相关联的事件发生时，即会执行或触发SQL触发器，例如插入，更新或删除。 SQL触发器是一种特殊类型的 存储过程. 这是特别的，因为它不像直接像存储过程那样调用。 触发器和存储过程之间的主要区别在于，当对表执行数据修改事件时，会自动调用触发器，而存储过程必须要明确地调用 优缺点优点 SQL触发器提供了检查数据完整性的替代方法。 SQL触发器可以捕获数据库层中业务逻辑中的错误。 SQL触发器提供了运行计划任务的另一种方法。通过使用SQL触发器，您不必等待运行计划的任务，因为在对表中的数据进行更改之前或之后自动调用触发器。 SQL触发器对于审核表中数据的更改非常有用。 缺点 SQL触发器只能提供扩展验证，并且无法替换所有验证。一些简单的验证必须在应用层完成。 例如，您可以使用JavaScript或服务器端使用服务器端来验证客户端的用户输入。 从客户端应用程序调用和执行SQL触发器不可见，因此很难弄清数据库层中发生的情况。 SQL触发器可能会增加数据库服务器的开销。 简介触发器是一组SQL语句，当对相关联的表上的数据进行更改时，会自动调用该语句. 在MySQL5.7.2版本之前，每个表最多可以定义六个触发器。 BEFORE INSERT - 在数据插入表之前被激活触发器。 AFTER INSERT - 在将数据插入表之后激活触发器。 BEFORE UPDATE - 在表中的数据更新之前激活触发器。 AFTER UPDATE - 在表中的数据更新之后激活触发器。 BEFORE DELETE - 在从表中删除数据之前激活触发器。 AFTER DELETE - 从表中删除数据之后激活触发器。 从*MySQL 5.7.2+*版本开始，可以为相同的触发事件和动作时间定义多个触发器。 当使用不使用INSERT，DELETE或UPDATE语句更改表中数据的语句时，不会调用与表关联的触发器。 比如truncate不会调用触发器 必须要为与表相关联的每个触发器使用唯一的名称。可以为不同的表定义相同的触发器名称，这是一个很好的做法。 应该使用以下命名约定命名触发器： 1(BEFORE | AFTER)_tableName_(INSERT| UPDATE | DELETE) 也可以这样 1tablename_(BEFORE | AFTER)_(INSERT| UPDATE | DELETE) 例如，order_before_update与上述before_order_update触发器相同。 触发器存储MySQL在数据目录中存储触发器，例如：/data/dbname/,并使用名为tablename.TRG和triggername.TRN的文件： tablename.TRG文件将触发器映射到相应的表。 triggername.TRN文件包含触发器定义。 可以通过将触发器文件复制到备份文件夹来备份MySQL触发器。也可以使用mysqldump工具备份触发器 限制MySQL触发器不能： 使用在SHOW，LOAD DATA，LOAD TABLE，BACKUP DATABASE，RESTORE，FLUSH和RETURN语句之上。 使用隐式或明确提交或回滚的语句，如COMMIT，ROLLBACK，START TRANSACTION，LOCK/UNLOCK TABLES，ALTER，CREATE，DROP，RENAME等。 使用准备语句，如PREPARE，EXECUTE等 使用动态SQL语句。 从MySQL 5.1.4版本开始，触发器可以调用存储过程或存储函数，在这之前的版本是有所限制的。 创建创建单个语法 123456CREATE TRIGGER trigger_name trigger_time trigger_event ON table_name FOR EACH ROW BEGIN ... END; trigger_name 遵循命名规范 trigger_time 触发器之前使用before, 之后after trigger_event 分为INSERT，UPDATE或DELETE , 只能写一个事件. 如果需要多个事件就写多个触发器 on 后面必须关联表名, 没有表名触发器无效 sql语句放在begin和end之间 比如 123456789101112DELIMITER $$CREATE TRIGGER before_employee_update (触发器名) BEFORE UPDATE ON employees (employees在更新之前) FOR EACH ROW BEGIN INSERT INTO employees_audit (employees_audit插入数据) SET action = 'update', employeeNumber = OLD.employeeNumber, lastname = OLD.lastname, changedat = NOW(); END$$DELIMITER ; 请注意，在为INSERT定义的触发器中，可以仅使用NEW关键字。不能使用OLD关键字。但是，在为DELETE定义的触发器中，没有新行，因此您只能使用OLD关键字。在UPDATE触发器中，OLD是指更新前的行，而NEW是更新后的行。 查看所有show triggers; 创建多个在*MySQL5.7.2+*版本之前，您只能为表中的事件创建一个触发器，例如，只能为BEFORE UPDATE或AFTER UPDATE事件创建一个触发器。 *MySQL 5.7.2+*版本解决了这样限制，并允许您为表中的相同事件和动作时间创建多个触发器。当事件发生时，触发器将依次激活。 语法和创建单个差不多. 其中区别是: 要更改触发器的顺序，需要在FOR EACH ROW子句之后指定FOLLOWS或PRECEDES。如下说明 - FOLLOWS选项允许新触发器在现有触发器之后激活。 PRECEDES选项允许新触发器在现有触发器之前激活。 12345678DELIMITER $$CREATE TRIGGER trigger_name[BEFORE|AFTER] [INSERT|UPDATE|DELETE] ON table_nameFOR EACH ROW [FOLLOWS|PRECEDES] existing_trigger_nameBEGIN…END$$DELIMITER ; 例子: 1234567891011DELIMITER $$CREATE TRIGGER before_products_update (创建第一个触发器) BEFORE UPDATE ON products FOR EACH ROW BEGIN (更新了products表就在price_logs里面插入日志数据) INSERT INTO price_logs(product_code,price) VALUES(old.productCode,old.msrp);END$$DELIMITER ; 12345678910DELIMITER $$CREATE TRIGGER before_products_update_2 (创建第二个触发器) BEFORE UPDATE ON products FOR EACH ROW FOLLOWS before_products_updateBEGIN (在第一个触发器执行完后, 在另一个表里面插入日志数据) INSERT INTO user_change_logs(product_code,updated_by) VALUES(old.productCode,user());END$$DELIMITER ; 如果使用SHOW TRIGGERS语句，则不会在表中看到触发激活同一事件和操作的顺序。 要查找此信息，需要如下查询information_schema数据库的triggers表中的action_order列，如下查询语句 - 123456789SELECT trigger_name, action_orderFROM information_schema.triggersWHERE trigger_schema = 'yiibaidb'ORDER BY event_object_table , action_timing , event_manipulation; 管理触发器触发器作为纯文本文件存储在以下数据库文件夹中： 1/data_folder/database_name/table_name.trg 也可通过查询information_schema数据库中的triggers表来显示触发器，如下所示： 12345678SELECT *FROM information_schema.triggersWHERE trigger_schema = 'database_name' AND trigger_name = 'trigger_name'; (指定触发器名称) AND event_object_table = 'employees';(指定表名) 还可以 SHOW TRIGGERS; 查找所有 SHOW TRIGGERS FROM dbname;指定db SHOW TRIGGERS FROM dbnameWHERE table = 'tablename';指定表 删除触发器DROP TRIGGER table_name.trigger_name; 修改只能删除重新建 事件调度器MySQL事件是基于预定义的时间表运行的任务，因此有时它被称为预定事件。MySQL事件也被称为“时间触发”，因为它是由时间触发的，而不是像触发器一样更新表来触发的。 在许多情况下使用MySQL事件，例如优化数据库表，清理日志，归档数据或在非高峰时间生成复杂的报告。 查看事务调度器show processlist; 默认情况下，事件调度程序线程未启用。 要启用和启动事件调度程序线程，需要执行以下命令： SET GLOBAL event_scheduler = ON; off禁用 创建1234CREATE EVENT [IF NOT EXIST] event_nameON SCHEDULE scheduleDOevent_body 首先，在CREATE EVENT子句之后指定事件名称。事件名称在数据库模式中必须是唯一的。 其次，在ON SCHEDULE子句后面加上一个表。如果事件是一次性事件，则使用语法：AT timestamp [+ INTERVAL]，如果事件是循环事件，则使用EVERY子句：EVERY interval STARTS timestamp [+INTERVAL] ENDS timestamp [+INTERVAL] 第三，将DO语句放在DO关键字之后。请注意，可以在事件主体内调用存储过程。 如果您有复合SQL语句，可以将它们放在BEGIN END块中。 比如: 1234567891011CREATE TABLE IF NOT EXISTS messages ( id INT PRIMARY KEY AUTO_INCREMENT, message VARCHAR(255) NOT NULL, created_at DATETIME NOT NULL);CREATE EVENT IF NOT EXISTS test_event_01ON SCHEDULE AT CURRENT_TIMESTAMPDO INSERT INTO messages(message,created_at) VALUES('Test MySQL Event 1',NOW()); 会查询到一条数据. 这意味着事件在创建时被执行。 查询事件 SHOW EVENTS FROM dbtest;啥都没有, 说明事件执行完之后就会被删除 在其创建时间1分钟后执行, ON COMPLETION PRESERVE 执行后不会被删除 1234567CREATE EVENT test_event_02ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 MINUTEON COMPLETION PRESERVEDO INSERT INTO messages(message,created_at) VALUES('Test MySQL Event 2',NOW()); 以下语句创建一个循环的事件，每分钟执行一次，并在其创建时间的1小时内过期： 1234567CREATE EVENT test_event_03ON SCHEDULE EVERY 1 MINUTESTARTS CURRENT_TIMESTAMPENDS CURRENT_TIMESTAMP + INTERVAL 1 HOURDO INSERT INTO messages(message,created_at) VALUES('Test MySQL recurring Event',NOW()); 请注意，使用STARTS和ENDS子句定义事件的有效期。等待个3，5分钟后再查看messages表数据，以测试验证此循环事件的执行。 删除DROP EVENT [IF EXISTS] event_name; 修改1234567ALTER EVENT event_nameON SCHEDULE scheduleON COMPLETION [NOT] PRESERVERENAME TO new_event_nameENABLE | DISABLEDO event_body 请注意，ALTER EVENT语句仅适用于存在的事件。如果您尝试修改不存在的事件，MySQL将会发出一条错误消息，因此在更改事件之前，应先使用SHOW EVENTS语句检查事件的存在。 本来 123456USE testdb;CREATE EVENT test_event_04ON SCHEDULE EVERY 1 MINUTEDO INSERT INTO messages(message,created_at) VALUES('Test ALTER EVENT statement',NOW()); 现在修改2分钟运行一次 12ALTER EVENT test_event_04ON SCHEDULE EVERY 2 MINUTE; 还可以改变逻辑主体 1234ALTER EVENT test_event_04DO INSERT INTO messages(message,created_at) VALUES('Message from event',NOW()); 要禁用某个事件,请在ALTER EVENT语句之后使用DISABLE关键字，请使用以下语句： 12ALTER EVENT test_event_04DISABLE; 启用 12ALTER EVENT test_event_04ENABLE; 重命名 12ALTER EVENT test_event_04RENAME TO test_event_05; 移动到其他数据库 12ALTER EVENT testdb.test_event_05RENAME TO newdb.test_event_05; 感谢原文易百","link":"/blog/2019/01/08/mysql-A2.%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"title":"mysql-存储过程","text":"mysql存储过程 优缺点MySQL存储过程的优点 减少网络通信量。调用一个行数不多的存储过程与直接调用SQL语句的网络通信量可能不会有很大的差别，可是如果存储过程包含上百行SQL语句，那么其性能绝对比一条一条的调用SQL语句要高得多。 执行速度更快。存储过程创建的时候，数据库已经对其进行了一次解析和优化。其次，存储过程一旦执行，在内存中就会保留一份这个存储过程，这样下次再执行同样的存储过程时，可以从内存中直接中读取。 更强的安全性。存储过程是通过向用户授予权限(而不是基于表)，它们可以提供对特定数据的访问，提高代码安全，比如防止 SQL注入。 业务逻辑可以封装存储过程中，这样不仅容易维护，而且执行效率也高 MySQL存储过程的缺点 如果使用大量存储过程，那么使用这些存储过程的每个连接的内存使用量将会大大增加。 此外，如果您在存储过程中过度使用大量逻辑操作，则CPU使用率也会增加，因为数据库服务器的设计不当于逻辑运算。 存储过程的构造使得开发具有复杂业务逻辑的存储过程变得更加困难。 很难调试存储过程。只有少数数据库管理系统允许您调试存储过程。不幸的是，MySQL不提供调试存储过程的功能。 开发和维护存储过程并不容易。开发和维护存储过程通常需要一个不是所有应用程序开发人员拥有的专业技能。这可能会导致应用程序开发和维护阶段的问题。 入门创建12345678DELIMITER // CREATE PROCEDURE getAllUsers() BEGIN SELECT * FROM user; END //DELIMITER ;call test.getAllUsers(); 解释: DELIMITER // 和存储过程无关, 表示//变为;. 意思就是只有 END //表示END ; 最后一个命令(DELIMITER;)将分隔符更改回分号(;)。 创建语句固定CREATE PROCEDURE + 命名 begin到end之间表示语句内容 call test.getAllUsers();调用存储语句查询得到结果. 在workbench中建立了存储过程, stored procedures中可以看见 删除1drop procedure if exists `getAllUsers`; 查询存储过程 查询所有存储过程 show procedure status; 查询指定数据库存储过程show procedure status where db = 'test'; 显示源代码show create procedure proceduce_name 参数开发存储过程肯定会用到参数, 其中参数有三种模式: in, out, inout in是默认模式. 它里面就是说存储过程只使用in参数的值, 在存储过程中改变了值是无效的 12345678910111213141516(括号里的都是注释忽略)(先创建存储过程)delimiter // create procedure getUserById(in id int)beginselect id; (这里传递过来的id为1, 所以输出1)set id=3; (这里改变了id的值)select * from user where user_id=id; (这里输出id为3的对象的查询结果)select id; (这里输出3, 因为改变了3)end //delimiter ;set @id=1; call test.getUserById(@id);select @id; (重点:::这里输出1, 因为传递过去的只是id的副本) 结果是: 先输出 1, 在输出查询结果id为3的结果对象, 在输出3, 最后输出1 out 可以在存储过程中更改OUT参数的值，并将其更改后新值传递回调用程序。请注意，存储过程在启动时无法访问OUT参数的初始值 12345678910delimiter //create procedure out_test(out total int)beginselect total; (这里获取到的total是null)select count(*) into total from user; (通过into赋值给了total)end //delimiter ;call test.out_test(@total);select @total; (这里获取到条目数为3) INOUT参数是IN和OUT参数的组合。这意味着调用程序可以传递参数，并且存储过程可以修改INOUT参数并将新值传递回调用程序 123456789101112delimiter //create procedure inout_test(inout total int, in inc int(4))beginset total = total + inc; (这里inout可以赋值,也可以调用)end //delimiter ;set @total = 0;call test.inout_test(@total,1); call test.inout_test(@total,2);call test.inout_test(@total,3);select @total; (输出为6) 语法IF123if expression then statements;end if; 12345if expression then statements;else statements;end if; 1234567if expression then statements;elseif expression then statements;else statements;end if; case123456CASE case_expression WHEN when_expression_1 THEN commands WHEN when_expression_2 THEN commands ... ELSE commandsEND CASE; while循环123WHILE expression DO statementsEND WHILE repeat循环1234REPEAT statements;UNTIL expressionEND REPEAT 先执行statements,然后判断expression. 如果expression表达式计算结果为false就一直重复. 注意until后面的expression是没有; LOOP，LEAVE和ITERATE语句12345678910111213141516171819202122CREATE PROCEDURE test_mysql_loop() BEGIN DECLARE x INT; DECLARE str VARCHAR(255); SET x = 1; SET str = ''; loop_label: LOOP IF x &gt; 10 THEN LEAVE loop_label; END IF; SET x = x + 1; IF (x mod 2) THEN ITERATE loop_label; ELSE SET str = CONCAT(str,x,','); END IF; END LOOP; SELECT str;END; 以上存储过程仅构造具有偶数字符串的字符串，例如2,4,6等。 在LOOP语句之前放置一个loop_label循环标签。 如果x的值大于10，则由于LEAVE语句，循环被终止。 如果x的值是一个奇数，ITERATE语句忽略它下面的所有内容，并开始一个新的迭代。 如果x的值是偶数，则ELSE语句中的块将使用偶数构建字符串。 结果2,4,6,8,10, 游标要处理存储过程中的结果集，请使用游标。游标允许您迭代查询返回的一组行，并相应地处理每行。 MySQL游标为只读，不可滚动和敏感。 只读：无法通过光标更新基础表中的数据。 不可滚动：只能按照SELECT语句确定的顺序获取行。不能以相反的顺序获取行。 此外，不能跳过行或跳转到结果集中的特定行。 敏感：有两种游标：敏感游标和不敏感游标。敏感游标指向实际数据，不敏感游标使用数据的临时副本。敏感游标比一个不敏感的游标执行得更快，因为它不需要临时拷贝数据。但是，对其他连接的数据所做的任何更改都将影响由敏感游标使用的数据，因此，如果不更新敏感游标所使用的数据，则更安全。 MySQL游标是敏感的。 可以再存储过程, 存储函数, 触发器中使用mysql 123456789101112131415161718192021222324252627282930313233delimiter $$create procedure get_name_list(inout name_list varchar(255))begin declare v_finished integer default 0; (声明一个表示,是否完成) declare v_name varchar(100) default &quot;&quot;; (用来保存遍历的值) declare name_cursor cursor for select name from user; (建立游标, 内容是所有user表的name字段) declare continue handler for (游标无法获取到数据会抛出异常) not found set v_finished = 1; (如果游标到尾无法获取数据时将标识设置为1) open name_cursor; (开启游标) get_name: loop (循环) fetch name_cursor into v_name; (读取游标的内容并将游标移动到下一行, into到v_name) if v_finished = 1 then leave get_name; (如果标识为1就跳出循环) end if; set name_list = concat(v_name,&quot;;&quot;,name_list);(设置name_list连接自身和游标遍历的值) end loop get_name; close name_cursor; (关闭游标)end $$delimiter ;set @name_list = &quot;&quot;;call get_name_list(@name_list);select @name_list; 异常处理声明异常处理程序, 可以使用declare action handler for condition_value statement 如果条件的值与condition_value匹配，则MySQL将执行statement，并根据该操作继续或退出当前的代码块。 操作(action)接受以下值之一： CONTINUE：继续执行封闭代码块(BEGIN ... END)。 EXIT：处理程序声明封闭代码块的执行终止。 condition_value指定一个特定条件或一类激活处理程序的条件。condition_value接受以下值之一： 一个MySQL错误代码。 标准SQLSTATE值或者它可以是SQLWARNING，NOTFOUND或SQLEXCEPTION条件，这是SQLSTATE值类的简写。NOTFOUND条件用于游标或SELECT INTO variable_list语句。 与MySQL错误代码或SQLSTATE值相关联的命名条件。 错误示例 错误了继续执行, 设置标识DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET has_error = 1; 错误回滚 12345DECLARE EXIT HANDLER FOR SQLEXCEPTIONBEGINROLLBACK;SELECT 'An error has occurred, operation rollbacked and the stored procedure was terminated';END; 光标到达最后一行不能后移了 DECLARE CONTINUE HANDLER FOR NOT FOUND SET no_row_found = 1; 程序如果发生重复的键错误，则会发出MySQL错误1062。 它发出错误消息并继续执行。 DECLARE CONTINUE HANDLER FOR 1062 SELECT 'Error, duplicate key occurred'; signal和esignalsignalsignal是向调用者返回错误或警告条件. 123SIGNAL SQLSTATE | condition_name;SET condition_information_item_name_1 = value_1, condition_information_item_name_1 = value_2, etc; 例子 12345678910111213141516171819202122DELIMITER $$CREATE PROCEDURE AddOrderItem(in orderNo int, in productCode varchar(45), in qty int,in price double, in lineNo int )BEGIN DECLARE C INT; SELECT COUNT(orderNumber) INTO C FROM orders WHERE orderNumber = orderNo; -- check if orderNumber exists IF(C != 1) THEN (请注意，45000是一个通用SQLSTATE值，用于说明未处理的用户定义异常。) SIGNAL SQLSTATE '45000' (引发SQLSTATE 45000的错误以及orders表中不存在订单号的错误消息。) SET MESSAGE_TEXT = 'Order No not found in orders table'; END IF; -- more code below -- ...END $$DELIMITER ; 存储函数存储的函数是返回单个值的特殊类型的存储程序。您使用存储的函数来封装在SQL语句或存储的程序中可重用的常用公式或业务规则。 存储函数可以在表达式中使用. 1234CREATE FUNCTION function_name(param1,param2,…) RETURNS datatype [NOT] DETERMINISTIC statements create function + 函数名称 + 参数(参数默认in类型, 不能指定) returns + 返回值类型 对于相同的输入参数，如果存储的函数返回相同的结果，这样则被认为是确定性的，否则存储的函数不是确定性的。必须决定一个存储函数是否是确定性的。 如果您声明不正确，则存储的函数可能会产生意想不到的结果，或者不使用可用的优化，从而降低性能。 将代码写入存储函数的主体中。 它可以是单个语句或复合语句。 在主体部分中，必须至少指定一个RETURN语句。RETURN语句用于返回一个值给调用者。 每当到达RETURN语句时，存储的函数的执行将立即终止。 123456789101112131415161718DELIMITER $$CREATE FUNCTION CustomerLevel(p_creditLimit double) RETURNS VARCHAR(10) DETERMINISTICBEGIN DECLARE lvl varchar(10); IF p_creditLimit &gt; 50000 THEN SET lvl = 'PLATINUM'; ELSEIF (p_creditLimit &lt;= 50000 AND p_creditLimit &gt;= 10000) THEN SET lvl = 'GOLD'; ELSEIF p_creditLimit &lt; 10000 THEN SET lvl = 'SILVER'; END IF; RETURN (lvl);END $$DELIMITER ; 12345SELECT customerName, CustomerLevel(creditLimit)FROM customersORDER BY customerName; 感谢易百","link":"/blog/2019/01/09/mysql-A3.%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"},{"title":"mysql-执行计划","text":"mysql执行计划介绍 mysql 提供了一个explain 命令, 他可以对查询语句进行分析, 并输出分析结果, 可以来看看. 使用很简单, 在select语句前面加上explain关键字就行了 输出格式explain输出格式为 123456789101112131415161718192021222324//SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.id: 1//SELECT 查询的类型.select_type: SIMPLE//查询的是哪个表table: user_info//匹配的分区partitions: NULL//join 类型type: const//此次查询中可能选用的索引(不一定真用到)possible_keys: PRIMARY//此次查询中确切使用到的索引.key: PRIMARY//使用到的索引字节数key_len: 8//哪个字段或常数与 key 一起被使用ref: const//显示此查询一共扫描了多少行. 这个是一个估计值.rows: 1//表示此查询条件所过滤的数据的百分比filtered: 100.00//额外的信息Extra: NULL 字段介绍select_type(重要)select_type 表示了查询的类型, 它的常用取值有: SIMPLE, 表示此查询不包含 UNION 查询或子查询, explain select * from tuser; PRIMARY, 表示此查询是最外层的查询, explain select (select name from tuser) from tuser ; UNION, 表示此查询是 UNION 的第二或随后的查询, explain select * from tuser where sex='1' union select * from tuser where sex='2'; DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询. explain select * from tuser where sex in (select sex from tuser where sex='1' union select sex from tuser where sex='2'); UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT, explain select * from tuser where id = (select max(id) from tuser); DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. explain select id,name,(select name from tdep a where a.id=b.dep) from tuser b; 最常见的查询类别应该是 SIMPLE 了, 比如当我们的查询没有子查询, 也没有 UNION 查询时, 那么通常就是 SIMPLE 类型 type(重要)type 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等. 性能排序从好到差: system，const，eq_ref，ref，fulltext，ref_or_null，unique_subquery，index_subquery，range，index_merge，index，ALL 最少要索引使用到range级别 system: 表中只有一行数据或者是空表. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可. 比如explain select * from user_info where id = 2 eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高. 比如EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询. 比如EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5 fulltext: 全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引 ref_or_null: 与ref方法类似，只是增加了null值的比较。实际用的不多 unique_subquery: 用于where中的in形式子查询，子查询返回不重复值唯一值 index_subquery: 用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重 range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 &gt;,&lt;,is null,between ,in ,like 操作中. index_merge: 表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所个索引，性能可能大部分时间都不如range index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据. index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. 比如EXPLAIN SELECT name FROM user_info. 我们查询的 name 字段恰好是一个索引, 因此我们直接从索引中获取数据就可以满足查询的需求了, 而不需要查询表中的数据. 因此这样的情况下, type 的值是 index, 并且 Extra 的值是 Using index ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免. 在全表扫描时, possible_keys 和 key 字段都是 NULL, 表示没有使用到索引, 并且 rows 十分巨大, 因此整个查询效率是十分低下的. key查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个 key_len表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.key_len 的计算规则如下: 字符串 char(n): n 字节长度 varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4 n + 2 字节. 数值类型: TINYINT: 1字节 SMALLINT: 2字节 MEDIUMINT: 3字节 INT: 4字节 BIGINT: 8字节 时间类型 DATE: 3字节 TIMESTAMP: 4字节 DATETIME: 8字节 字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性. 比如EXPLAIN SELECT * FROM order_info WHERE user_id &lt; 3 AND product_name = 'p1' AND productor = 'WHH' 从表 order_info 中查询指定的内容, 而我们从此表的建表语句中可以知道, 表 order_info 有一个联合索引: 1KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`) 不过此查询语句 WHERE user_id &lt; 3 AND product_name = 'p1' AND productor = 'WHH' 中, 因为先进行 user_id 的范围查询, 而根据 最左前缀匹配 原则, 当遇到范围查询时, 就停止索引的匹配, 因此实际上我们使用到的索引的字段只有 user_id, 因此在 EXPLAIN 中, 显示的 key_len 为 9. 因为 user_id 字段是 BIGINT, 占用 8 字节, 而 NULL 属性占用一个字节, 因此总共是 9 个字节. 若我们将user_id 字段改为 BIGINT(20) NOT NULL DEFAULT '0', 则 key_length 应该是8. 上面因为 最左前缀匹配 原则, 我们的查询仅仅使用到了联合索引的 user_id 字段, 因此效率不算高. 比如EXPLAIN SELECT * FROM order_info WHERE user_id = 1 AND product_name = 'p1' 这次的查询中, 我们没有使用到范围查询, key_len 的值为 161. 为什么呢? 因为我们的查询条件 WHERE user_id = 1 AND product_name = 'p1' 中, 仅仅使用到了联合索引中的前两个字段, 因此 keyLen(user_id) + keyLen(product_name) = 9 + 50 * 3 + 2 = 161 rows(重要)rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好. Extra(重要)EXplain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容: no tables used: 不带from字句的查询或者From dual查询 using filesort(重要): 排序或者分组没有使用索引, 建议优化去掉, 因为这样的查询 CPU 资源消耗大. Using index(重要): 查询时不需要回表查询&lt;1&gt;, 使用到了覆盖索引（Covering Index）性能不错 Using temporary: 查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 或者distinct去重, 查询效率不高, 建议优化. Using where(重要): 表示没有用到索引 Using index condition: 查询条件中分为限制条件和检查条件，5.6之前，存储引擎只能根据限制条件扫描数据并返回，然后server层根据检查条件进行过滤再返回真正符合查询的数据。5.6.x之后支持ICP(索引下推)特性，可以把检查条件也下推到存储引擎层，不符合检查条件和限制条件的数据，直接不读取，这样就大大减少了存储引擎扫描的记录数量 &lt;1&gt;回表就是聚簇索引中辅助索引取到主键key之后再用主键key去主键索引中找数据记录, 但是如果select的key刚好在辅助索引中就有这个字段的话, 是不需要回表操作","link":"/blog/2019/01/12/mysql-A4.explain%E5%91%BD%E4%BB%A4/"},{"title":"redis-内存模型","text":"介绍redis内存模型 redis内存模型123456789101112131415161718192021127.0.0.1:6379&gt; info memory# Memory# redis分配的内存总量, 包括虚拟内存(字节)used_memory:1201064used_memory_human:1.15M# 占操作系统的内存, 不包括虚拟内存(字节)used_memory_rss:1164136used_memory_rss_human:1.11Mused_memory_peak:1278072used_memory_peak_human:1.22Mtotal_system_memory:0total_system_memory_human:0Bused_memory_lua:37888used_memory_lua_human:37.00Kmaxmemory:0maxmemory_human:0Bmaxmemory_policy:noeviction# 内存碎片化比例, 如果小于0表示使用了虚拟内存, 就重启一下mem_fragmentation_ratio:0.97# 内存分配器mem_allocator:jemalloc-3.6.0 数据最主要部分, 这部分占用内存会统计在used_memory中.包括5中类型, 字符串,哈希, 列表, 集合, 有序集合.实际上redis内部, 每种类型可能有2中或者更多的内部编码实现. 进程redis主进程肯定需要占用内存, 如代码,常量池等. 这部分不是由jemalloc分配, 因此不会统计在used_memory_rss中. redis子进程也会占用内存, 如redis执行aof/rdb重写时创建的子进程.这部分不会统计在used_memory和used_memory_rss中. 缓冲内存包括客户端缓冲区, 复制挤压缓冲区, aof缓冲区等. 这部分有jemalloc分配, 因此会统计在used_memory中. 内存碎片如果对数据频繁更改, 而且数据之间大小相差很大, 就会导致redis释放的空间在物理内存中没有释放. 但redis又无法有效利用, 就形成内存碎片, 不会统计在used_memory中. 如果内存碎片很大, 可以通过安全重启减少碎片. 因为重启redis重新从备份的文件中读取数据, 内存会重排. 内存碎片redis内存分配器默认是jemalloc, 它是按照固定大小划分内存空间, 例如 8 字节、16 字节、32 字节、48 字节，… 2KB、4KB、8KB 等. 例如，Redis 申请一个20字节的空间保存数据，jemalloc就会分配32字节，此时，如果应用还要写入 10 字节的数据, Redis就不用再向操作系统申请空间了，因为刚才分配的32字节已经够用了，这就避免了一次分配操作。增删改会产生碎片. 查看碎片 12345678INFO memory# Memoryused_memory:1073741736 //实际申请使用的空间used_memory_human:1024.00Mused_memory_rss:1997159792 //实际分配给Redis的物理内存空间used_memory_rss_human:1.86G…mem_fragmentation_ratio:1.86 mem_fragmentation_ratio范围 大于1但小于1.5: 合理范围, 因为碎片化不可避免 大于1.5: 碎片率已经超过50%, 需要采取一些措施降低内存碎片率 小于1: 这里就表示出发swap, 要重视 解决方法: 重启redis 从4.0-RC3版本后有一个自动清理内存碎的方法, 主线程运行, 有阻塞风险 12//开启碎片自动清理config set activedefrag yes 同时满足两个条件才会自动清理: active-defrag-ignore-bytes 100mb:表示内存碎片的字节数达到100MB时 active-defrag-threshold-lower 10:表示内存碎片空间占操作系统分配给Redis的总空间比例达到10%时 为了尽可能减少碎片清理对Redis正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的CPU时间，而且还设置了两个参数，分别用于控制清理操作占用的CPU时间比例的上、下限，既保证清理工作能正常进行，又避免了降低Redis性能。这两个参数具体如下： active-defrag-cycle-min 25： 表示自动清理过程所用CPU时间的比例不低于25%，保证清理能正常开展； active-defrag-cycle-max 75：表示自动清理过程所用CPU时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。 redis缓冲区缓冲区作用是客户端发送操作命令的时候, 就会暂存客户端发送的命令. 这样就不会导致redis来不及处理而丢失数据. 其实除了输入有缓冲区, 输出也是有缓冲区, 先到都是先到缓冲区之后再处理. 缓冲区溢出情况? 写入了bigkey, 比如一下子写入了多个百万级别的集合类型数据 redis处理很慢, 导致缓冲区越堆积越多 查看缓冲区 12CLIENT LISTid=5 addr=127.0.0.1:50487 fd=9 name= age=4 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client 缓冲区信息关注点: 客户端与服务器连接的信息, 这里只有一个连接所以只显示了一个IP:端口 cmd: 客户端最新命令; qbuf: 缓冲区已使用大小; qbuf-free: 缓冲区未使用大小, 如果这个值很小就需要注意了 解决输入缓冲区溢出: 避免太多客户端连接redis服务, 在代码中缓冲区上限阈值是1GB, 就是客户端连接占用大于1GB可能崩溃. 这里没有参数去修改 避免写入bigkey, 避免redis主线程阻塞 输出缓冲区分两部分: 大小为16kb的固定缓冲区, 用来暂存OK响应和出错信息; 一个可以动态增加的缓冲区空间, 暂存响应结果解决输出缓冲区溢出: 服务器端返回bigkey的大量结果 MONITOR命令用来检测redis, 会持续检测各个命令操作. 但是也会持续占用输出缓冲区. 只在调试环境使用, 不要在生产使用(偶尔使用没问题). 设置缓冲区大小. 普通客户端: 12//normal 表示当前设置的是普通客户端, 0分别是缓冲区大小限制/缓冲区持续写入量限制/持续写入时间限制, 就是都不限制client-output-buffer-limit normal 0 0 0 订阅了Redis频道的订阅客户端, 一旦订阅的 Redis 频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以，订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。不过，如果频道消息较多的话，也会占用较多的输出缓冲区空间 12//pubsub表示订阅客户端, 输出缓冲区上限8MB, 超过关闭客户端连接; 连续60s对输出缓冲区写入超过2MB关闭客户端连接client-output-buffer-limit pubsub 8mb 2mb 60 主从使用缓冲区TODO","link":"/blog/2020/02/01/redis-1.%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"redis-大杂烩","text":"redis大杂烩 缓存和数据库不一致只读缓存: 先读取缓存中有没有, 有直接返回. 如果数据库更新了数据, 删除缓存. 下一次读取的时候没有数据, 先查询数据库, 并写入缓存中读写缓存: 同时修改数据库和缓存中的值. 同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致 异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了 缓存中有数据, 和数据库一致/缓冲中没有数据: 除了这种情况外其他都是缓冲和数据库不一致 读写数据不一致解决:删除缓存值或更新数据库失败而导致数据不一致, 你可以使用重试机制确保删除或更新操作成功 只读缓存有什么数据不一致的情况. 先删除缓存, 在更新数据库. 这时候A删除缓存后, 还没来得及更新数据库. 然后B读取缓存, 发现没有缓存有查询了旧数据之后更新成缓存, 最后A才更新数据库. 这样缓存就是旧数据 延迟双删1234567//先删除redis.delKey(X)//假设B这时候查询缓存没有数据, 然后去查询数据在放入缓存中db.update(X)//这里延迟就要是为了B可以查询数据然后放入缓存的时间, 只要放入了缓存, 之后再删除, 数据就是一致的Thread.sleep(N)redis.delKey(X) 缺点: 如果业务应用中读取数据库和写缓存的时间不好估算，那么延迟双删中的等待时间就不好设置 先更新数据库, 再删除缓存. A更新了数据库, 但是没有来得及删除缓存. B开始读取缓存, 就会读取到旧缓存. 其实一般删除缓存很快, 而且就算读取旧缓存也就是当时并发的B会读取, 其他的还是会读取到新缓存. 所以这种对业务影响比较小. 如果删除失败, 就消息队列重试删除 缓存雪崩/击穿/穿透雪崩: 大量缓存同时过期或者redis宕机解决: 过期时间加一个小的随机值, 服务降级/主从集群 击穿: 热点数据过期, 并发很大导致很多请求都进入数据库. 热点数据不设置过期时间 穿透: 本身就没有这个数据, 然后每次请求缓存没有, 在请求到数据库也没有. 下一次还是请求到数据库.解决: 缓存空值或缺省值/使用布隆过滤器/对于恶意请求的拦截 布隆过滤器一个很长的bit[]组成, 默认都是保存0. 然后来了一个值, 经过N次hash运算, 每次计算出的hash都放入对应位置并把值改为1. 比如现在进行三次hash计算, 分别放入了位置1,100,1000的位置, 值都是1. 然后我们判断的时候只需要hash N次, 看看位置都是1. 如果有一个位置为0, 表示肯定不存在. 如果全部都是1, 表示可能存在, 因为可能是巧合别的hash全部改为了1 缓存污染用的很少的缓存还是一直存在, 直到内存满了之后自动淘汰掉, 但是这样引入额外的时间开销, 影响性能. LRU(Least Recently Used)最近最少使用, 首先淘汰最长时间未被使用 LFU(Least Frequently Used)最近不经常使用, 首先淘汰一定时期内被访问次数最少 解决缓存污染:可以使用LFU Pika如果数据量很大, redis成本很高的话, 可以选择Pika. 基于SSD给Redis单实例进行扩容的技术方案 无锁原子操作如果库存减一, 先读取库存, 在减一, 写入库存缓存 解决: 使用多个操作实现的一个操作(单命令操作), 比如INCR/DECR命令 使用Lua脚本 分布式锁可以试试Etcd 单机式: https://github.com/JingRui-H/blog/blob/master/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/4.redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.md 优化删除可以用lua脚本先判断value是否一致, 再删除. redlock算法为了避免 Redis 实例故障而导致的锁无法工作的问题，Redis 的开发者 Antirez 提出了分布式锁算法 Redlock.是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败 事务 命令入队时就报错，会放弃事务执行，保证原子性 命令入队时没报错，实际执行时报错，不保证原子性 EXEC命令执行时实例故障，如果开启了AOF日志，可以保证原子性。 主从可能的坑主从数据不一致尽量保证网络快速, 主从库部署在同一个机房 开发一个外部程序来监控主从库间的复制进度。因为 Redis 的 INFO replication 命令可以查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从库的进度，然后，我们用 master_repl_offset 减去 slave_repl_offset，这样就能得到从库和主库间的复制进度差值了 读取到过期信息过期删除策略: 惰性删除 定期删除(默认100ms随机选出一定数量的数据) 如果从主库读取过期信息, 触发惰性删除. 但是从库本身不会执行删除操作. 在redis3.2版本之前, 会直接返回过期数据, redis3.2版本之后在从库上获取过期数据的时候虽然从库不会删除, 但是会返回空值. 如果设置过期时间因为主从同步被延后了也可能获取到过期数据, 这种情况建议使用EXPIREAT/PEXPIREAT命令, 使用具体的时间点过期 主从不合理配置导致服务器挂掉protected-mode: 作用是限定哨兵实例能否被其他服务器访问, yes只能部署服务器本地访问; no其他服务器也可以访问 如果哨兵部署在不同服务器并且设置为yes, 哨兵之间就无法通信. 123//设置为no, 并且bind其他哨兵的ip, 就可以保证安全性protected-mode nobind 192.168.10.3 192.168.10.4 192.168.10.5 cluster-node-timeout: Redis Cluster集群中为每个实例配置了一主一从模式时, 如果主从切换比较慢超过了这个超时时间, 就会导致这个节点挂掉. 所以建议这个时间配置大一点(比如10-20秒)","link":"/blog/2020/02/10/redis-10.%E5%85%B6%E4%BB%96/"},{"title":"mysql-慢日志","text":"mysql慢日志介绍 mysql查询慢日志(slow log) 可以吧超过参数long_query_time时间的所有SQL语句记录进来, 然后可以去针对性的优化SQL语句. long_query_time默认值是10s, 建议线上配置0.1~0.5s之间都是可以的. 慢日志保存在数据目录下, 为slow.log 查看12345678910 show variables like '%slow%'; +---------------------------+------------------------------------------------------------------+| Variable_name | Value |+---------------------------+------------------------------------------------------------------+| log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | C:\\environment\\mysql-5.7.23-winx64\\data\\DESKTOP-NNVGE9C-slow.log |+---------------------------+------------------------------------------------------------------+ slow_query_log 这边显示慢日志没有开启, 路径为slow_query_log_file显示的路径 这里开启我们使用修改my.ini文件的方式, 需要重启. Linux中是/etc/my.cnf 1234//慢日志, 设置时间为0.2sslow_query_log = ONslow_query_log_file = C://environment//mysql-5.7.23-winx64//logs//slow_query_log.txtlong_query_time = 0.2 重启service mysqld restart show VARIABLES like '%slow%';查看之后会发现慢日志已经开启. show VARIABLES like 'long_query_time';查看慢日志的限制时间 注意这边配置慢日志的路径的时间需要先把路径和文件先建立好, 之前一直没建立, 所以导致慢日志开启失败. 慢日志分析工具: mysqldumpslow是MySQL自带 percona-toolkit是一组高级命令行工具的集合，可以查看当前服务的摘要信息，磁盘检测，分析慢查询日志，查找重复索引，实现表同步等等","link":"/blog/2019/01/07/mysql-A1.%E6%85%A2%E6%97%A5%E5%BF%97/"},{"title":"redis-持久化","text":"介绍redis持久化 AOF(Append Only File)比如set testkey testvalue AOF文件 1234567*3 //当前命令有三个部分$3 //一共三个字节set$7testkey$9testvalue 先执行,之后记录log.好处: 为了避免检查开销, 如果先执行日志的话可能会记录错误日志. 执行完之后记录不会阻塞当前的写操作 缺点: 如果执行完还没记日志就直接宕机, 日志就丢失了 可能会给下一个操作带来阻塞风险, 因为aof日志也是在主线程中执行的 回写策略这里的缺点其实都和回写策略有关, aof配置项appendfsync的三个可选值 同步写回(Always): 每个写命令执行完, 立马同步地将日志写回磁盘 每秒写回(Everysec默认): 每个写命令执行完, 只是先把日志写到 AOF文件的内存缓冲区, 每隔一秒把缓冲区中的内容写入磁盘 操作系统控制的写回(No): 每个写命令执行完, 只是先把日志写到AOF文件的内存缓冲区, 由操作系统决定何时将缓冲区内容写回磁盘. 性能最高 重写机制aof会追加到越来越大, 就会有各种风险 文件系统本身对文件大小有限制 文件太大, 追加命令效率会变慢 如果宕机需要恢复, 日志很大恢复很慢 Redis 根据数据库的现状创建一个新的AOF文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入 重写过程: 主线程fork出后台bgrewriteaof子进程. fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据 bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。 如果有新的操作进来, 会写入正在使用的aof文件中, 同时写日志到AOF重写缓冲中，等从内存拷贝的AOF重写日志生成好后再合并进去，生成完整的AOF重写日志 新的aof代替旧的 风险点: fork可能阻塞主线程, fork操作执行时，内核需要给子进程拷贝主线程的页表。如果主线程的内存大，页表也相应大，拷贝页表耗时长，会阻塞主线程。 如果重写的时候来了写入或更新bigkey, 那么主线程需要申请内存空间来保存这个数据, 可能会阻塞主线程. RDB问题: 对那些数据做快照 快照时, 会阻塞主线程吗 redis提供了两个命令来生成RDB文件 save：在主线程中执行，会导致阻塞 bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，这也是Redis RDB文件生成的默认配置。 自动触发: 123save 900 1 # 表示900 秒内如果至少有 1 个 key 的值变化，则触发RDBsave 300 10 # 表示300 秒内如果至少有 10 个 key 的值变化，则触发RDBsave 60 10000 # 表示60 秒内如果至少有 10000 个 key 的值变化，则触发RDB 生成RDB过程: 主线程fork生成bgsave子进程, 可以共享主线程的所有内存数据 bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB文件 (写时复制)如果主线程此时有写入操作, 直接写入主线程. 主线程会把新数据或修改后的数据写到一个新的物理内存地址上，并修改主线程自己的页表映射. 所以，子进程读到的类似于原始数据的一个副本，而主线程也可以正常进行修改 多久快照一次呢? 在Redis 4.0中提出了一个混合使用AOF日志和内存快照的方法, 设置的参数是: aof-use-rdb-preamble yes 这样一来，快照不用很频繁地执行，这就避免了频繁fork对主线程的影响。而且，AOF日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。 建议: 数据不能丢失时，内存快照和AOF的混合使用是一个很好的选择 如果允许分钟级别的数据丢失，可以只使用 RDB 如果只用AOF，优先使用everysec的配置选项，因为它在可靠性和性能之间取了一个平衡","link":"/blog/2020/02/04/redis-4.%E6%8C%81%E4%B9%85%E5%8C%96/"},{"title":"redis-高级应用","text":"介绍redis高级应用 HyperLogLogRedis HyperLogLog 是用来做基数统计的算法。这里并不会存储元素的具体值，HyperLogLog只会根据输入元素来计算基数。HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。比如数据集是{1,2,2,3,3}，那么基数集就是{1,2,3}，基数是3。比如统计用户UV（unique visitor, 一天中有多少独立ip访问）数据，最适合用HLL来实现。 特点： 代码实现较难 能够使用极少的内存来统计巨量的数据，在 Redis 中实现的 HyperLogLog，只需要12K内存就能统计2^64个数据。 计数存在一定的误差，误差率整体较低。标准误差为 0.81% 。 误差可以被设置辅助计算因子进行降低。 命令1234567pfadd user:login:20200526 127.0.0.1 # 记录ip访问pfadd user:login:20200526 127.0.0.2pfcount user:login:20200526 # 返回2， 统计出来0526那一天UV是2pfadd user:login:20200526 127.0.0.2 127.0.0.3pfcount user:login:20200526 # 返回3， 虽然127.0.0.2访问两次，但是还是返回3 如果要统计的详细一点的，比如不仅仅统计天为单位， 还要统计一小时为单位。在保存一份pfadd user:login:2020052618 127.0.0.1记录是18：00的时候访问的。还可以合并 12345pfadd user:login:2020052618 127.0.0.1pfadd user:login:2020052619 127.0.0.2Pfcount user:login:2020052618 user:login:2020052619 # 统计这18：00到19：00的UVpfmerge user:login:2020052618-19 user:login:2020052618 user:login:2020052619 # 把两个key合并成一个独立的keypfcount user:login:2020052618-19 # 获取key的个数 BitmapSETBIT key offset value用来记录key偏移量上的一个状态。 key不存在的时候会新建 offset 参数必须大于或等于 0 ，小于 2^32 (bit 映射被限制在 512 MB 之内)。 value 只能支持0和1 一般用于用户签到，活跃用户，用户在线状态等记录状态的场景。 位图是支持按 bit 位来存储信息，可以用来实现 布隆过滤器（BloomFilter） Bloom Filter布隆过滤器一个很长的bit[]组成, 默认都是保存0. 然后来了一个值, 经过N次hash运算, 每次计算出的hash都放入对应位置并把值改为1. 比如现在进行三次hash计算, 分别放入了位置1,100,1000的位置, 值都是1. 然后我们判断的时候只需要hash N次, 看看位置都是1. 如果有一个位置为0, 表示肯定不存在. 如果全部都是1, 表示可能存在, 因为可能是巧合别的hash全部改为了1 优点：判断是否在数据集中的空间效率和查询时间远超一般算法。缺点：有一定的误识别率和删除困难(不能将要删除的1变为0，会影响其他数据)，百度Counting Bloom Filter 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930public class TestBloomFilter { private static int total = 1000000; private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total);// private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total, 0.001); public static void main(String[] args) { // 初始化1000000条数据到过滤器中 for (int i = 0; i &lt; total; i++) { bf.put(i); } // 匹配已在过滤器中的值，是否有匹配不上的 for (int i = 0; i &lt; total; i++) { if (!bf.mightContain(i)) { System.out.println(&quot;有坏人逃脱了~~~&quot;); } } // 匹配不在过滤器中的10000个值，有多少匹配出来 int count = 0; for (int i = total; i &lt; total + 10000; i++) { if (bf.mightContain(i)) { count++; } } System.out.println(&quot;误伤的数量：&quot; + count); }} 遍历这一百万个在过滤器中的数时，都被识别出来了。一万个不在过滤器中的数，误伤了320个，错误率是0.03左右。可以修改fpp 错误率(默认值为0.03)。错误率越大，所需空间和时间越小，错误率越小，所需空间和时间约大。 去重之类的应用都可以用bloomFilter， 比如缓存穿透(我认为不好用, 比如一个商品添加进入, 加入到布隆过滤其中)，爬虫过滤url，垃圾邮箱过滤，监控数据已经存在的就不在保存了 思考: 对于缓存穿透用布隆过滤器? 我觉得不好用. 比如一个商品添加进入, 然后加入布隆过滤器中. 这时候可以防止缓存穿透. 但是之后商品删除了呢? 布隆过滤器删除困难, 之后还是会造成这个商品的缓存穿透. GEO前面说到了Bitmap、HyperLogLog, GEO是用于位置信息服务（Location-Based Service，LBS）的应用. 需要记录用户的经纬度. 第一反应想到了hash去实现, key是用户的uid, value是经纬度. 但是我们还需要一个功能就是根据距离来排序, hash没有排序功能. 那就用sortedSet, key是地址, member是车辆ID, 权重是经纬度. 但是Sorted Set 元素的权重分数是一个浮点数（float 类型）, 而经纬度是两个值. 所以有了GEO GeoHash编码方法为了能高效地对经纬度进行比较，Redis 采用了业界广泛使用的 GeoHash 编码方法，这个方法的基本原理就是“二分区间，区间编码”。 计算的经纬度(116.37，39.86), 对于一个地理位置信息来说，它的经度范围是[-180,180], 现在经度是116.37, 然后进行五次分区 把最大的经度区间[-180,180]变成左分区[-180,0)和右分区[0,180]. 此时, 经度值116.37是属于右分区[0,180], 所以用1表示第一次二分区后的编码值 第二次[0,180], 分成[0,90)[90,180], 经度值116.37是属于右分区[90,180], 用1表示第一次二分区后的编码值 [90, 180] -&gt; [90,135)[135,180], 属于左分区用0表示 [90,135] -&gt; [90,112.5)[112.5,135], 属于右分区用1表示 [112.5,135] -&gt; [112.5, 123.75)[123.75,135], 属于右分区用1表示 获得经度值的5位编码值, 即11010 只是纬度的范围是[-90，90], 现在纬度是39.86, 同理获得10111. 最后将经纬度各自编码值11010和10111, 各自取第一位, 在各自取第二位, 组合获得1110011101. 这里获得的GeoHash编码就可以作为权重分数了. 怎么操作GEO类型呢? 12345//假设车辆ID是33,经纬度位置是（116.034579，39.030452）,我们可以用一个GEO集合保存所有车辆的经纬度, 集合key是cars:locationsGEOADD cars:locations 116.034579 39.030452 33//查找以这个经纬度为中心的5公里内的车辆信息GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10 pub/sub发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 开启两个cli， 一个先运行subscribe channel1订阅channel1频道， 另一个运行publish channel1 hahah对channel1发布消息。之后可以在第一个cli上面看到hahah pipeline pipeline选择客户端缓冲，multi选择服务端缓冲； 请求次数的不一致，multi需要每个命令都发送一次给服务端，pipeline最后一次性发送给服务端，请求次数相对于multi减少 multi/exec可以保证原子性，而pipeline不保证原子性 适用场景：批量发送短信等 Lua脚本可以保证原子性 事务Redis 提供的不是严格的事务，Redis 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。 详情看这个文章, 写的挺好https://www.cnblogs.com/yulinfeng/p/12363960.html 加点杂七杂八的东西 统计聚合统计统计手机每天新用户和第二天留存用户数用set记录用户信息, 然后使用统计命令类似 SUNIONSTORE user:id user:id user:id:20200803实现, 如果数据量很大建立在主从集群中用一个从库专门去复制Set 的差集、并集和交集的聚合计算 排序统计可以使用list和zset, 但是list使用LRANGE test1 1 10获取分页时, 万一又有了一条新数据, 那么第二页数据就会重复一条数据, 被顶下来.用zset的话使用ZRANGEBYSCORE test N-9 N, 按照权重自己分配, 就不会被顶下来了 二值状态统计比如只记录是否的数据, 签到/未签到等, 可以使用bitmap.bitmap本身就是用string类型作为底层数据结构实现的一种二值状态统计.String类型是会保存为二进制的字节数组，所以Redis就把字节数组的每个bit位利用起来，用来表示一个元素的二值状态。你可以把Bitmap看作是一个bit数组。 Bitmap 提供了 GETBIT/SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0 开始算的，也就是说 offset 的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数 123456//记录8月3号该用户签到SETBIT uid:sign:3000:202008 2 1 //检查该用户8月3日是否签到GETBIT uid:sign:3000:202008 2 //统计该用户在8月份签到次数BITCOUNT uid:sign:3000:202008 统计连续签到8天可以把8天的用户的bitmap都做与操作, 为1的用户就是连续签到8天的用户 物联网案例需要周期性的统计近万台设备的实时状态, 包括设备ID、压力、温度、湿度，以及对应的时间戳 可查询单条记录, hash存key, 时间戳:温度等 可以对某个范围内数据查询, sortedSet存key, 时间戳:温度等 可以聚合计算, 使用基于RedisTimeSeries模块保存时间序列数据 作为消息队列 直接使用List作为消息队列, 生产者LPUSH, 消费者RPOP. 使用while(1)循环(解决顺序消费) 消费者使用BRPOP读取, 阻塞式读取, 没有数据时自动阻塞. 有新数据就开始读取 消费者使用BRPOPLPUSH, 消费之后再把消息放入另一个list, 保证消息安全性(解决消息可靠性) 冥等性在队列中加入唯一标识, 业务处理就好了(解决重复消费) 还有一个问题就是, 消费者只能单个消费, 我们希望是一个消费组消费.Redis从5.0版本开始提供的Streams数据类型了, 除了上面的功能, 还支持消费组形式的消息读取 命令: XADD: 插入消息, 保证有序, 可以自动生成全局唯一ID XREAD: 用于读取消息, 可以按ID读取数据 XREADGROUP: 按消费组形式读取消息 XPENDING和XACK: XPENDING命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息, 而XACK命令用于向消息队列确认消息处理已完成 123//插入消息队列, *表示自动生成唯一标识, key是repo, value是5XADD mqstream * repo 5&quot;1599203861727-0&quot; //返回的1599203861727表示以毫秒为单位的当前服务器时间, 0表示编号第一条消息 读取mqstream队列消息, 从1599203861727-0开始, 没有消息的时候自动阻塞时间100毫秒 1234567891011XREAD BLOCK 100 STREAMS mqstream 1599203861727-01) 1) &quot;mqstream&quot; 2) 1) 1) &quot;1599274912765-0&quot; 2) 1) &quot;repo&quot; 2) &quot;3&quot; 2) 1) &quot;1599274925823-0&quot; 2) 1) &quot;repo&quot; 2) &quot;2&quot; 3) 1) &quot;1599274927910-0&quot; 2) 1) &quot;repo&quot; 2) &quot;1&quot; $表示读取最新消息, 这里阻塞10000毫秒(10s), 一直没有消息, 就返回空值 123XREAD block 10000 streams mqstream $(nil)(10.00s) 消费组消费 创建消费组XGROUP create mqstream group1 0, 组名为group1, 消费mqstream队列 让group1消费组里的消费者consumer1从mqstream中读取所有消息, 命令最后的参数”&gt;”, 表示从第一条尚未被消费的消息开始读取. 1234567891011121314XREADGROUP group group1 consumer1 streams mqstream &gt;1) 1) &quot;mqstream&quot; 2) 1) 1) &quot;1599203861727-0&quot; 2) 1) &quot;repo&quot; 2) &quot;5&quot; 2) 1) &quot;1599274912765-0&quot; 2) 1) &quot;repo&quot; 2) &quot;3&quot; 3) 1) &quot;1599274925823-0&quot; 2) 1) &quot;repo&quot; 2) &quot;2&quot; 4) 1) &quot;1599274927910-0&quot; 2) 1) &quot;repo&quot; 2) &quot;1&quot; 消费完了其他消费者就不能在消费了 123XREADGROUP group group1 consumer2 streams mqstream 01) 1) &quot;mqstream&quot; 2) (empty list or set) 想让消费者负载均衡读取消息 1234567891011121314151617XREADGROUP group group2 consumer1 count 1 streams mqstream &gt;1) 1) &quot;mqstream&quot; 2) 1) 1) &quot;1599203861727-0&quot; 2) 1) &quot;repo&quot; 2) &quot;5&quot;XREADGROUP group group2 consumer2 count 1 streams mqstream &gt;1) 1) &quot;mqstream&quot; 2) 1) 1) &quot;1599274912765-0&quot; 2) 1) &quot;repo&quot; 2) &quot;3&quot;XREADGROUP group group2 consumer3 count 1 streams mqstream &gt;1) 1) &quot;mqstream&quot; 2) 1) 1) &quot;1599274925823-0&quot; 2) 1) &quot;repo&quot; 2) &quot;2&quot; Streams会自动使用内部队列（也称为PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用XACK命令通知 Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给Streams发送XACK命令，消息仍然会留存。此时，消费者可以在重启后，用XPENDING命令查看已读取、但尚未确认处理完成的消息 例如，我们来查看一下 group2 中各个消费者已读取、但尚未确认的消息个数。其中，XPENDING 返回结果的第二、三行分别表示 group2 中所有消费者读取的消息最小 ID 和最大ID 12345678910XPENDING mqstream group21) (integer) 32) &quot;1599203861727-0&quot;3) &quot;1599274925823-0&quot;4) 1) 1) &quot;consumer1&quot; 2) &quot;1&quot; 2) 1) &quot;consumer2&quot; 2) &quot;1&quot; 3) 1) &quot;consumer3&quot; 2) &quot;1&quot; 如果我们还需要进一步查看某个消费者具体读取了哪些数据，可以执行下面的命令 123456XPENDING mqstream group2 - + 10 consumer21) 1) &quot;1599274912765-0&quot; 2) &quot;consumer2&quot; 3) (integer) 513336 4) (integer) 1 以看到，consumer2 已读取的消息的 ID 是 1599274912765-0 一旦消息 1599274912765-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除。当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了 1234 XACK mqstream group2 1599274912765-0(integer) 1XPENDING mqstream group2 - + 10 consumer2(empty list or set)","link":"/blog/2020/02/03/redis-3.%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/"},{"title":"redis-主从哨兵","text":"介绍redis主从哨兵模式 主从原理连接阶段： slave 节点启动时，会在自己本地保存master 节点的信息，包括ip port等。 slave节点内部有个定时任务 replicationCron，每隔1秒钟检查是否有新的master节点要连接和复制，如果有，就跟master节点建立一个Socket连接，如果连接成功，从节点为该Socket连接创建一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB命令，接收命令传播等。 当从节点变成了主节点的一个客户端之后，会给主节点发送 ping 请求。 数据同步阶段：4. slave节点第一次会执行全量复制，master节点通过bgsave命令在本地生成一个RDB数据快照文件，然后将RDB文件通过Socket连接传送给从节点，然后从节点先清空自身数据，然后使用接收到的RDB文件加载数据。 传送文件会有个超时时间，如果超时了会进行重连，可以设置大一点，防止超时循环重连，配置文件修改repl-timeout配置项设置。5. 在开始生成RDB文件时，master节点还会接收新的写命令，会把新的写命令缓存在内存中，在slave 节点通过RDB文件加载数据成功后，再把新的写命令发送给slave节点。6. 命令传播阶段：从节点数据同步完成后，可以开始对外提供读服务，主节点还是会继续执行写命令，然后异步将命令发送给slave 节点用于同步数据。是异步的，所以数据一致性必然会存在延时，与Zookeeper采用CP模式保证数据分布式一致性不一样，redis使用的是AP保证服务可用性。7. 如果从节点由于某些原因，比如宕机啥的，与主节点断开连接了一段时间，在重新连接后会使用增量复制来同步数据，主节点和从节点都有master_repl_offset命令来记录数据的偏移量，偏移量越大，数据越新，一般主节点都要大于等于从节点的偏移量，可以使用该偏移量来进行增量复制，增量的数据就是主节点与从节点直接的数据偏移量之差。 数据一致性延迟是不可避免的，只能通过优化网络来尽可能减少数据延时时间。repl-disable-tcp-nodelay no上面配置的作用是：当设置为yes时，TCP会对多个写命令TCP包进行合并一次性发送从而减少带宽，但是发送的频率会降低，从节点的数据延时会增加，一致性变差，具体发送频率与linux内核参数有关，默认为40ms，当设置为no时，TCP会立马把主节点的数据发送给从节点，带宽增加但延时变小。 一般来说，只有当应用对 Redis 数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为 yes；多数情况使用默认值 no。 主从库如何实现数据一致比如实例1（ip：172.16.19.3）和实例2（ip：172.16.19.5）我们在实例2上执行replicaof 172.16.19.3 6379，实例2就变成了实例1的从库，并从实例1上复制数据. Redis5.0之前使用slaveof 流程: 从库给主库发送psync ? -1命令. 其中?表示runID, 是每个redis实例启动都会自动生成的一个随机ID, 标识唯一. 因为不知道主库runID, 所以?. -1表示offset, 第一次复制为-1 主库响应从库FULLRESYNC [runID] [offset]返回给从库, 从库收到会记录这两个参数. 注意: 这里第一次复制是全量复制 主库执行bgsave, 将RDB文件发送给从库. 从库收到RDB之后会清空本地数据, 再加载RDB文件. 如果同步过程主库会有写操作, 会记录在replication buffer中 主库会把replication buffer记录的发送给从库 如果有多个从库怎么处理, 生成RDB和传输RDB很占用资源? 最好是主 -&gt; 从 -&gt; 从 那如果网络断了怎么处理数据同步呢? 在Redis 2.8之前是直接重新全量复制, 之后就是用增量复制方式同步. 当从库断连又重连之后，通过psync命令告诉主库自己的slave_repl_offset，然后主库根据自己的master_repl_offset和slave_repl_offset来判断是需要全量同步还是把两者之间的命令增量同步给从库（同步的方式就是通过主库与每个从库建立连接之后的这个所谓的replication buffer） repl_backlog_buffer是一个环形缓冲区, 主库会记录自己偏移量master_repl_offset, 从库会记录自己的偏移量slave_repl_offset. 所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。 如果不想全量复制, 可以设置repl_backlog_buffer大一点. 建议redis实例不要太大, 一般在几GB比较合适, 减少RDB生成传输和重新加载的开销. 缺点主从复制的不足： RDB文件过大时，同步耗时。 在一主一从或者一主多从情况下，如果主节点挂了，对外提供的写服务就是不可用了（从节点仍然可以对外提供读服务） 哨兵机制三大问题: 主库真的挂了吗？ 该选择哪个从库作为主库？ 怎么把新主库的相关信息通知给从库和客户端呢？ 哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知 监控: 周期性PING主从, 如果从没在规定时间响应标记为主观下线. 如果主没有在规定时间内响应, 先标记为主观下线. 然后哨兵集群的其他哨兵一起判断看看是不是主观下线, 如果大多数都是主观下线就会被标记为客观下线. 开始主从切换 选主: 先使用配置项down-after-milliseconds(表示主节点没有连接上从节点的最大时间), 如果断线次数超过10次, 就把不符合的从库筛选掉. 给剩余从库打分, 先根据从库优先级, 如果有优先级最高的, 直接变主库. 如果一样, 继续判断主从同步进度, 看从库偏移量slave_repl_offset哪个和主库偏移量master_repl_offset最接近. 如果还是有一样的, 就看从库ID最小的, ID是实例唯一标识 通知: 把新主库连接信息发给从库, 执行replicaof命令, 和新主库建立连接和复制. 同时会把新主库连接信息发送给客户端 如果哨兵挂了, 主从切换就不能用了. 这里就开始哨兵集群了.如果你部署过哨兵集群的话就会知道，在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的 IP 和端口，并没有配置其他哨兵的连接信息sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;,哨兵是基于pub/sub机制的哨兵集群组成, 通过Redis进行消息的发布和订阅, 在主从集群中，主库上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的. 哨兵又给主库发送INFO命令, 获得从库的连接信息, 就可以和从库建立连接进行监控了. 由哪个哨兵去切换主从呢? 哨兵选举TODO 总结：redis的投票机制 投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超时(cluster-node-timeout),认为当前master节点挂掉。 选举的依据依次是：网络连接正常-&gt;5秒内回复过INFO命令-&gt;10*down-after-milliseconds内与主连接过的-&gt;从服务器优先级-&gt;复制偏移量-&gt;运行id较小的。选出之后通过slaveif no ont将该从服务器升为新主服务器。 通过slaveof ip port命令让其他从服务器复制该信主服务器。 最后当旧主重新连接后将其变为新主的从服务器 选举的依据依次是：网络连接正常-&gt;5秒内回复过INFO命令-&gt;10*down-after-milliseconds内与主连接过的-&gt;从服务器优先级-&gt;复制偏移量-&gt;运行id较小的 Redis Sentinel的主要功能Sentinel的主要功能包括主节点存活检测、主从运行情况检测、自动故障转移（failover）、主从切换。Redis的Sentinel 最小配置是 一主一从。Redis的Sentinel 系统可以用来管理多个Redis服务器，该系统可以执行以下四个任务： 监控: Sentinel 会不断的检查 主服务器 和 从服务器 是否正常运行。 通知: 当被监控的某个 Redis 服务器出现问题，Sentinel 通过 API 脚本 向 管理员 或者其他的 应用程序 发送通知。 自动故障转移: 当主节点不能正常工作时，Sentinel会开始一次自动的故障转移操作，它会将与失效主节点是主从关系的其中一个从节点升级为新的主节点，并且将其他的从节点指向新的主节点。 配置提供者: 在Redis Sentinel模式下，客户端应用在初始化时连接的是Sentinel节点集合，从中获取主节点的信息。 节点数为什么redis哨兵集群只有2个节点无法正常工作？因为至少要两个哨兵才能选举出来哨兵故障准转移，过半原则。所以三个哨兵的时候挂掉一个才可以满足条件 123456789 +----+ | M1 | | S1 | +----+ |+----+ | +----+| R2 |----+----| R3 || S2 | | S3 |+----+ +----+ 主观下线和客观下线默认情况下，每个Sentinel节点会以每秒一次的频率对Redis节点和其它的Sentinel节点发送PING命令，并通过节点的回复 来判断节点是否在线。 主观下线: 适用于所有主节点和从节点。如果在 down-after-milliseconds 毫秒内，Sentinel没有收到目标节点的有效回复，则会判定该节点为主观下线。 客观下线: 适用于主节点。如果主节点出现故障，Sentinel节点会通过 sentinel is-master-down-by-addr 命令，向其它Sentinel节点询问对该节点的状态判断。如果超过 个数的节点判定主节点不可达，则该Sentinel节点会判断主节点为客观下线。 原理 每个Sentinel节点都需要定期执行以下任务：每个Sentinel以每秒钟一次的频率，向它所知的主服务器、从服务器以及其他Sentinel实例发送一个PING命令。 如果一个实例（instance）距离最后一次有效回复PING命令的时间超过down-after-milliseconds所指定的值，那么这个实例会被Sentinel标记为主观下线。 如果一个主服务器被标记为主观下线，那么正在监视这个主服务器的所有Sentinel节点，要以每秒一次的频率确认主服务器的确进入了主观下线状态。 如果一个主服务器被标记为主观下线，并且有足够数量的Sentinel（至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断，那么这个主服务器被标记为客观下线。 在一般情况下，每个Sentinel会以每10秒一次的频率，向它已知的所有主服务器和从服务器发送INFO命令。当一个主服务器被Sentinel标记为客观下线时，Sentinel向下线主服务器的所有从服务器发送INFO命令的频率，会从10秒一次改为每秒一次。 Sentinel和其他Sentinel协商主节点的状态，如果主节点处于SDOWN状态，则投票自动选出新的主节点。将剩余的从节点指向新的主节点进行数据复制。 当没有足够数量的Sentinel同意主服务器下线时，主服务器的客观下线状态就会被移除。当主服务器重新向Sentinel的PING命令返回有效回复时，主服务器的主观下线状态就会被移除。 搭建环境看https://juejin.im/post/5b7d226a6fb9a01a1e01ff64 缺点哨兵机制的不足： 主从切换时会丢失数据，主从复制是异步执行的，master节点写入数据后没来得及同步到slave节点就发送了故障，进行主从切换，该没有同步的数据就会丢失。而且主从切换的时候服务存在瞬断情况 只能单点写，没有解决水平扩容的问题。 这种主从模式所以节点保存的数据都是一样的，无法对数据进行水平扩容，如果数据量非常大，这个时候我们需要多个 master-slave 的 group，把数据分布到不同的 group 中。 脑裂主从集群有1个主库, 5个从库, 3个哨兵. 脑裂就是同时有两个主节点, 然后客户端往不同的主节点写入数据, 导致数据丢失. 原主库假故障导致脑裂, 假设原主库只是暂时异常无法响应哨兵心跳, 哨兵把主库判断为客观下线, 开始主从切换. 然后原主库恢复正常, 连接的客户端插入数据, 但是有一个从库又变成了主库. 然后哨兵就会让原主库执行slave of命令, 和新主库进行全量同步. 原主库会清空本地数据, 这时候主从切换期间保存的数据就丢失了 min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量 min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。 假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。 我给你的建议是，假设从库有K个，可以将 min-slaves-to-write 设置为 K/2+1（如果K等于1，就设为 1），将 min-slaves-max-lag 设置为十几秒（例如10～20s），在这个配置下，如果有一半以上的从库和主库进行的ACK消息延迟超过十几秒，我们就禁止主库接收客户端写请求。 集群通过对Redis进行分布式集群，可以达到以下效果： 水平扩展Redis的写性能，分布式集群实际上就是多个主从为一个组，然后多个组组成一个集群，每个组的master节点可以进行写操作，水平扩展了redis的写性能，这是哨兵机制做不到的。 水平扩展能存储的数据量，把所有数据通过分片技术分布在一个个Group里面，像上图有两个Group之间的数据时不一样的，但是同一Group的主从节点数据时一样的。这样就可以水平扩展数据。 分片技术有三种方案对数据进行分片： 在客户端分片，就是在客户端对数据的key进行hash，再取模，就能确定落到哪个Group里面，取数据的时候也用同样的算法路由到对应的Group进行取数据，这种方案分片逻辑集中在客户端，不依赖于中间件，分区逻辑可以自定义，但是不能动态增减服务器，也就是增加或减少Group就要修改相应的代码。 第二种思路就是把分片的代码抽取出来，做成一个公共服务，所有的客户端都连接到这个代理层。由代理层来实现请求和转发。典型的代理分区方案有 Twitter 开源的 Twemproxy 和国内的豌豆荚开源的 Codis。 第三种方案是通过服务端实现集群，在Redis3.0之后，推出了Redis Cluster用来解决分布式的需求，同时也可以实现高可用。跟 Codis 不一样，它是去中心化的，客户端可以连接到任意一个可用节点。 1/2方案都是对服务端透明的，也就是redis集群中的每个Group都不会知道其他Group的存在，只是有客户端或者中间件进行分片调配。 Redis Cluster数据分片的关键考虑问题： 数据怎么均匀的分配，也就是数据怎么均匀地分配到每个Group而不会出现某个Group的数据量很大，另一个却很小的情况。 客户端怎么访问到相应的节点和数据。 重新分片过程，怎么保证正常服务。 感谢： https://blog.csdn.net/qq_40837310/article/details/109224737","link":"/blog/2020/02/05/redis-5.%E4%B8%BB%E4%BB%8E+%E5%93%A8%E5%85%B5/"},{"title":"redis-优化","text":"介绍redis优化 redis变慢优化避免单线程阻塞客户端阻塞点因为多路复用, 一般网络IO不会是阻塞点. 但是因为单线程, 所以复杂度搞得增删改查会阻塞redis. 集合全量查询和聚合操作, 如HGETALL/SMEMBERS等操作和交/并/差集处理 bigKey删除, 因为释放内存操作系统需要把释放的内存块插入一个空闲内存块的链表, 以便后续进行管理和分配 清空数据库, 如FLUSHDB和FLUSHALL AOF日志同步写, 因为同步写会每一次写入磁盘 主从生成RDB传输给从库使用子线程, 所以不会阻塞主线程. 但是从库收到了RDB文件之后需要FLUSHDB清空数据库, 并且还需要把RDB加载到内存. 就会阻塞 RedisCluster需要进行负载均衡或者有实例增删时, 需要进行迁移. 不过哈希槽信息量不大, 而且迁移是渐进式的, 所以一般阻塞风险不大. 但是如果迁移的是bigkey的话, 就会造成主线程阻塞, 因为迁移是同步迁移 解决: 键值对删除, UNLINK命令(Redis4.0之后, 需要开启lazy-free惰性删除) 清空数据库, FLUSHDB ASYNC 和FLUSHALL AYSNC(Redis4.0之后) 全量查询使用SCAN命令分批读取, 客户端聚合计算 从库加载RDB文件, 建议把主库数据量大小控制在2-4GB左右 为什么CPU结构会影响Redis性能先说一下主流服务器CPU架构 一个CPU会有多个物理核, 每个物理核都可以运行应用程序 一个物理核拥有一级缓存(Level 1 cache), 包括一级指令缓存和一级数据缓存. 二级缓存, L1Cache和L2Cache只能被自己的物理核使用. 一般都是KB级别 不同的物理核之间会共享一个三级缓存(L3Cache), 一般都是几MB到几十MB, 当L1/L2没有数据缓存时, 可以访问L3, 尽可能避免访问内存 现在主流CPU中一个物理核中会有多个逻辑核, 共享使用L1,L2缓存 123456- 一个服务器 - 多个CPU(CPU Socket) - 一个CPU多个物理核 - 一个物理核多个逻辑核 - 一个逻辑核: L1 和 L2 - 多个物理核共享一个L3 然而应用程序可以再不同处理器上运行, redis可能在CPU Socket1运行一段时间之后, 然后被调度到Socket2上运行. 被调度到其他CPU之后访问内存需要使用远程内存访问 在多CPU架构下，一个应用程序访问所在Socket的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构） 所以如果要优化CPU, 就需要将redis绑定在一个物理核上. 因为被调度到其他CPU核上, L1 L2缓存需要重新从L3缓存中获取, 甚至内存中加载 12//将redis实例绑定在0号核上taskset -c 0 ./redis-server 优化网络性能, 需要把网络中断处理程序绑定和redis实例绑定在同一个核上, 就不用跨CPU Socket访问内存了. 这时候绑定哪一个CPU编号就需要注意了. 在CPU的NUMA架构下，对CPU核的编号规则，并不是先把一个CPU Socket中的所有逻辑核编完，再对下一个CPU Socket中的逻辑核编码，而是先给每个CPU Socket中每个物理核的第一个逻辑核依次编号，再给每个CPU Socket中的物理核的第二个逻辑核依次编号. 假设有2个CPU Socket，每个Socket 上有6个物理核，每个物理核又有2个逻辑核，总共24个逻辑核。我们可以执行lscpu命令，查看到这些核的编号： 1234567lscpuArchitecture: x86_64...NUMA node0 CPU(s): 0-5,12-17NUMA node1 CPU(s): 6-11,18-23... 缺点: 如果绑定在一个逻辑核上, 那么RDB和AOF开启子进程就会和主线程竞争资源 解决方案: 一个redis实例绑定一个物理核taskset -c 0,12 ./redis-server 优化redis源码 排查redis变慢变慢很可怕, 作为缓存会拖垮数据库, 作为事务会拖慢事务完成等. 是否变慢使用基于当前环境下的Redis基线性能 举个例子，比如说我们运行下面的命令，该命令会打印120秒内监测到的最大延迟。可以看到，这里的最大延迟是119微秒，也就是基线性能为119微秒。一般情况下，运行120秒就足够监测到最大延迟了，所以我们可以把参数设置为120。 123456789./redis-cli --intrinsic-latency 120Max latency so far: 17 microseconds.Max latency so far: 44 microseconds.Max latency so far: 94 microseconds.Max latency so far: 110 microseconds.Max latency so far: 119 microseconds.36481658 total runs (avg latency: 3.2893 microseconds / 3289.32 nanoseconds per run).Worst run took 36x longer than the average latency. (生产环境中,数据量比较大的时候内部延迟超过100也是很正常的，不会对用户的读写性能造成影响)。不过需要注意的是，内部延迟严重依赖于cpu的load，如果你的系统有其他应用在共享cpu，那么对不起，你的内部延迟一定很大。 一般来说，你要把运行时延迟和基线性能进行对比，如果你观察到的Redis运行时延迟是其基线性能的2倍及以上，就可以认定Redis变慢了。 如果你想了解网络对 Redis 性能的影响，一个简单的方法是用 iPerf 这样的工具，测量从 Redis 客户端到服务器端的网络延迟。如果这个延迟有几十毫秒甚至是几百毫秒，就说明，Redis 运行的网络环境中很可能有大流量的其他应用程序在运行，导致网络拥塞了。这个时候，你就需要协调网络运维，调整网络的流量分配了。 慢原因 慢命令. 使用复杂地O(1)最好, redis官方文档有每个命令复杂度. 比如返回SET所有成员不要使用SMEMBERS命令, 而是用SSCAN多次迭代返回, 避免一次返回大量数据. 排序, 交并差集可以在客户端完成. 不能使用KEYS 避免过期时间设置全都一样, 因为大批量一起过期删除会阻塞线程 AOF回盘策略no/everysec/always(回盘策略依赖文件系统的write/fsync两个系统调用完成, write写入内核缓冲区就返回, fsync写入磁盘返回). 尽量不要使用always. aof重写会调用子线程由fsync写入磁盘, 本来不会阻塞, 因为子线程. 但是如果子线程很慢, 主线程又发起了一次重写, 就会阻塞主线程. 如果允许一定数据丢失, 可以no-appendfsync-on-rewrite yes. aof重写不会进行fsync操作. 如果都要就换成固态硬盘吧 内存不够导致出发linux的swap, 建议增加机器内存或使用集群. 查看是否swap 1234567891011121314151617//查看redis进程号$ redis-cli info | grep process_idprocess_id: 5332//进入/proc下该进程目录中$ cd /proc/5332//每一行Size表示的是Redis实例所用的一块内存大小，而Size下方的Swap和它相对应，表示这块Size大小的内存区域有多少已经被换出到磁盘上了。如果这两个值相等，就表示这块内存区域已经完全被换出到磁盘了。$cat smaps | egrep '^(Swap|Size)'Size: 584 kBSwap: 0 kBSize: 4 kBSwap: 4 kBSize: 4 kBSwap: 0 kBSize: 462044 kBSwap: 462008 kBSize: 21392 kBSwap: 0 kB 内存大页, Linux内核从2.6.38开始支持内存大页机制,该机制支持2MB大小的内存页分配,而常规的内存页分配是按4KB的粒度来执行的. 虽然内存大页可以减少分配次数, 但是持久化的时候写时复制会拷贝一个内存页. 就算修改100B数据也会拷贝2MB内存大页. 1234//always表示内存大页启动了, never表示被禁止cat /sys/kernel/mm/transparent_hugepage/enabled//禁止内存大页echo never /sys/kernel/mm/transparent_hugepage/enabled 再加上上面两章一起就是全部阻塞点了 总结: 使用复杂度过高的命令或一次查询全量数据 操作bigkey 大量key集中过期 内存达到maxmemory 客户端使用短连接和Redis相连 当Redis实例的数据量大时，无论是生成RDB，还是AOF重写，都会导致fork耗时严重 AOF的写回策略为always，导致每个操作都要同步刷回磁盘 Redis实例运行机器的内存不足，导致swap发生，Redis需要到swap分区读取数据 进程绑定CPU不合理 Redis实例运行机器上开启了透明内存大页机制 网卡压力过大 检测慢查询使用慢查询日志需要设置两个参数: slowlog-log-slower-than：这个参数表示，慢查询日志对执行时间大于多少微秒的命令进行记录 slowlog-max-len(默认128, 建议1000)：这个参数表示，慢查询日志最多能记录多少条命令记录. 123456789//查看最近一条慢查询日志SLOWLOG GET 11) 1) (integer) 33 //每条日志的唯一ID编号 2) (integer) 1600990583 //命令执行时的时间戳 3) (integer) 20906 //命令执行的时长，单位是微秒 4) 1) &quot;keys&quot; //具体的执行命令和参数 2) &quot;abc*&quot; 5) &quot;127.0.0.1:54793&quot; //客户端的IP和端口号 6) &quot;&quot; //客户端的名称，此处为空 使用latency monitor监控工具要使用 latency monitor，首先要设置命令执行时长的阈值 12345678910//把latency monitor监控的命令执行时长阈值设为1000微秒config set latency-monitor-threshold 1000//查看最新和最大的超过阈值的延迟情况latency latest1) 1) &quot;command&quot; 2) (integer) 1600991500 //命令执行的时间戳 3) (integer) 2500 //最近的超过阈值的延迟 4) (integer) 10100 //最大的超过阈值的延迟 排查bigkey统计bigkey, 这个工具通过扫描数据库来查找, 所以对redis性能会有所影响, 建议在从库使用. 或者加上-i参数控制扫描时间. ./redis-cli --bigkeys -i 0.1表示每扫描100次暂停100毫秒（0.1 秒） 123456789101112131415161718192021./redis-cli --bigkeys-------- summary -------Sampled 32 keys in the keyspace!Total key length in bytes is 184 (avg len 5.75)//统计每种数据类型中元素个数最多的bigkeyBiggest list found 'product1' has 8 itemsBiggest hash found 'dtemp' has 5 fieldsBiggest string found 'page2' has 28 bytesBiggest stream found 'mqstream' has 4 entriesBiggest set found 'userid' has 5 membersBiggest zset found 'device:temperature' has 6 members//统计每种数据类型的总键值个数，占所有键值个数的比例，以及平均大小4 lists with 15 items (12.50% of keys, avg size 3.75)5 hashs with 14 fields (15.62% of keys, avg size 2.80)10 strings with 68 bytes (31.25% of keys, avg size 6.80)1 streams with 4 entries (03.12% of keys, avg size 4.00)7 sets with 19 members (21.88% of keys, avg size 2.71)5 zsets with 17 members (15.62% of keys, avg size 3.40) 缺点: 只能返回类中类型中最大的那个bigkey, 无法获得排在前N位的 这个只统计集合个数多少, 而不是实际占用内存量. 缓存淘汰机制先我们要知道如何设置redis最大缓存容量CONFIG SET maxmemory 4gb. 默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃 8中淘汰策略: 不进行数据淘汰 noeviction(3.0之后默认): 缓存写满之后直接报错 在设置过期时间数据中淘汰 volatile-random: 设置了过期时间的随机删除 volatile-ttl: 过期时间越早的优先删除 volatile-lru(3.0之前默认): LRU算法删除 volatile-lfu: LFU算法删除 所有数据中淘汰 allkeys-random: 所有键中随机删除 allkeys-lru: 所有键中LRU算法删除 allkeys-lfu: 所有键中LFU算法删除 一般LRU算法都是使用链表, 使用过的就被插入到head. 缓存满了从tail开始删除.但是这样需要用链表管理所有redis数据, 而且会带来很多链表移动操作, 会降低redis性能. 所以redis中是在redisObject中lru字段记录最近使用的时间戳. 淘汰的时候会随机选出N个数据作为候选集合, 然后把lru值最小的淘汰. 之后再次淘汰数据, redis需要挑选进入候选集合的lru必须小于之前候选集合的最小值 TODO 具体如何删除过期键","link":"/blog/2020/02/07/redis-7.%E4%BC%98%E5%8C%96/"},{"title":"redis-集群","text":"介绍redis集群 切片集群如果数据量很大, 使用RDB持久化的时候, fork是很慢的. 可以使用INFO命令查看latest_fork_usec(微妙). 这时候有一个比较好的解决方案, 就是切片集群/分片集群 这里官方在Redis3.0之后就出了Redis Cluster作为切片集群的解决方案. 数据分布Redis Cluster采用哈希槽(Hash Slot)来处理, 一个切片集群共有16384个哈希槽. 先是根据键值对的key按照CRC16算法计算出一个16bit的值, 再去对于16384取模, 就知道映射在哪一个哈希槽 在使用cluster create创建集群时, redis会自动把这些槽分布在集群实例上. 当然也可以使用cluster meet手动建立实例间的连接, 形成集群, 在使用cluster addslot指定每个实例上的哈希槽个数(手动分配哈希槽总数一定要为16384) 客户端定位数据数据所处的哈希槽是可以计算获得的, 这个计算是由客户端在发送请求时来执行的. 客户端和集群建立连接后, 实例就会把所有哈希槽分配信息发送给客户端. 但是开始的时候实例只知道自己分配的哈希槽, 因为Redis实例会把自己的哈希槽信息发给和它相连接的其它实例, 来完成哈希槽分配信息的扩散. 客户端收到哈希槽信息后, 就会吧哈希槽信息缓存在本地. 然后就可以直接发送请求了. 但是实例对应哈希槽关系是会变化的: 集群实例新增或者删除 为了负载均衡, redis需要把哈希槽所有实例重新分布一遍 如果实例对应哈希槽关系变化了, 客户端并不知道. 发送给了错误的实例, 实例就会MOVED响应, 告诉新实例的访问地址. 客户端会重定向到正确的实例, 同时也会更新本地缓存 12GET hello:key(error) MOVED 13320 172.16.19.5:6379 如果slot1迁移到slot2只完成了一半, 这时候访问的是前移到了slot2的数据, 就不能返回move响应了. 因为这样后续还没迁移的就会直接请求到slot2. 这时候会响应(error) ASK 13320 172.16.19.5:6379, 表示哈希槽正在迁移, 目前请求的key在这个ip上, 然后客户端需要给slot2发送ASKING命令请求允许去获取数据, 接着在去发送GET请求获取数据. 这里是不会更新客户端缓存的 codis VS redis cluster codis server: 这是进行了二次开发的Redis实例，其中增加了额外的数据结构，支持数据迁移操作，主要负责处理具体的数据读写请求。 codis proxy：接收客户端请求，并把请求转发给codis server。 Zookeeper集群：保存集群元数据，例如数据位置信息和codis proxy信息。 codis dashboard 和 codis fe：共同组成了集群管理工具。其中，codis dashboard 负责执行集群管理工作，包括增删codis server、codis proxy和进行数据迁移。而codis fe负责提供dashboard的Web操作界面，便于我们直接在Web界面上进行集群管理。 gossip协议Cluster中的每个节点都维护一份在自己看来当前整个集群的状态，主要包括： 当前集群状态 集群中各节点所负责的slots信息，及其migrate状态 集群中各节点的master-slave状态 集群中各节点的存活状态及不可达投票 基于Gossip协议当集群状态变化时，如新节点加入、slot迁移、节点宕机、slave提升为新Master，我们希望这些变化尽快的被发现，传播到整个集群的所有节点并达成一致。节点之间相互的心跳（PING，PONG，MEET）及其携带的数据是集群状态传播最主要的途径。 Redis 集群是去中心化的，彼此之间状态同步靠 gossip 协议通信，集群的消息有以下几种类型： Meet 通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。 Ping 节点每秒会向集群中其他节点发送 ping 消息，消息中带有自己已知的两个节点的地址、槽、状态信息、最后一次通信时间等。 Pong 节点收到 ping 消息后会回复 pong 消息，消息中同样带有自己已知的两个节点信息。 Fail 节点 ping 不通某节点后，会向集群所有节点广播该节点挂掉的消息。其他节点收到消息后标记已下线。 由于 gossip 协议对服务器时间的要求较高，否则时间戳不准确会影响节点判断消息的有效性。另外节点数量增多后的网络开销也会对服务器产生压力，同时结点数太多，意味着达到最终一致性的时间也相对变长，因此官方推荐最大节点数为1000左右 基于Gossip协议的故障检测集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此交换各个节点状态信息，检测各个节点状态：在线状态、疑似下线状态PFAIL、已下线状态FAIL。 自己保存信息：当主节点A通过消息得知主节点B认为主节点D进入了疑似下线(PFAIL)状态时,主节点A会在自己的clusterState.nodes字典中找到主节点D所对应的clusterNode结构，并将主节点B的下线报告添加到clusterNode结构的fail_reports链表中，并后续关于结点D疑似下线的状态通过Gossip协议通知其他节点。 一起裁定：如果集群里面，半数以上的主节点都将主节点D报告为疑似下线，那么主节点D将被标记为已下线(FAIL)状态，将主节点D标记为已下线的节点会向集群广播主节点D的FAIL消息，所有收到FAIL消息的节点都会立即更新nodes里面主节点D状态标记为已下线。 最终裁定：将 node 标记为 FAIL 需要满足以下两个条件：有半数以上的主节点将 node 标记为 PFAIL 状态。当前节点也将 node 标记为 PFAIL 状态。 也就是说当前节点发现其他结点疑似挂掉了，那么就写在自己的小本本上，等着通知给其他好基友，让他们自己也看看，最后又一半以上的好基友都认为那个节点挂了，并且那个节点自己也认为自己挂了，那么就是真的挂了，过程还是比较严谨的。","link":"/blog/2020/02/06/redis-6.%E9%9B%86%E7%BE%A4/"},{"title":"redis-多路复用","text":"介绍redis多路复用 redis是单线程吗?Redis是单线程，主要是指Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程。但Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。 那为什么不用多线程呢? 因为多线程面临共享资源并发控制的问题, 比如两个线程一起去操作list的lpush/lpop, 那么就变成了粗粒度串行. 如果要细粒度串行就需要处理很多线程安全问题. 性能瓶颈: 因为单线程, 所以任何耗时操作都算. 比如bigkey/全量返回等 那为什么redis的单线程模式这么快? redis大部分操作都是内存上完成的, 再加上采用了高效的数据结构, 比如哈希表和跳表 多路复用机制 Redis单线程处理IO请求性能瓶颈主要包括2个方面： 任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种： 操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时； 使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据； 大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长； 淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长； AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能； 主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久； 并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。 针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。 针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的 redis6.0新特性redis6.0多线程: 之前虽然AOF重写/快照生成/异步删除等都是多线程处理. 但是从网络IO处理到实际读写命令处理都是单线程处理的. 现在网络IO处理也改为多线程处理, 而实际读写命令处理依旧是单线程. redis6.0主线程和IO线程协作: 首先，主线程负责接收建立连接请求。当有客户端请求和实例建立 Socket 连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把 Socket 连接分配给 IO 线程。 主线程一旦把 Socket 分配给 IO 线程，就会进入阻塞状态，等待 IO 线程完成客户端请求读取和解析。因为有多个 IO 线程在并行处理，所以，这个过程很快就可以完成。 等到 IO 线程解析完请求，主线程还是会以单线程的方式执行这些命令操作 当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待 IO 线程把这些结果回写到 Socket 中，并返回给客户端。 ``//表示启用多线程, 默认关闭的io-threads-do-reads yes//线程数小于redis的cpu个数, 比如8核建议配置6个IO线程io-threads 6 12如果你在实际应用中，发现Redis实例的CPU开销不大，吞吐量却没有提升，可以考虑使用Redis 6.0的多线程机制，加速网络处理，进而提升实例的吞吐量。 多路复用我们经常用的IO是BIO(blocking I/O), 在Java中的NIO(非阻塞I/O, New I/O) 底层是通过多路复用I/O模型实现的. 而现实的场景也是诸如netty，redis，nginx，nodejs都是采用的多路复用I/O模型. 多路: 多个客户端连接（连接就是套接字描述符） 复用: 使用单进程就能够实现同时处理多个客户端的连接 其发展可以分select-&gt;poll-&gt;epoll三个阶段来描述. select就是轮询，在Linux上限制个数一般为1024个 poll解决了select的个数限制，但是依然是轮询 epoll解决了个数的限制，同时解决了轮询的方式 select函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。select具有良好的跨平台支持，其缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024 poll改变了文件描述符集合的描述方式，使用了pollfd结构而不是select的fd_set结构，使得poll支持的文件描述符集合限制远大于select的1024 下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。!image 为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。那么，回调机制是怎么工作的呢？其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。","link":"/blog/2020/02/08/redis-8.%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"title":"springAware源码","text":"Aware接口可以感知bean，实现了对应接口就可以获取对应bean 总结内部存在两种方式执行Aware： 通过直接执行的方式，执行invokeAwareMethods的一些基础接口方法。 通过ApplicationContextAwareProcessor间接执行更高级的Aware实现类。 invokeAwareMethods AbstractAutowireCapableBeanFactory#doCreateBean AbstractAutowireCapableBeanFactory#initializeBean 调用了invokeAwareMethods(beanName, bean);方法 12345678910111213141516private void invokeAwareMethods(String beanName, Object bean) { if (bean instanceof Aware) { if (bean instanceof BeanNameAware) { ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanClassLoaderAware) { ClassLoader bcl = getBeanClassLoader(); if (bcl != null) { ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); } } if (bean instanceof BeanFactoryAware) { ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); } }} ApplicationContextAwareProcessorApplicationContextAwareProcessor是在refresh方法的prepareBeanFactory中添加的beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Override@Nullablepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { if (!(bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)){ return bean; } AccessControlContext acc = null; if (System.getSecurityManager() != null) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; { invokeAwareInterfaces(bean); return null; }, acc); } else { invokeAwareInterfaces(bean); } return bean;}private void invokeAwareInterfaces(Object bean) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); }}","link":"/blog/2021/05/09/spring-6.aware/"},{"title":"springboot自动装配使用","text":"自定义spring自动加载 @Import只需要@Import写入一个Enable**注解，之后就可以直接使用默认配置了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Target({ ElementType.TYPE })@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import({ SwaggerAutoConfiguration.class })public @interface EnablePiscesSwagger2 {}@Data@ConfigurationProperties(&quot;swagger&quot;)public class SwaggerProperties { /** * 是否开启swagger */ private Boolean enabled; /** * swagger会解析的包路径 **/ private String basePackage = &quot;&quot;; ...}@Configuration@EnableSwagger2@EnableAutoConfiguration@ConditionalOnProperty(name = &quot;swagger.enabled&quot;, matchIfMissing = true)public class SwaggerAutoConfiguration { /** * 默认的排除路径，排除Spring Boot默认的错误处理路径和端点 */ private static final List&lt;String&gt; DEFAULT_EXCLUDE_PATH = Arrays.asList(&quot;/error&quot;, &quot;/actuator/**&quot;); private static final String BASE_PATH = &quot;/**&quot;; @Bean @ConditionalOnMissingBean public SwaggerProperties swaggerProperties() { return new SwaggerProperties(); } @Bean public Docket api(SwaggerProperties swaggerProperties) { return new Docket(DocumentationType.SWAGGER_2).host(swaggerProperties.getHost()) .apiInfo(apiInfo(swaggerProperties)).globalOperationParameters(pars).select() .apis(RequestHandlerSelectors.basePackage(swaggerProperties.getBasePackage())) .paths(Predicates.and(Predicates.not(Predicates.or(excludePath)), Predicates.or(basePath))).build() .securitySchemes(Collections.singletonList(securitySchema())) .securityContexts(Collections.singletonList(securityContext())).pathMapping(&quot;/&quot;); }} 使用spring.factories文件比如resources/META-INF/spring.factories中添加 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ cn.pisces.cloud.common.data.cache.RedisTemplateConfig 123456789101112131415161718@EnableCaching@Configuration@AllArgsConstructor@AutoConfigureBefore(RedisAutoConfiguration.class)public class RedisTemplateConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new JdkSerializationRedisSerializer()); redisTemplate.setHashValueSerializer(new JdkSerializationRedisSerializer()); redisTemplate.setConnectionFactory(redisConnectionFactory); return redisTemplate; }} Condition配置比如 12345//配置文件中test.enable为true加载，不存在默认true@Configuration@ConditionalOnProperty(value = &quot;test.enable&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)public class TestConfiguration {} @ConditionalOnProperty：配置文件 @ConditionalOnBean({ RedisConnectionFactory.class })：RedisConnectionFactory存在上下文中才会配置 @ConditionalOnMissingBean：不存在才配置 @ConditionalOnClass、@ConditionalOnMissingClass @ConditionalOnExpression(value = &quot;${a.enable:true} and ${b.enable:true}&quot;)：多个配置项符合条件 @ConditionalOnSingleCandidate @ConditionalOnResource(resources = &quot;/logback.xml&quot;)：我们要查找的bean依赖指定资源是否存在于classpath @ConditionalOnJndi：只有指定的资源通过 JNDI 加载后才加载 bean @ConditionalOnJava：只有运行指定版本的 Java 才会加载 Bean @ConditionalOnWebApplication、@ConditionalOnNotWebApplication：是否在web/非web情况下加载该配置 @ConditionalOnCloudPlatform：只有运行在指定的云平台上才加载指定的 bean","link":"/blog/2019/10/20/springboot-%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E4%BD%BF%E7%94%A8/"},{"title":"zookeeper-集群部署","text":"介绍zookeeper集群部署 一定要配置奇数?Zookeeper集群部署并非一定需要奇数台服务器，任意台Zookeeper服务器都能部署且能够正常运行。 一个Zookeeper集群如果要对外提供可用的服务，那么集群中必须要有过半的机器正常工作并且彼此之间能够正常通信。基于这个特性，如果想搭建一个能够允许N台机器挂掉的集群，那么就需要部署一个由2XN+1台服务器构成的Zookeeper集群。因此，一个由5台机器构成的Zookeeper集群，能够在挂掉2台机器后依然正常工作，而如果是一个由6台服务器构成的Zookeeper集群，同样只能够挂掉2台机器，因为如果挂掉3台，剩下的机器就无法实现过半了。 因此，从上面的讲解中，我们可以看出，对于一个由6台服务器组成的Zookeeper集群来说，和一个由5台服务器构成的Zookeeper集群相比，其在容灾能力上没有任何明显的提升。基于这个原因，Zookeeper集群通常设计部署成奇数台服务器即可。 docker宿主机上创建相应目录12345678910mkdir -p /opt/data/zk1/datamkdir -p /opt/data/zk2/datamkdir -p /opt/data/zk3/datamkdir -p /opt/data/zk1/confmkdir -p /opt/data/zk2/confmkdir -p /opt/data/zk3/conf将zookeeper-3.4.11.tar.gz，解压出zoo_sample.cfg,并重命名为zoo.cfg将zoo.cfg传到/opt/data/zk1/conf,/opt/data/zk1/conf,/opt/data/zk1/conf目录下 创建myid文件分别在/opt/data/zk1/data,/opt/data/zk2/data,/opt/data/zk3/data目录下创建myid文件，并写入相应的id 123cd /opt/data/zk1/data/ &amp;&amp; echo 1 |tee myidcd /opt/data/zk2/data/ &amp;&amp; echo 2 |tee myidcd /opt/data/zk3/data/ &amp;&amp; echo 3 |tee myid zoo.cfg配置123456789101112131415161718192021222324252627282930313233# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/datadataLogDir=/datalog# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1=192.168.56.101:2881:3881server.2=192.168.56.101:2882:3882server.3=192.168.56.101:2883:3883 启动12345docker run --name zk1 --net host --restart always -d -v/opt/data/zk1/data:/data -v /opt/data/zk1/conf/zoo.cfg:/conf/zoo.cfg -p 2181:2181 -p 2881:2881 -p 3881:3881 zookeeperdocker run --name zk2 --net host --restart always -d -v/opt/data/zk2/data:/data -v /opt/data/zk2/conf/zoo.cfg:/conf/zoo.cfg -p 2182:2182 -p 2882:2882 -p 3882:3882 zookeeperdocker run --name zk3 --net host --restart always -d -v/opt/data/zk3/data:/data -v /opt/data/zk3/conf/zoo.cfg:/conf/zoo.cfg -p 2183:2183 -p 2883:2883 -p 3883:3883 zookeeper docker-compose直接使用docker-compose.yml 12345678910111213141516171819202122232425262728293031version: '2'services: zoo1: image: zookeeper restart: always container_name: zoo1 ports: - &quot;2181:2181&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper restart: always container_name: zoo2 ports: - &quot;2182:2181&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper restart: always container_name: zoo3 ports: - &quot;2183:2181&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 之后 docker-compose up -d 验证zoo1 docker exec -it zoo1 bash 12345678910111213bash-4.4# echo stat | nc 127.0.0.1 2181Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMTClients: /127.0.0.1:39105[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x0Mode: followerNode count: 4 zoo2 docker exec -it zoo2 bash 12345678910111213bash-4.4# echo stat | nc 127.0.0.1 2181Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMTClients: /127.0.0.1:42773[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x0Mode: followerNode count: 4 zoo3 docker exec -it zoo3 bash 1234567891011121314bash-4.4# echo stat | nc 127.0.0.1 2181Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMTClients: /127.0.0.1:37405[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x100000000Mode: leaderNode count: 4Proposal sizes last/min/max: -1/-1/-1","link":"/blog/2018/02/08/zookeeper-2.%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"title":"JPA基础","text":"新进了一家公司, 一进去发现里面用的SpringDataJpa. 虽然以前学过hibernate, 但是早就忘了, 还是赶紧学了起来. 感觉spring系列搭配起来感觉很好.开始吧! 栗子 idea建立项目, new Product -&gt; Spring Initialize -&gt; Next -&gt; 选择Web,JPA,MySQL -&gt; Next....Finish 配置文件application.properties 12345678# 注意这里连接需要添加编码, 这样生成的表才会默认utf8spring.datasource.url=jdbc:mysql://localhost:3306/db_example?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=falsespring.datasource.username=rootspring.datasource.password=root# 生成表策略spring.jpa.properties.hibernate.hbm2ddl.auto=update# 显示sql语句hibernate.show_sql=true DAO –&gt; public interface UserRepository extends JpaRepository&lt;User,Integer&gt;{} Entity 123456789101112@Entity@Tablepublic class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String name; private String email; ...get/set} 运行的时候就会自动在数据库中生成表了. 可能生成的表编码不支持utf8, 用的是mysql默认的编码. 建立MySQL5DialectUTF8 1234567public class MySQL5DialectUTF8 extends MySQL5InnoDBDialect { @Override public String getTableTypeString() { return &quot; ENGINE=InnoDB DEFAULT CHARSET=utf8&quot;; }} 在配置一下spring.jpa.properties.hibernate.dialect=com.example.springdatajpa.MySQL5DialectUTF8 之后直接userRepository.save就是插入或者更新表, delete, find*等等方法. 点进去看方法就好了 分页PageRequest.of() 排序new Sort(Sort.Direction.DESC,&quot;id&quot;) 介绍自动生成表策略 create 每次加载Hibernate时都会删除上一次生成的表，然后重新生成新表，即使两次没有任何修改也会这样执行，这就导致每次启动都是一个新的数据库，也是导致数据丢失的重要原因 create-drop 每次加载Hibernate时都会生成表，但当SessionFactory关闭时，所生成的表将自动删除 update：最常用的属性值，第一次加载Hibernate时创建数据表（前提是需要先有数据库），以后加载HIbernate时只会根据model更新，即使model已经删除了某些属性，数据表也不会随之删除字段 validate：每次加载Hibernate时都会验证数据表结构，只会和已经存在的数据表进行比较，根据model修改表结构，但不会创建新表 查询方法策略设置通过@EnableJpaRepositories(queryLookupStrategy=QueryLookupStrategy.Key.CREATE_IF_NOT_FOUND)可以配置方法的查询策略，其中QueryLookupStrategy.Key的值一共有三个 CREATE：直接根据方法名进行创建 USE_DECLARED_QUERY：声明方式创建,@Query CREATE_IF_NOT_FOUND(缺省值), 先找@query,没有再用方法名 @Query &gt; @NameQuery &gt; 方法定义查询 查询@Query查询12@Query(&quot;select u from User u where u.name = ?1&quot;)User FindByName(String name); 其中?1代表第一个参数 如果是like查询需要where u.name like %?1 还可以使用原始Sql, @query(value=&quot;select * from users where name=?1&quot;,nativeQuery=true) , 注意nativeQuery不支持Sort参数排序 原生排序应该这样 12@query(value=&quot;select * from users where name=?1 order by ?2&quot;,nativeQuery=true)User FindByName(String name,String sort); @Param用法, 就是参数和名字对应起来, 而不是用顺序来保持 12@query(value=&quot;select * from users where name=:name order by :sort&quot;,nativeQuery=true)User FindByName(@Param(&quot;name&quot;)String name,@Param(&quot;sort&quot;)String sort); 在Spring Data JPA 1.4以后，支持在@Query中使用SpEL表达式来接收变量(略) @Modifying作用. 如果配置了一级缓存, 这时候用clearAutomctically=true, 就会刷新hibernate的一级缓存, 不然你在同一接口中更新一个对象, 接着查询这个对象, 查出来的对象就是没有更新之前的状态. 如果删除的时候可以添加这个注解 @Procedure存储过程 方法名查询 就是说根据定义的一些含义, 根据方法名来查询. Keyword Sample JPQL snippet And findByLastnameAndFirstname … where x.lastname = ?1 and x.firstname = ?2 Or findByLastnameOrFirstname … where x.lastname = ?1 or x.firstname = ?2 Is,Equals findByFirstname,&lt;br /&gt;findByFirstnameIs,&lt;br /&gt;findByFirstnameEquals … where x.firstname = 1? Between findByStartDateBetween … where x.startDate between 1? and ?2 LessThan findByAgeLessThan … where x.age &lt; ?1 LessThanEqual findByAgeLessThanEqual … where x.age &lt;= ?1 GreaterThan findByAgeGreaterThan … where x.age &gt; ?1 GreaterThanEqual findByAgeGreaterThanEqual … where x.age &gt;= ?1 After findByStartDateAfter … where x.startDate &gt; ?1 Before findByStartDateBefore … where x.startDate &lt; ?1 IsNull findByAgeIsNull … where x.age is null IsNotNull,NotNull findByAge(Is)NotNull … where x.age not null Like findByFirstnameLike … where x.firstname like ?1 NotLike findByFirstnameNotLike … where x.firstname not like ?1 StartingWith findByFirstnameStartingWith … where x.firstname like ?1 (parameter bound with appended %) EndingWith findByFirstnameEndingWith … where x.firstname like ?1 (parameter bound with prepended %) Containing findByFirstnameContaining … where x.firstname like ?1 (parameter bound wrapped in %) OrderBy findByAgeOrderByLastnameDesc … where x.age = ?1 order by x.lastname desc Not findByLastnameNot … where x.lastname &lt;&gt; ?1 In findByAgeIn(Collection&lt;Age&gt; ages) … where x.age in ?1 NotIn findByAgeNotIn(Collection&lt;Age&gt; age) … where x.age not in ?1 True findByActiveTrue() … where x.active = true False findByActiveFalse() … where x.active = false IgnoreCase findByFirstnameIgnoreCase … where UPPER(x.firstame) = UPPER(?1) @Async 可以执行异步查询 实体类的注解字段注解 @Entity 实体类 @Table 指定数据库表名 @Id 主键 @GeneratedValue主键生成策略 1234TABLE, 由表模拟序列产生主键, 这个更易于数据库移植SEQYENCE, 通过序列产生主键, 通过@SequenceGenerator, mysql不支持IDENTITY, id自增, 一般用于mysqlAUTO, jpa自动选择合适策略,缺省值 @Basic 没写注解默认就是这个 12FetchType:EAGER(默认,立即加载),LAZY(延迟加载,大字段用这个)optional:是否可以为null, 默认true @Transient 代表不在数据库中生成此字段 @Column 定义数据库列名 1234567name 数据库列名unique 是否唯一nullable 是否允许为空insertable, 插入时是否包含此字段,默认trueupdateable, 更新时是否包含此字段,默认truecolumnDefinition 数据库中实际类型,如columnDefinition = &quot;varchar(128) not null&quot;length 字段长度 @Temporal, date类型属性(TemporalType.DATE, TemporalType.TIME, TemporalType.TIMESTAMP) @Enumerated, 映射enum @Lob 大字段用这个, 加上懒加载. 比如文章内容用 123@Lob@Basic(fetch = FetchType.LAZY)private String content; 定义精度 12@Column(precision = 0, scale = 2)private BigDecimal price; @Embedded 123//配合@Embeddable使用, 其实使用之后还是生成一张表, 不过包含了BookDetail的所有字段@Embeddedprivate BookDetail bookDetail; 1234567@Embeddablepublic class BookDetail { private String detail1; private String detail2; ...} @ElementCollection字符串映射 123456//类似一本书有很多感谢人的名单@ElementCollection@CollectionTable(name=&quot;pk_thanks&quot;) //会生成pk_thanks表@MapKeyColumn(name=&quot;pk_thanks_username&quot;) //会有一个pk_thanks_username,pk_thanks_phone字段@Column(name=&quot;pk_thanks_phone&quot;) // 主键自动生成一个book_id字段, 关联外键为Book表的主键private Map&lt;String, String&gt; thanksInfo; 通用目标映射 123//根据属性名生成book_book_chapter表, 主键自动生成一个book_id字段, 关联外键为Book表的主键,其他的都一样@ElementCollection(targetClass = Chapter.class)private Collection bookChapter = new ArrayList(); 1234567@Embeddablepublic class Chapter { private String content; private String name; ...} 多表关联如果只用OneToOne,其中会自动生成一个外键关联表字段, 默认字段名为外键表名+外键主键名 @JoinColumn必须配合@OneToOne,@ManyToOne,@OneToMany一起用才有效 1234567- columnDefinition(可选,&quot;&quot;),JPA 使用最少量 SQL 创建一个数据库表列。- insertable(可选,true), 默认情况下，JPA 持续性提供程序假设它可以插入到所有表列中。如果该列为只读，请将 insertable 设置为 false。- name(可选,默认为引用表名+&quot;_&quot;+主键名), 设置外键名- nullable(可选,true)- table(可选, 默认引用表名)- unique(可选,false),- updatable(可选,true) @OneToOne1234targetEntity: 可选, 关系目标实体, 默认该字段类型cascade: PERSIST 级联新建; REMOVE; REFRESH; MERGE 级联更新; ALL 全部fetch: EAGER; LAZYmappedBy: 关联关系被谁维护, 可选, 一般不需要特别指定.写了这个就代表是关系被维护方. 里面的值指另一方实体里面属性的字段, 而不是数据库字段, 也不是实体对象的名字, 即配置了@JoinColumn或@JoinTable注解属性字段名字. 比如: 这样只是单项指定 12345678910111213@Entity@Tablepublic class Woman { @Id @GeneratedValue private Integer id; @OneToOne @JoinColumn(name=&quot;woman_id&quot;,referencedColumnName=&quot;id&quot;) private Man man; ...get/set} 加上这个就是双向指定,mappedBy意思是放弃关联关系维护并且不能在使用, 此值为Woman中Man的属性值 123456789101112@Entity@Tablepublic class Man { @Id @GeneratedValue private Integer id; @OneToOne(mappedBy=&quot;man&quot;) private Woman woman; ...get/set} 生成的表 123456789101112CREATE TABLE `woman` ( `id` int(11) NOT NULL, `woman_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `FKls77cjbm77mxo41kr13ahiwdq` (`woman_id`), CONSTRAINT `FKls77cjbm77mxo41kr13ahiwdq` FOREIGN KEY (`woman_id`) REFERENCES `man` (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `man` ( `id` int(11) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 多对一单向关联12345678910111213@Entitypublic class Picture { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer pictureId; private String pictureName; @ManyToOne private Category category; ...} 12345678910@Entitypublic class Category { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer categoryId; private String categoryName; ...} 生成的picture表 123456789CREATE TABLE `picture` ( `picture_id` int(11) NOT NULL AUTO_INCREMENT, `picture_name` varchar(255) DEFAULT NULL, `category_category_id` int(11) DEFAULT NULL, PRIMARY KEY (`picture_id`), KEY `FKcc24ya5ilyoucwe8p5i56y4d7` (`category_category_id`), CONSTRAINT `FKcc24ya5ilyoucwe8p5i56y4d7` FOREIGN KEY (`category_category_id`) REFERENCES `category` (`category_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 双向关联Category的Model修改为 12345678910111213@Entitypublic class Category { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer categoryId; private String categoryName; @OneToMany(mappedBy = &quot;category&quot;) private Set&lt;Picture&gt; pictures; ...} OrderBy一般和@OneToMany使用, 比如@OrderBy(&quot;name DESC&quot;) @JoinTable如果对象与对象之间有一个关联关系表的时候，就会用到@JoinTable，一般和@ManyToMany一起使用 12345name: 中间关联表名catalog: 表的catalogschemaJoinColumn[]: 主链接表的字段inverseJoinColumns[]: 被关联的表外键字段 注意: 注解要不全部写在字段上, 要不全部写在get方法上 Json序列化的时候很容易死循环, 所以很多情况要@JsonIgnore 级联删除注意一下 表的字段修改要注意. 生产环境很容易丢失数据","link":"/blog/2016/01/10/%E5%85%B6%E4%BB%96-JPA%E5%9F%BA%E7%A1%80/"},{"title":"分布式事务解决形态","text":"这里说一下分布式事务概要和解决形态 分布式基本概念CAP 一致性（Consistency） 可用性（Availability） 分区容错性（Partition tolerance） BASE理论 Basically Available（基本可用）： 比如高并发的时候让一部分请求直接降级处理 Soft state（软状态）：允许系统中存在中间状态，不同节点的数据副本在数据同步的过程中存在延迟 Eventually consistent（最终一致性）：数据副本在一段时间之后都可以达到一个最终同步的状态 分布式事务解决方案2pc 准备阶段：所有参与者准备执行锁住资源，向TM告诉自己准备好了 提交阶段：所有参与者都说了准备好了，TM向所有参与者发送提交命令。 缺点： 资源阻塞 单点问题，如果协调者挂了就不知道事务怎么样了 数据不一致，假设TM只通知到了部分会出现不一致 3pc CanCommit：询问TM问参与者是否可以正常执行，然后参与者判断 PreCommit：执行事务不提交 DoCommit ：TM发送提交或者回滚操作，这时候参与者才会提交 改进： 参与者也有超时机制 预提交解决了上面不一致问题 基于XA协议DB层面实现 tccTry、Confirm、Cancel，3个方法均由业务编码实现 注意事项： 冥等性：confirm和cancel一定要保持冥等性，因为网络不稳定会重试 空回滚：要判断好try有没有成功执行，如果try没有成功预留资源的话，cancel需要空回滚 资源悬挂：try超时之后cancel空回滚，然后try执行成功，但是这时候事务的最终状态是结束，所以资源需要悬挂 注意点详细可以看这篇文章 这里面需要判断资源的最终状态咯爱处理2，3条异常 SAGASAGA可以看做一个异步的、利用队列实现的补偿事务。 其适用于无需马上返回业务发起方最终状态的场景，例如：你的请求已提交，请稍后查询或留意通知 之类。 将上述补偿事务的场景用SAGA改写，其流程如下： 订单服务创建最终状态未知的订单记录，并提交事务 现金服务扣除所需的金额，并提交事务 订单服务更新订单状态为成功，并提交事务 以上为成功的流程，若现金服务扣除金额失败，那么，最后一步订单服务将会更新订单状态为失败。 其业务编码工作量比补偿事务多一点，包括以下内容： 订单服务创建初始订单的逻辑 订单服务确认订单成功的逻辑 订单服务确认订单失败的逻辑 现金服务扣除现金的逻辑 现金服务补偿返回现金的逻辑 lcnLCN模式是通过代理Connection的方式实现对本地事务的操作，然后在由TxManager统一协调控制事务。当本地事务提交回滚或者关闭连接时将会执行假操作，该代理的连接将由LCN连接池管理。 事务发起者会向TM创建事务组，执行本地业务，调用模块A 模块A加入事务组，执行业务，假提交返回数据 模块B加入事务组，执行业务，假提交返回数据 事务发起者获得AB结果通知事务组，之后事务组内的所有模块会决定提交还是回滚，之后把提交和回滚的结果告诉事务组 最终会返回给事务发起方 seataAT模式 两阶段提交 业务数据和回滚日志在记录在同一个本地事务中，释放本地锁和连接资源 提交异步化，回滚通过一阶段回滚日志方向补偿 Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。 Transaction Manager (TM)： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。 Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID。 XID 在微服务调用链路的上下文中传播。 RM向TC注册分支事务，接着执行这个分支事务并提交（这时候会生成回滚记录），最后将执行结果汇报给TC。 TM 根据 TC 中所有的分支事务的执行情况，发起全局提交或回滚决议。 TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。 消息事务柔性事务解决方案，最终一致性 主动方投递消息 预发送消息, 状态待确认. 返回消息存储成功的结果. 失败不执行业务操作, 成功执行业务操作. 业务操作, 成功更新消息为待发送, 失败逻辑删除(更新状态为已回滚). 注意: 3更新状态失败要抛出异常回滚事务, 不投递到mq中. 投递mq失败也要回滚. 2/3在同一个事务中 状态为待发送就投递到mq中, 更新状态为已发送. 被动方接受消息 等待mq投递消息, 调用本地事务成功更新状态已完成. 失败一直重试, 设置重试次数, 超过人工处理. 注意冥等性 注意: 需要定时任务去查询待确认状态, 回查待确认本地业务操作情况. 可以看看a2.rocketmq介绍.md 优点： 通用性比较强，性能比较好 解决形态 消息事务：适合提交和回滚只取决于发起方的业务需求，比如下订单之后加积分。都不需要编写反向的业务逻辑过程 补偿事务：类似seata自动补偿的形式 TCC事务：可以处理各种事务，但是业务入侵很强 SAGA事务：适用于不需要同步返回发起方执行最终结果、可以进行补偿、对性能要求较高、不介意额外编码的业务场景 感谢： https://www.sofastack.tech/blog/sofa-meetup-3-seata-retrospect/ https://www.cnblogs.com/skyesx/p/9697817.html","link":"/blog/2021/01/08/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E5%BD%A2%E6%80%81/"},{"title":"redis分布式锁","text":"分布式的时候需要用中间件来实现锁, 比如redis, zookeeper.理论上来说只能用zookeeper类似的, 因为根据CAP模型, zookeeper属于CP,保证一致性和分区性.但是redis属于AP, 保证可用性和分区性. 但是考虑到流量没有很大, 并且系统中刚好用到redis,没用到zookeeper.所以还是可以考虑用redis作为分布式锁. redis锁需要注意： setNX需要设置过期时间，而且要一起设置过期时间，不然本服务上锁之后宕机所有的服务都会上不了锁。处理方法，LUA脚本或者jedis.set(key, value, &quot;NX&quot;, &quot;PX&quot;, expireMillis); set的值需要设置成UUID。比如业务A长时间导致redis锁超时自动释放。业务B进来加了同样的锁，然后业务A处理完了释放了业务B的锁 业务A拿到锁之后执行时间过长，然后过期释放了，业务B进来同时拿到了锁。要不设置超时时间长一点，要不自动续期。锁设置自动延期，Redisson实现。默认锁超时时间30S，上锁成功就会开一个线程（开门狗）。每过10s就会续期一次，重置成30s。业务服务宕机了线程也就停了，所以到了时间也会过期 无法等待锁释放。可以客户端轮询，或者使用redis发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。 不可重入。可以使用LUA脚本，使用hash结构去保存key+重入次数 如果是主从模式+哨兵，因为数据同步是异步的。主从切换的时候导致锁丢失会造成多个客户端拥有锁。 脑裂。sentinel发现master不可达之后，其实master只是网络有点问题，从变主。之前master网络恢复，两个主。不同客户端访问不同主节点，会同时获取锁 集群获取锁，redlock 获取当前时间 顺序依次向redis集群中每一个加锁，同时还有设置一个加锁超时。全部加锁遍历之后，算出总共加锁耗时多少。如果一半以上加锁成功并且加锁耗时不超过锁的超时时间，表示加锁成功 如果加锁失败，释放所有redis集群中加的锁 redlock文章 直接失败这边maven只依赖了redis starter 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 简易实现方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package com.tencent.finance.util;import com.fasterxml.jackson.core.JsonParseException;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonMappingException;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.data.redis.core.*;import org.springframework.data.redis.core.ZSetOperations.TypedTuple;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.io.IOException;import java.util.ArrayList;import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.TimeUnit;/** * Redis 访问操作工具类 * * @author */@Componentpublic class JedisUtils { @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; @Resource(name = &quot;redisTemplate&quot;) private ValueOperations&lt;String, String&gt; valOpsStr; @Resource(name = &quot;redisTemplate&quot;) private SetOperations&lt;String, String&gt; valOpsSet; @Resource(name = &quot;redisTemplate&quot;) private ZSetOperations&lt;String, String&gt; valOpsZSet; @Resource(name = &quot;redisTemplate&quot;) ListOperations&lt;String, String&gt; valOpsList; @Resource(name = &quot;redisTemplate&quot;) private HashOperations&lt;String, String, Object&gt; valOpsHash; /** * redis key 前缀 */ @Value(&quot;${redis_prefix}&quot;) public String redisPrefix; private static final ObjectMapper mapper = new ObjectMapper(); private static final String LOCK_PREFIX = &quot;LOCK_KEY&quot;; private String initKey(String key) { return redisPrefix + &quot;:&quot; + key; } public boolean tryLock(String key, String val, int expire) { return valOpsStr.setIfAbsent(initKey(LOCK_PREFIX + &quot;:&quot; + key), val, expire, TimeUnit.SECONDS); } public void unLock(String key){ delKey(initKey(LOCK_PREFIX + &quot;:&quot; + key)); } /** * 从缓存中删除数据 * * @return */ public void delKey(String key) { key = initKey(key); redisTemplate.delete(key);// redisTemplate.execute((RedisCallback&lt;Long&gt;) connection -&gt; connection.del(key.getBytes())); } /** * 设置超时时间 * * @param key * @param seconds */ public void expire(String key, int seconds) { key = initKey(key); redisTemplate.expire(key, seconds, TimeUnit.SECONDS); }} 比如定时任务就需要用到分布式锁, 因为集群部署的话不用会出现问题 1234if(jedisUtils.tryLock(Thread.currentThread().getStackTrace()[1].getMethodName(), String.valueOf(System.currentTimeMillis()), 10)){...jedisUtils.unLock(Thread.currentThread().getStackTrace()[1].getMethodName());} unlock的时候还可以去判断value值是否一致, 保证只能当前线程可以解开当前锁 http://blog-save.oss-cn-shenzhen.aliyuncs.com/%E4%BB%A3%E7%A0%81/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/JedisUtils.java 可参考 https://crossoverjie.top/2018/03/29/distributed-lock/distributed-lock-redis/# 持续获取实现了自动关锁, 持续性获得锁.判断value是否是否一致, 避免A线程超时过期之后,B线程进来, 然后A线程执行结束后会把B的锁解开. 注意redis操作如果用到了事务的话, 每次操作都是占用一个连接. 测试类中调用每次都会占用连接, 我原以为是测试方法默认开启事务, 测试了一下也不对.但是在service调用分布式锁的逻辑有又完全不会报错, 现在还是无解状态, 希望有大佬可以指点一下.报错信息放在本文最下面 代码自动关锁 123456789101112131415161718192021222324252627282930313233343536373839import lombok.RequiredArgsConstructor;import lombok.ToString;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.connection.RedisConnection;import org.springframework.data.redis.core.RedisConnectionUtils;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.data.redis.core.script.DefaultRedisScript;import org.springframework.transaction.support.TransactionSynchronizationManager;import java.util.Collections;import java.util.List;@Slf4j@ToString@RequiredArgsConstructorpublic class RedisDistributedLock implements AutoCloseable{ private final RedisTemplate&lt;String, Object&gt; redisTemplate; private final String key; private final String value; private static final String COMPARE_AND_DELETE = &quot;if redis.call('get',KEYS[1]) == ARGV[1]\\n&quot; + &quot;then\\n&quot; + &quot; return redis.call('del',KEYS[1])\\n&quot; + &quot;else\\n&quot; + &quot; return 0\\n&quot; + &quot;end&quot;; @Override public void close() throws Exception { log.debug(&quot;执行完关锁, {}&quot;, this.toString()); System.out.println(&quot;执行完关锁, &quot;+ this.toString()); final List&lt;String&gt; keys = Collections.singletonList(key); redisTemplate.execute(new DefaultRedisScript&lt;&gt;(COMPARE_AND_DELETE, Object.class), keys, value); }} 持续性获得锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.math.NumberUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;@Slf4j@Componentpublic class RedisLock { @Value(&quot;${redis_prefix}&quot;) public String redisPrefix; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; private static final String LOCK_PREFIX = &quot;LOCK_KEY&quot;; /** * 加锁. 默认10s超时, 重试10次, 每次200毫秒 * * @param key * @param handler * @param &lt;T&gt; * @return * @throws Exception */ public &lt;T&gt; T tryLock(String key, LockHandler&lt;T&gt; handler) throws Exception { return tryLock(key, 10, 10, 200, handler); } /** * @param key 加锁key * @param timeout 超时时间, 秒 * @param retries 重试次数 * @param waitingTime 重试等待时间 * @param handler 加锁内部逻辑 * @param &lt;T&gt; * @return * @throws Exception */ public &lt;T&gt; T tryLock(String key, long timeout, int retries, long waitingTime, LockHandler&lt;T&gt; handler) throws Exception { key = LOCK_PREFIX + &quot;:&quot; + redisPrefix + &quot;:&quot; + key; String value = Thread.currentThread().getName() + &quot;:&quot; + (System.currentTimeMillis() + timeout); try (final RedisDistributedLock lock = this.acquire(key, value, timeout, retries, waitingTime)) { if (lock != null) { return handler.handle(); } } return null; } public RedisDistributedLock acquire(String key, String val, long timeout, int retries, long waitingTime) throws InterruptedException { do { System.out.println(&quot;尝试:&quot; + Thread.currentThread().getName() + &quot; , retries:&quot; + retries); final ValueOperations&lt;String, Object&gt; stringObjectValueOperations = redisTemplate.opsForValue(); Boolean result = stringObjectValueOperations.setIfAbsent(key, val, timeout, TimeUnit.SECONDS); if (result) { log.debug(&quot;加锁成功, KEY: {}, VALUE: {}&quot;, key, val); System.out.println(&quot;加锁成功, KEY: &quot; + key + &quot;, VALUE: &quot; + val); return new RedisDistributedLock(redisTemplate, key, val); } if (retries &gt; NumberUtils.INTEGER_ZERO) { TimeUnit.MILLISECONDS.sleep(waitingTime); } if (Thread.currentThread().isInterrupted()) { break; } } while (retries-- &gt; NumberUtils.INTEGER_ZERO); return null; } @FunctionalInterface public interface LockHandler&lt;T&gt; { T handle(); }} 测试类 12345678910111213141516171819202122@Testpublic void testLock() throws Exception { final CountDownLatch countDownLatch = new CountDownLatch(6); final ExecutorService threadPool = Executors.newFixedThreadPool(6); for (int i = 0; i &lt; 6; i++) { threadPool.execute(new Runnable() { @SneakyThrows @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; 等着！！！&quot;); countDownLatch.countDown(); countDownLatch.await(); System.out.println(Thread.currentThread().getName() + &quot; 开始&quot;); redisLock.tryLock(&quot;hahaha&quot;, () -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 终于来了！！！&quot;); return null; }); } }); }} 报错信息1234Exception in thread &quot;pool-6-thread-6&quot; org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect toCaused by: io.lettuce.core.RedisConnectionException: Unable to connect toCaused by: java.lang.IllegalStateException: executor not accepting a task at io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:60)","link":"/blog/2021/01/10/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-redis/"},{"title":"jdk环境","text":"jdk环境 受不了了, 每次重装环境都要百度一下, 一些写的都有问题, 来回弄太浪费时间了. 自己记录一下 环境变量设置 编辑系统变量 添加 JAVA_HOME, 比如C:\\Program Files\\Java\\jdk1.8.0_191 path里面添加两条记录, %JAVA_HOME%\\bin和%JAVA_HOME%\\jre\\bin 添加CLASSPATH, 变量值为.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar 全部确定之后, 一定要重新打开cmd 验证java -version 和 javac -version centos下载https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html 123456789vim /etc/profileexport JAVA_HOME=/usr/local/java/jdk1.8.0_171export JRE_HOME=${JAVA_HOME}/jreexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/libexport PATH=${JAVA_HOME}/bin:$PATHsource /etc/profile","link":"/blog/2015/03/03/%E5%B7%A5%E5%85%B7-2.jdk%E7%8E%AF%E5%A2%83/"},{"title":"GIT","text":"GIT 不提交分支修改bug情景: 在dev分支开发, 发现bug, 需要切换到master修改bug, 但是又不想提交dev, 因为没开发完 git checkout dev git stash 保存修改内容 git stash list 可以看到存储的列表 git status 发现没有改动的代码 master修改bug之后切回dev git stash apply 回去保存的代码 git stash drop 删除保存list里面的内容, 如果保存了很多, 可以git stash apply stash@{0}来删除指定id的 初始化第一次提交12345git config --global user.name &quot;username&quot;git config --global user.email &quot;***@qq.com&quot;git initgit add .git commit -m &quot;first commit&quot; 提交远程厂库SSH KEY 创建SSH Key 在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果有的话，直接跳过此如下命令 如果没有的话，打开命令行，输入如下命令：(个人用直接回车，不设置密码也无所谓) ssh-keygen -t rsa -C “xx@qq.com“ id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 登录github,打开” settings”中的SSH Keys页面，然后点击“Add SSH Key”,填上任意title，在Key文本框里黏贴id_rsa.pub文件的内容 添加仓库 git remote add origin https://***.git 推送 第一次推送记得忽略你想要忽略的东西 我们第一次推送master分支时，加上了 –u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来 git push -u origin master 以后直接git push origin master 可以更新一下git pull 有时候会报错，因为和github冲突，可以强制push： git push -u origin master -f 下载自己git的code： git pull src 远程仓库clone的时候实际上Git自动把本地的master分支和远程的master分支对应起来了，并且远程库的默认名称是origin git remote 要查看远程库的信息 使用 git remote –v 要查看远程库的详细信息 使用 git push origin master 推送分支 分支git checkout –b dev 创建dev分支 并切换到dev分支上 git branch 查看当前所有的分支 git checkout master 切换回master分支 git merge dev 在当前的分支上合并dev分支,可以先到master在执行这句就合并分支到主分支了 git branch –d dev 删除dev分支 git branch &lt;name&gt; &lt;hash_val&gt; 恢复删除分支 git branch name 创建分支 合并分支默认使用Fast-forward模式，是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快 修改冲突,再去add , commit 禁用Fast forward模式通常合并分支时，git一般使用Fast forward模式，在这种模式下，删除分支后，会丢掉分支信息，现在我们来使用带参数 –no-ff来禁用”Fast forward”模式。 git merge –no-ff -m 注释 dev 合并分支使用这个的话, 删除分支后分支的log还在 bug分支如果在分支上开发到一半的时候, 发现master上出现一个bug. 你可以直接新建一个目录,clone, 修复, 提交. 也可以使用stash功能，可以把当前工作现场 ”隐藏起来”，等以后恢复现场后继续工作。 操作如下 : git stash 隐藏现场 git status 发现没有需要提交的东西 git checkout -b bug 创建并切换到bug分支,修改bug后 add , commit git checkout master 切换回master git merge –no-ff -m “修复bug” bug 合并分支 git branch -d bug 删除bug分支 git checkout dev 回到dev分支继续开发 git stash list 查看下 git stash pop 恢复的同时把stash内容也删除了也可以 git stash apply恢复，恢复后，stash内容并不删除，你需要使用命令git stash drop来删除 回退git log 显示从最近到最远的显示日志 git log –pretty=oneline 简化显示日志 git reset –hard HEAD^ 回退上一个版本 如果回退上上版本, HEAD^^ git reset –hard HEAD~100 回退前100版本 假设我们会退到了上个版本, 现在我们想回去最新的版本怎么做呢? git reset –hard 版本号 切换到一个版本 但是现在我们不知道版本号 git reflog 显示所有commit, 包括所有分支和所有撤销的commit 验证失败1git config --system --unset credential.helper 在clone一次, 提示再输入输入一遍用户名密码就好了 其他cat readme.txt 查看这个文件内容 git status 查看状态 git diff readme.txt 查看readme.txt文件改变了什么","link":"/blog/2015/03/02/%E5%B7%A5%E5%85%B7-1.git/"},{"title":"AES对称加密工具类","text":"直接上修改完bug之后的一个aes工具类吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package **.util;import java.security.InvalidAlgorithmParameterException;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;import java.security.SecureRandom;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.KeyGenerator;import javax.crypto.NoSuchPaddingException;import javax.crypto.SecretKey;import javax.crypto.spec.GCMParameterSpec;import javax.crypto.spec.SecretKeySpec;import org.apache.commons.codec.binary.Base64;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * AES对称加密工具类 */public class AesUtils { private static final Logger logger = LoggerFactory.getLogger(AesUtils.class); private static final String KEY_ALGORITHM = &quot;AES&quot;; private static final String DEFAULT_CIPHER_ALGORITHM = &quot;AES/GCM/PKCS5Padding&quot;;// 默认的加密算法 /** aes加密长度 **/ private static final int secretAesLength = 256; /** * AES 加密操作 * * @param content 待加密内容 * @param salt 加密密码 * @return 返回Base64转码后的加密数据 */ public static String encrypt(String content, String salt, int secretAesLength) { try { Cipher cipher = Cipher.getInstance(DEFAULT_CIPHER_ALGORITHM); cipher.init(Cipher.ENCRYPT_MODE, getSecretKey(salt, secretAesLength)); byte[] iv = cipher.getIV(); assert iv.length == 12; byte[] encryptData = cipher.doFinal(content.getBytes()); assert encryptData.length == content.getBytes().length + 16; byte[] message = new byte[12 + content.getBytes().length + 16]; System.arraycopy(iv, 0, message, 0, 12); System.arraycopy(encryptData, 0, message, 12, encryptData.length); return Base64.encodeBase64String(message); } catch (InvalidKeyException | NoSuchAlgorithmException | NoSuchPaddingException | IllegalBlockSizeException | BadPaddingException e) { logger.error(e.getMessage(), e); } return null; } /** * AES 解密操作 * * @param base64Content * @param salt * @return */ public static String decrypt(String base64Content, String salt, int secretAesLength) { byte[] content = Base64.decodeBase64(base64Content); if (content.length &lt; 12 + 16) throw new IllegalArgumentException(); GCMParameterSpec params = new GCMParameterSpec(128, content, 0, 12); try { Cipher cipher = Cipher.getInstance(DEFAULT_CIPHER_ALGORITHM); cipher.init(Cipher.DECRYPT_MODE, getSecretKey(salt, secretAesLength), params); byte[] decryptData = cipher.doFinal(content, 12, content.length - 12); return new String(decryptData); } catch (InvalidKeyException | NoSuchAlgorithmException | NoSuchPaddingException | InvalidAlgorithmParameterException | IllegalBlockSizeException | BadPaddingException e) { logger.error(e.getMessage(), e); } return null; } /** * 生成加密秘钥 * * @return * @throws NoSuchAlgorithmException */ private static SecretKeySpec getSecretKey(String encryptPass, int secretAesLength) throws NoSuchAlgorithmException { KeyGenerator kg = KeyGenerator.getInstance(KEY_ALGORITHM); SecureRandom secureRandom = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); secureRandom.setSeed(encryptPass.getBytes()); // 初始化密钥生成器，AES要求密钥长度为128位、192位、256位// kg.init(secretAesLength, new SecureRandom(encryptPass.getBytes())); kg.init(secretAesLength, secureRandom); SecretKey secretKey = kg.generateKey(); return new SecretKeySpec(secretKey.getEncoded(), KEY_ALGORITHM);// 转换为AES专用密钥 } public static void main(String[] args) { String s = &quot;436fa3e6e33648a492c791c442f23ff4&quot;; String salt = &quot;hahahaha&quot;; String encoded = encrypt(s, salt, 256); logger.info(&quot;加密之前：{}&quot;, s); logger.info(&quot;加密结果：{}&quot;, encoded); logger.info(&quot;解密结果：{}&quot;, decrypt(encoded, salt, 256)); }}","link":"/blog/2015/03/05/%E5%B7%A5%E5%85%B7-4.aes/"},{"title":"idea","text":"idea cpu占用100解决 安装插件choose runtime 打开Help -&gt; Find Action, 搜索choose runtime 点击choose runtime就出现Loading Runtime List...的弹出框 选择本机自己安装的jdk 重启 12345678910111213141516171819202122232425262728293031323334#堆栈设置-Xms4096m-Xmx4096m-Xmn3072m-XX:MetaspaceSize=1024m-XX:MaxMetaspaceSize=1024m-XX:+AlwaysPreTouch-XX:InitialCodeCacheSize=1200m-XX:ReservedCodeCacheSize=1200m-XX:+UseCompressedOops-Dfile.encoding=UTF-8# 采用何种垃圾回收参数-XX:+UseConcMarkSweepGC-XX:ParallelGCThreads=4-XX:SoftRefLRUPolicyMSPerMB=50-ea# JIT 参数-XX:CICompilerCount=2-XX:+TieredCompilation-XX:TieredStopAtLevel=3-XX:CompileThreshold=100000#-XX:Tier4MinInvocationThreshold=200000#-XX:Tier4InvocationThreshold=300000#-XX:Tier4CompileThreshold=400000-XX:MaxInlineLevel=3-Dsun.io.useCanonPrefixCache=false-Djava.net.preferIPv4Stack=true-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot;-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Djdk.attach.allowAttachSelf-Xverify:none 感谢https://blog.csdn.net/weixin_44729500/article/details/105041902 常用插件记录一下自己比较喜欢的插件， 没办法， 喜欢重装系统， 每次都去百度一遍挺难受。 快捷键 ctrl+alt+s 打开设置， 自行打开插件栏，略 JRebel for IntelliJ 下载 https://github.com/ilanyu/ReverseProxy/releases/tag/v1.4 这里我下载win64版本ReverseProxy_windows_amd64.exe，点击开启 安转插件JRebel for IntelliJ 从新打开idea，点击debug jrebel 选择默认的Connect to online licensing service, 第一行填写http://127.0.0.1:8888/2aacfda2-91c7-4ca3-bd41-cafe937878e2， 这里可以生成GUID. 第二行输入正确邮箱格式就行， 同意协议点击确定。 激活成功，打开settings，ctrl+alt+s ，点击JRebel 点击 work offline， 之后就可以关闭ReverseProxy_windows_amd64.exe了。 .ignore目前先这么写吧 1234567891011121314151617181920212223242526272829303132333435363738394041HELP.mdtarget/!.mvn/wrapper/maven-wrapper.jar!**/src/main/**!**/src/test/**### STS ###.apt_generated.classpath.factorypath.project.settings.springBeans.sts4-cache### IntelliJ IDEA ###.idea*.iws*.iml*.ipr# *.xml*.log.**.log### NetBeans ###/nbproject/private//nbbuild//dist//nbdist//.nb-gradle/build/### VS Code ###.vscode/**/rebel.xml**/.rebel.xml.bak**/.rebel-remote.xml.bak*.0 CamelCase驼峰，下划线等各种格式转换， shift+alt+u 神奇 StringManipulation字符串操作超级强大， 我用的比较多的是数字递增， 配合Alt批量选择。用的thrift福音 Lombok plugin不说话 Mybatis plugin可以在mapper接口中和mapper的xml文件中来回跳转，就想接口跳到实现类那样简单。 GsonFormat以前写android的时候不能缺少的插件，没有之一 GenerateAllSetter因为有时候BeanUtil.copyProperties()有时候不是很适合。 自动set，创建完对象， 在变量名上面按Alt+Enter就会出来 generate all setter选项。 Rainbow Brackets彩虹颜色的括号 看着很舒服 敲代码效率变高。 看个人 Free Mybatis pluginJRebel MybatisPlus extension如果用了MybatisPlus就要安装这个插件之后jrebel才能xml热更新 翻译插件","link":"/blog/2015/03/04/%E5%B7%A5%E5%85%B7-3.idea/"},{"title":"maven资源文件处理","text":"maven资源文件处理 12345678910111213141516171819202122&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.woff&lt;/exclude&gt; &lt;exclude&gt;**/*.woff2&lt;/exclude&gt; &lt;exclude&gt;**/*.ttf&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*.woff&lt;/include&gt; &lt;include&gt;**/*.woff2&lt;/include&gt; &lt;include&gt;**/*.ttf&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; filtering: true就是将${}替换为直接值, 比如a.properties里面的${name}引用了b.properties的name值, 就会直接替换.上面的意思是src/main/resources目录下排除.woff/.woff2/.ttf之外的文件都会替换值; 第二个是src/main/resources目录下的.woff/.woff2/.ttf都不会替换值 maven设置阿里云仓库设置maven的setting.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344 &lt;mirrors&gt; &lt;!-- mirror | Specifies a repository mirror site to use instead of a given repository. The repository that | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used | for inheritance and direct lookup purposes, and must be unique across the set of mirrors. | &lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt; --&gt;&lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云公共仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云谷歌仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/google&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云阿帕奇仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/apache-snapshots&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云spring仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/spring&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云spring插件仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/spring-plugin&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;","link":"/blog/2015/03/06/%E5%B7%A5%E5%85%B7-5.maven/"},{"title":"VI常用操作","text":"VI常用操作 查看日志, 一直忘记 123456789101112131415161718shitf+g = G 光标到文本最后面gg 光标到文本最前面/[word] 文本从头开始找?[word] 文本从尾开始找n 查找下一个shift+n = N 查找上一个set nu 显示行号ctrl+b 向上半屏ctrl+d 向下半屏ctrl+y 向上一行ctrl+e 向下一行:e 刷新 常用命令光标定位1234567h ：光标左移一个字符k ：光标上移一个字符j ：光标下移一个字符l ：光标右移一个字符0 ：光标移至行首(数字0)$ ：光标移至行尾 翻页12345G ：跳转到文件的末尾行gg: 跳转到文件的首行ctrl+f：向文件尾翻一屏ctrl+b：向文件首翻一屏 删除1234d0：删除光标至行首的内容d$：删除光标至行尾的内容dd ：删除整行ndd ：向下删除n行 复制12345yy ：复制整行nyy ：复制n行p ：在所在行下一行粘贴P ：在所在行上一行粘贴dd ：剪切整行 查找123456/pattern ：向下查找?pattern ：向上查找n ：顺序查找N ：反向查找:s/p1/p2/g ：在当前行，将p1替换成p2:n1,n2s/p1/p2/g ：将n1至n2行之间的p1替换成p2 其他123456789:w 保存:q 退出:x 保存并退出 或 :wq:q! 强制退出:w! 强制保存:数字 定位到指定行:set nu 显示行号:set nonu 取消行号u：取消上一次操作","link":"/blog/2015/03/08/%E5%B7%A5%E5%85%B7-6.vi/"},{"title":"UML","text":"UML 类/接口/类图类在 UML 中, 类使用包含类名、属性和操作且带有分隔线的矩形来表示 1234567891011大概长这样--------------------| Student | //类名|-------------------|| -name:String | //字段 [可见性]属性名:类型[=默认值]| +age:int=18 | //public(+), private(-), protected(#), friendly(~)|-------------------|| +display():void | //方法 [可见性]方法名(参数类型)[:返回类型]-------------------- 接口在 UML 中, 接口使用一个带有名称的小圆圈来进行表示 123456 O Person----------------+display():void 类图123456789101112131415161718 O Person----------------+display():void △ | (空心三角箭头虚线, 实现关系) | | --------------------| Student | //类名|-------------------|| -name:String | //字段 [可见性]属性名:类型[=默认值]| +age:int=18 | //public(+), private(-), protected(#), friendly(~)|-------------------|| +display():void | //方法 [可见性]方法名(参数类型)[:返回类型]-------------------- 类之间关系根据类与类之间的耦合度从弱到强排列, UML 中的类图有以下几种关系：依赖关系、关联关系、聚合关系、组合关系、泛化关系和实现关系.其中泛化和实现的耦合度相等, 它们是最强 依赖关系依赖（Dependency）关系是一种使用关系,它是对象之间耦合度最弱的一种关联方式,是临时性的关联. 在代码中,某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责. 比如人打电话是依赖手机 关联关系关联（Association）关系是对象之间的一种引用关系,用于表示一类对象与另一类对象之间的联系,如老师和学生、师傅和徒弟、丈夫和妻子等.关联关系是类与类之间最常用的一种关系,分为一般关联关系、聚合关系和组合关系. 我们先介绍一般关联. 关联可以是双向的,也可以是单向的.在 UML 类图中,双向的关联可以用带两个箭头或者没有箭头的实线来表示,单向的关联用带一个箭头的实线来表示,箭头从使用类指向被关联的类.也可以在关联线的两端标注角色名,代表两种不同的角色. 在代码中通常将一个类的对象作为另一个类的成员变量来实现关联关系. 老师和学生的关系图,每个老师可以教多个学生,每个学生也可向多个老师学,他们是双向关联 聚合关系聚合（Aggregation）关系是关联关系的一种,是强关联关系,是整体和部分之间的关系,是 has-a 的关系. 聚合关系也是通过成员对象来实现的,其中成员对象是整体对象的一部分,但是成员对象可以脱离整体对象而独立存在.例如,学校与老师的关系,学校包含老师,但如果学校停办了,老师依然存在. 在 UML 类图中,聚合关系可以用带空心菱形的实线来表示,菱形指向整体. 组合关系组合（Composition）关系也是关联关系的一种,也表示类之间的整体与部分的关系,但它是一种更强烈的聚合关系,是 contains-a 关系. 在组合关系中,整体对象可以控制部分对象的生命周期,一旦整体对象不存在,部分对象也将不存在,部分对象不能脱离整体对象而存在.例如,头和嘴的关系,没有了头,嘴也就不存在了. 在 UML 类图中,组合关系用带实心菱形的实线来表示,菱形指向整体 泛化关系泛化（Generalization）关系是对象之间耦合度最大的一种关系,表示一般与特殊的关系,是父类与子类之间的关系,是一种继承关系,是 is-a 的关系. 在 UML 类图中,泛化关系用带空心三角箭头的实线来表示,箭头从子类指向父类. 在代码实现时,使用面向对象的继承机制来实现泛化关系. 例如,Student 类和 Teacher 类都是 Person 类的子类 实现关系实现（Realization）关系是接口与实现类之间的关系.在这种关系中,类实现了接口,类中的操作实现了接口中所声明的所有的抽象操作. 在 UML 类图中,实现关系使用带空心三角箭头的虚线来表示,箭头从实现类指向接口. 例如,汽车和船实现了交通工具","link":"/blog/2015/03/07/%E5%B7%A5%E5%85%B7-7.uml/"},{"title":"ThreadLocal","text":"ThreadLocal解析 一般使用 123456789ThreadLocal&lt;String&gt; local = new ThreadLocal&lt;&gt;();local.set(&quot;hahah&quot;);System.out.println(&quot;local: &quot; + local.get());local.remove();System.out.println(&quot;local: &quot; + local.get());//结果local: hahahlocal: null ThreadLocal # set方法 123456789101112131415public void set(T value) { //获取当前线程 Thread t = Thread.currentThread(); //其实就是拿当前线程中ThreadLocal.ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) //存在直接在map里面key为ThreadLocal, value为Object map.set(this, value); else //没有就new一个直接赋值 createMap(t, value);}void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} 每个线程都有自己的 ThreadLocalMap, key为ThreadLocal, value为Object 注意其实ThreadLocalMap的key是一个 弱引用 每个线程在往ThreadLocal里放值的时候，都会往自己的ThreadLocalMap里存，读也是以ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离 ThreadLocalMap有点类似HashMap的结构，只是HashMap是由数组+链表实现的，而ThreadLocalMap中并没有链表结构 为什么需要弱引用？因为当前Thread持有了ThreadLocalMap，ThreadLocalMap的key持有了ThreadLocal，所以只要当前线程在运行就不会回收ThreadLocal 为什么会内存泄露？因为key使用软引用，GC之后key为null，但是value还是存在。在get(),set(),remove()方法中会清楚key为空的数据。但是如果使用的线程池，线程池使用完之后没有回收并且没有使用这几个方法。 解决内存泄露？每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 GC之后key是否为null？如果是后面没有用到ThreadLocal, 那么就会被回收掉. 如果后面调用了, 比如ThreadLocal.get(), 那么还是ThreadLocal还是存在强引用, 不会被回收. ThreadLocalMap的Hash算法他自己实现了map结构, 数组由Entry组成的结构. 也实现自己的hash算法来解决散列表数组冲突问题 12345678//ThreadLocalMap中hash算法很简单, 这里i就是当前key在散列表中对应的数组下标位置, 最关键的就是threadLocalHashCode值的计算int i = key.threadLocalHashCode &amp; (len-1);//ThreadLocal中有一个属性为HASH_INCREMENT = 0x61c88647//每当创建一个ThreadLocal对象，这个ThreadLocal.nextHashCode 这个值就会增长 0x61c88647//这个值很特殊，它是斐波那契数 也叫黄金分割数. 好处是hash分布非常均匀. 但是还是可能hash冲突//由于他没有链表结构, 处理hash冲突的方式是继续向后查找, 如果找到为null就放进去 处理hash冲突: 通过 hash计算 ThreadLocal, 发现对应的数组下标为空, 直接插入 通过 hash计算 ThreadLocal, 发现hash冲突并key相等, 更新 通过 hash计算 ThreadLocal, 发现hash冲突并key不相等, 向后查找为null的槽位放进去 TODO https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/multi-thread/%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3ThreadLocal%E5%85%B3%E9%94%AE%E5%AD%97.md","link":"/blog/2019/04/01/%E5%B9%B6%E5%8F%911.ThreadLocal/"},{"title":"并发一些知识点","text":"杂七杂八的知识点 wait、sleep、 yield区别1234567891011121314new Object().wait(1000);1. wait是定义在Objetc中2. 只能在同步方法或同步块中3. 释放对象锁，进入等待队列。4. 只有调用notify()之后才有资格去竞争同步资源锁Thread.sleep(1000);1. sleep定义在线程对象中2. 只会让出CPU，不会让出同步资源锁。3. 不能被notify()唤醒4. 注意：调用t.sleep()不是t线程睡眠，而是当前线程睡眠。因为sleep()是静态方法Thread.yield();1. 和sleep差不多，区别就是让同等优先级在等待的线程执行。如果没有同等级优先级在等待的线程，就会继续执行 interrupt、interrupted、isInterrupted区别123456789101112new Thread().interrupt();1. 修改线程中断标志位new Thread().isInterrupted();1. 返回线程中断标志位Thread.interrupted();1. 会返回当前线程中断标志位，同时重置中断标志位false中断标志位作用？线程不应该由其他线程来强制中断或停止，应该由线程自己停止。1. 如果线程处于被阻塞状态（例如处于sleep, wait, join 等状态），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。仅此而已。2. 如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。 JMMJava内存模型（Java Memory Model） 工作内存：线程创建时jvm会为其创建一个，每个线程私有区域。线程对变量操作必须在工作内存中进行 主内存：共享内存 变量修改先从主内存拷贝到工作内存，修改之后写回主内存 volatilevolatile是java虚拟机轻量级的同步机制。 保证可见性。比如一个四核CPU，每个核里面都有一个L1、L2，然后CPU还有一个L3每个核共享 不保证原子性 禁止指令重排 保证线程可见性 CPU中线程执行到什么位置PC计数器记住、线程数据寄存器记住，线程做计算ALU来做。但是这样只能运行一个线程，如果线程切换需要把PC、register的数据放入一个地方保存再去运行新的线程。超线程：一个ALU切换，对应多个PC、register。比如四核八线程 乱序执行，比如A指令需要内存取数据很慢，所以会先执行下一条指令B。单例new对象的时候，需要volatile。new一个对象，默认属性；调用init方法初始化属性；指向对象；重排可能先指向，那么别的线程就可能获取到半初始化数据 系统底层如何实现数据一致性：如果MESI可以处理就用MESI，不能锁总线 系统底层如何保证有序性：内存屏障、锁总线 内存屏障：屏障两边的指令不能重排，保证有序。在volatile写操作上加了必须写完了才能读，读操作加了必须读完了才能写的屏障。hotsport使用lock实现 强软弱虚（和不存在一样，get不到。管理对堆内存，比如NIO是直接内存，jvm外面不会GC。监控回收对象，回收对堆内存） ThreadLocal：应用 &gt; spring的@Transaction注解之后两个方法区操作数据库拿到的connect都是一样的。 为什么用弱引用 12如果Key是强引用的话，比如线程set/get操作完之后，一定还是不能回收TL。因为当前线程TL.Map还是保存了TL。如果是弱引用，TL没了，然后只要GC就会被回收掉。注意：用完一定要TL.remove()，因为GC之后TL.Map的key是没有了，但是value还是存在。 CAS12CAS比较和交换，读取当前值1，+1之后再去读取当前值，如果还是1表示没有人动过这个值，赋值为1。如果不为1了，表示有人修改了这个值，重新读取重新加1，在比较是否为2...一直循环ABA加版本号解决 synchronized 底层使用lock cmpxchg汇编指令实现，但是cmpxchg不保证原子性。比如在CAS比较之后写入的时候，也可能会被别的线程修改。这时候就是lock可以使我修改值的时候其他cpu不能打断 可以使用jdk官方Maven依赖jol-core查看内存, 然后代码中ClassLayout.parseInstance(对象引用).toPrintable() new一个普通对象内存由四部分构成：markword对象头（锁的信息等）、class pointer类型指针（指向属于的class类）、instance data实例数据、padding对齐（一定要被8整除）。new Object多少字节：markword-8字节+class pointer-开启压缩情况下4字节+instance data-0字节+padding-4字节补齐 new-偏向锁-轻量级锁（无锁、自旋锁）-重量级锁 12345markword记录锁信息（1bit偏向锁位、2bit锁标志位）、分代年龄（4bit）1. 无锁态：0 - 012. 偏向锁：1 - 01 没有被占用，直接加偏向锁（加个线程id标签）。下一次来了发现又是上一次的线程，直接获取3. 轻量级锁：—— - 00 偏向锁已经存在A了，来了B。先判断A是否存活，如果没有存活了就直接变无锁，存活就升级轻量级锁。然后使用CAS把自己线程栈中LockRecord指针放入markword中，放入成功就加锁ok。优点用户态，缺点耗CPU4. 重量级锁：—— - 11 自旋次数、自旋线程数到达一定之后升级为重量级。用户态到内核态，所有线程进入锁的等待队列，什么时候到了什么时候获取锁 锁消除lock eliminate：比如在在方法中new StringBuffer，当使用append方法的时候，因为这个SB是局部变量栈私有，所以JVM会自动消除SB内部的锁。是通过对象逃逸？ 锁粗化lock coarsening：比如在一个方法里面for 1000{StringBuffer.append(str)}，这时候锁不会加锁解锁1000次，会直接粗化到for上面 sync底层实现： 12341. 代码：synchronized2. 字节码：monitorenter moniterexit3. 执行过程中锁升级4. 汇编指令：lock cmpxchg 注意：如果父类方法有synchronized方法, 子类继承是不会继承synchronized关键字, 因为synchronized不属于方法的一部分","link":"/blog/2020/01/01/%E5%B9%B6%E5%8F%910.%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"title":"AQS","text":"AQS是一个用来构建锁和同步器的框架, 使用AQS能简单且高效地构造出应用广泛的大量的同步器, 比如我们提到的ReentrantLock, Semaphore, 其他的诸如ReentrantReadWriteLock, SynchronousQueue, FutureTask等等皆是基于AQS的. AQS核心思想: 123456789101112131415161718AQS的全称为(AbstractQueuedSynchronizer, 抽象的队列式的同步器)基于许可的多线程控制：1. 进入共享区，发放许可2. 离开共享区，归还许可3. 如果许可用完了，放入同步等待队列排他锁(exclusive)和共享锁(shared)？在排他模式上，只有一个线程可以访问共享变量，而共享模式则允许多个线程同时访问。简单地说，重入锁是排他的；信号量是共享的。LockSupport- public static void park() : 如果没有可用许可，则挂起当前线程(停车)- public static void unpark(Thread thread)：给thread一个可用的许可，让它得以继续执行为了维护lock()操作引起的等待，所以需要同步等待队列。一个为了维护等待在条件变量上的等待线程，AQS又需要再维护一个条件变量等待队列，也就是那些由Condition.await()引起阻塞的线程。多个 请求锁12345678910111213141516171819202122232425262728293031# acquirepublic final void acquire(int arg) { //尝试获得许可， arg为许可的个数。对于重入锁来说，每次请求1个。 if (!tryAcquire(arg) &amp;&amp; // 如果tryAcquire 失败，则先使用addWaiter()将当前线程加入同步等待队列 // 然后继续尝试获得锁 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();}# 将当前线程加入到等待队列的队尾，并返回当前线程所在的结点private Node addWaiter(Node mode) { //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享） Node node = new Node(Thread.currentThread(), mode); //尝试快速方式直接放到队尾。 Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //上一步失败则通过enq入队。 //CAS&quot;自旋&quot;，直到成功加入队尾 enq(node); return node;} 条件变量代码解释 1234567891011121314151617181920212223242526272829303132333435private static ReentrantLock lock = new ReentrantLock();//lock对应的条件变量,可以创建多个private static Condition condition = lock.newCondition();public static void main(String[] args) throws InterruptedException { new Thread(() -&gt; { //获取独占锁 lock.lock(); try { System.out.println(&quot;thread1开始等待&quot;); //阻塞挂起thread1 condition.await(); System.out.println(&quot;thread1被唤醒&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;thread1&quot;).start(); Thread.sleep(1000); new Thread(() -&gt; { //因为thread1被condition.await()阻塞挂起，所以可以拿到锁 lock.lock(); System.out.println(&quot;thread2开始唤醒&quot;); //唤醒thread1 condition.signal(); System.out.println(&quot;thread2唤醒完成&quot;); //释放lock之后才能完全唤醒 lock.unlock(); }, &quot;thread2&quot;).start();} 请求资源, 是否空闲? 空闲: 将资源state设置为锁定状态, 当前请求线程设置为工作线程 不空闲: 添加到CLH队列中 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列. 就是不存在队列实例, 其实就是节点之间相互指向了. AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点Node来实现锁的分配 12345678910111213141516//共享变量，使用volatile修饰保证线程可见性private volatile int state;//状态信息通过protected方法操作//返回同步状态的当前值, 0表示初始值未占用protected final int getState() { return state;} // 设置同步状态的值protected final void setState(int newState) { state = newState;}//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} AQS使用模板方法: 1234567891011121314//该线程是否正在独占资源, 只有用到condition才需要去实现它isHeldExclusively()//独占方式. 尝试获取资源, 成功则返回true, 失败则返回falsetryAcquire(int)//独占方式. 尝试释放资源, 成功则返回true, 失败则返回falsetryRelease(int)//共享方式, 尝试获取资源. 负数表示失败; 0表示成功, 但没有剩余可用资源; 正数表示成功, 且有剩余资源tryAcquireShared(int)//共享方式, 尝试释放资源. 成功则返回true; 失败则返回falsetryReleaseShared(int) AQS组件: ReentrantLock Semaphore CountDownLatch CyclicBarrier ReadWriteLock","link":"/blog/2020/03/22/%E5%B9%B6%E5%8F%912.AQS/"},{"title":"AQS","text":"线程池 Executors弊端 FixedThreadPool和SingleThreadExecutor: 允许请求的队列长度为Integer.MAX_VALUE, 可能堆积大量的请求, 从而导致OOM CachedThreadPool和ScheduledThreadPool: 允许创建的线程数量为Integer.MAX_VALUE, 可能会创建大量线程, 从而导致OOM FixedThreadPool: 固定线程池, 队列长度Integer.MAX_VALUE SingleThreadExecutor: 只有一个线程的线程池, 队列长度Integer.MAX_VALUE CachedThreadPool: 线程数量为Integer.MAX_VALUE, 可变 ThreadPoolExecutor推荐使用ThreadPoolExecutor创建, 更加明确线程池的运行规则, 规避资源耗尽的风险 ThreadPoolExecutor构造参数解释: corePoolSize: 最小可以同时运行的线程数量 maximumPoolSize: 当队列中存放的任务达到队列容量的时候, 当前可以同时运行的线程数量变为最大线程数 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数, 如果达到的话, 新任务就会被存放在队列中 keepAliveTime: 当线程池中的线程数量大于corePoolSize的时候, 如果这时没有新的任务提交, 核心线程外的线程不会立即销毁, 而是会等待, 直到等待的时间超过了keepAliveTime才会被回收销毁 unit: keepAliveTime参数的时间单位 threadFactory: executor创建新线程的时候会用到 handler: 饱和策略 如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时, ThreadPoolTaskExecutor定义一些饱和策略: ThreadPoolExecutor.AbortPolicy(默认): 抛出RejectedExecutionException来拒绝新任务的处理. ThreadPoolExecutor.CallerRunsPolicy: 调用执行自己的线程运行任务, 也就是直接在调用execute方法的线程中运行(run)被拒绝的任务, 如果执行程序已关闭, 则会丢弃该任务. 因此这种策略会降低对于新任务提交速度, 影响程序的整体性能. 如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话, 你可以选择这个策略. ThreadPoolExecutor.DiscardPolicy: 不处理新任务, 直接丢弃掉. ThreadPoolExecutor.DiscardOldestPolicy: 此策略将丢弃最早的未处理的任务请求. 1234567891011121314151617181920212223242526272829303132333435import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class ThreadPoolExecutorDemo { private static final int CORE_POOL_SIZE = 5; private static final int MAX_POOL_SIZE = 10; private static final int QUEUE_CAPACITY = 100; private static final Long KEEP_ALIVE_TIME = 1L; public static void main(String[] args) { //使用阿里巴巴推荐的创建线程池的方式 //通过ThreadPoolExecutor构造函数自定义参数创建 ThreadPoolExecutor executor = new ThreadPoolExecutor( CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 10; i++) { //创建WorkerThread对象（WorkerThread类实现了Runnable 接口） Runnable worker = new MyRunnable(&quot;&quot; + i); //执行Runnable executor.execute(worker); } //终止线程池 executor.shutdown(); while (!executor.isTerminated()) { } System.out.println(&quot;Finished all threads&quot;); }} 线程池建议 线程池配置个数 CPU密集型任务(N+1) I/O密集型任务2N 不同的业务用不同的线程池 检测线程池运行状态: 比如使用Actuator组件 使用ThreadPoolExecutor创建线程池 别忘记给线程池命名 1234567//利用guava的ThreadFactoryBuilderThreadFactory threadFactory = new ThreadFactoryBuilder() .setNameFormat(threadNamePrefix + &quot;-%d&quot;) .setDaemon(true).build();ExecutorService threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory)//使用 class NamingThreadFactory implements ThreadFactory 自己实现","link":"/blog/2020/03/21/%E5%B9%B6%E5%8F%914.%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"title":"rocketmq入门","text":"rocketmq入门 整体介绍 天然支持集群模型, 负载均衡, 水平扩展能力 亿级别的消息堆积能力 采用零拷贝原理, 顺序写盘随机读 丰富API, 支持同步消息, 异步消息, 顺序消息, 延迟消息, 事务消息等 代码优秀, 底层通信框架采用Netty NIO框架 NameServer代替Zookeeper 支持消息失败重试机制, 消息可查询 开源社区活跃, 成熟度很高(经过双十一考验) 概念模型 producer: 消息生产者 consumer: 消息消费者 push consumer: 需要向consumer对象注册监听 pull consumer: 需要主动请求broker拉去消息 producer group: 生产者集合, 一般用于发送一类消息 consumer group: 消费者集合, 用于接收一类消息 broker: mq消息服务, 用于消息存储与生产消费转发 开始下载 修改runbroker.sh和runserver.sh中java_home地址还有设置的默认内存大小设置 123456789#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; JAVA_HOME=$HOME/jdk/java#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; JAVA_HOME=/usr/java#[ ! -e &quot;$JAVA_HOME/bin/java&quot; ] &amp;&amp; error_exit &quot;Please set the JAVA_HOME variable in your environment, We need java(x64)!&quot;export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home...JAVA_OPT=&quot;${JAVA_OPT} -server -Xms128m -Xmx128m -Xmn64m&quot; master配置 123456789101112131415161718192021brokerClusterName = DefaultCluster# Broker的名称， Master和Slave通过使用相同的Broker名称来表明相互关系brokerName = broker-a# 一个MasterBarker可以有多个Slave, 0表示Master ，大于0表示不同Slave的IDbrokerId = 0# 与fileReservedTime参数呼应，表明在几点做消息删除动作，默认值04表示凌晨4点deleteWhen = 04# 在磁盘上保存消息的时长，单位是小时，自动删除超时的消息 fileReservedTime = 48# brokerRole有3种：SYNC_MASTER、ASYNC_MASTER、SLAVE。 关键词SYNC和ASYNC表示Master和Slave之间同步消息的机制，# SYNC是当Slave和Master消息同步完成后，再返回发送成功的状态 brokerRole = ASYNC_MASTER# flushDiskType表示刷盘策略，分为SYNC_FLUSH 和 ASYNC_FLUSH两种，分别代表同步刷盘和异步刷盘。 # 同步刷盘情况下，消息真正写人磁盘后再返回成功状态；异步刷盘情况下，消息写人 page_cache 后就返回成功状态 flushDiskType = ASYNC_FLUSH# 自定义端口listenPort=10911# 存储消息以及一些配置信息的根目录#storePathRootDir=/Users/hjr/ENV/rocketmq/rocketmq1-master/store slave配置 12345678910111213141516171819brokerClusterName = DefaultCluster# Broker的名称， Master和Slave通过使用相同的Broker名称来表明相互关系brokerName = broker-a# 一个MasterBarker可以有多个Slave, 0表示Master ，大于0表示不同Slave的IDbrokerId = 1# 与fileReservedTime参数呼应，表明在几点做消息删除动作，默认值04表示凌晨4点deleteWhen = 04# 在磁盘上保存消息的时长，单位是小时，自动删除超时的消息 fileReservedTime = 48# brokerRole有3种：SYNC_MASTER、ASYNC_MASTER、SLAVE。 关键词SYNC和ASYNC表示Master和Slave之间同步消息的机制，# SYNC是当Slave和Master消息同步完成后，再返回发送成功的状态 brokerRole = SLAVE# flushDiskType表示刷盘策略，分为SYNC_FLUSH 和 ASYNC_FLUSH两种，分别代表同步刷盘和异步刷盘 。 # 同步刷盘情况下，消息真正写人磁盘后再返回成功状态；异步刷盘情况下，消息写人 page_cache 后就返回成功状态 flushDiskType = ASYNC_FLUSH# 自定义端口listenPort=10912# 存储消息以及一些配置信息的根目录#storePathRootDir=/Users/hjr/ENV/rocketmq/rocketmq1-slave/store 补充配置 namesrvAddr=127.0.0.1:9871; defaultTopicQueueNums=4 默认创建队列数 autoCreateTopicEnable=true 是否允许broker自动创建topic, 线上不建议开启 autoCreateSubscriptionGroup=true 是否允许自动创建订阅组, 线上不建议开启 listenPort=10911 broker对外端口 mapedFileSizeCommitLog=1073741824 每个commitLog文件大小, 默认1G mapedFileSizeConsumeQueue=300000 consumerQueue每个文件默认存30w条 diskMaxUsedSpaceRatio=80 监测物理文件磁盘空间, 80%做一些事情 storePathRootDir 存储路径 storePathCommitLog commitLog存储路径 storePathConsumeQueue 消费队列存储路径 storePathIndex 消息索引存储路径 storeCheckPoint 文件存储路径 abortFile abort文件存储路径 maxMessageSize=65536 限制消息大小 相关命令 关闭所有服务 sh mqshutdown namesrv | broker 查看日志tail -f ~/logs/rocketmqlogs/namesrv.log和tail -f ~/logs/rocketmqlogs/broker.log 查看broker是否连接上namesrv sh mqadmin clusterList -n localhost:9876 启动nohup sh mqnamesrv &amp;和nohup sh mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp; jps查看是否启动成功 rocketmq控制台搭建打开github连接 我这里使用docker操作 1234docker pull apacherocketmq/rocketmq-console:2.0.0docker run --name rocketmq_console -e &quot;JAVA_OPTS=-Drocketmq.namesrv.addr=10.98.91.171:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false&quot; -p 8080:8080 -t apacherocketmq/rocketmq-console:2.0.0 如果用127.0.0.1连接不上namesrv, 那就直接用本地ip 之后直接localhost:8080打开使用就好了 如果碰到异常com.alibaba.rocketmq.client.exception.MQClientException: No route info of this topic, test_topic, 关闭brokersh mqshutdown broker , 使用nohup sh mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp;打开就好了 简单案例pom文件 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;rocketmq&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;3.2.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 生产者 1234567891011121314151617181920212223242526package com.rocketmq.demo.simple;import com.alibaba.rocketmq.client.exception.MQBrokerException;import com.alibaba.rocketmq.client.exception.MQClientException;import com.alibaba.rocketmq.client.producer.DefaultMQProducer;import com.alibaba.rocketmq.client.producer.SendResult;import com.alibaba.rocketmq.common.message.Message;import com.alibaba.rocketmq.remoting.exception.RemotingException;public class Producer { public static final String NAME_SERVER = &quot;10.98.91.171:9876&quot;; public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException, MQBrokerException { DefaultMQProducer producer = new DefaultMQProducer(&quot;test_quick_producer_group&quot;); producer.setNamesrvAddr(NAME_SERVER); producer.start(); for (int i = 0; i &lt; 5; i++) { Message message = new Message(&quot;test_topic&quot;, &quot;TAG_A&quot;, &quot;KEY_A&quot;, (&quot;this is message : &quot; + i).getBytes()); SendResult sendResult = producer.send(message); System.out.println(&quot;sendResult = &quot; + sendResult); } }} 消费者 1234567891011121314151617181920212223242526272829303132333435363738package com.rocketmq.demo.simple;import com.alibaba.rocketmq.client.consumer.DefaultMQPushConsumer;import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import com.alibaba.rocketmq.client.consumer.listener.MessageListenerConcurrently;import com.alibaba.rocketmq.client.exception.MQClientException;import com.alibaba.rocketmq.common.consumer.ConsumeFromWhere;import com.alibaba.rocketmq.common.message.MessageExt;import java.util.List;import static com.rocketmq.demo.simple.Producer.NAME_SERVER;public class Consumer { public static void main(String[] args) throws MQClientException { DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;test_quick_consumer_group&quot;); consumer.setNamesrvAddr(NAME_SERVER); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET); consumer.subscribe(&quot;test_topic&quot;, &quot;*&quot;); consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) { MessageExt messageExt = list.get(0); String topic = messageExt.getTopic(); String tags = messageExt.getTags(); String keys = messageExt.getKeys(); String body = new String(messageExt.getBody()); System.out.println(&quot;topic = &quot; + topic + &quot;, tags = &quot; + tags+ &quot;, keys = &quot; + keys+ &quot;, body = &quot; + body); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); consumer.start(); System.out.println(&quot;消费端以及启动&quot;); }} 主从模式的时候, 期间master宕机了, slave还是依旧可以消费. 然后master重启之后会和从节点同步offset, 使其不会重复消费 消费的时候如果业务异常, 会在1s 5s 10s …之后不断重试15次, 怎么处理呢? 可以直接在消费代码try-catch, 在catch里面使用message.getReconsumer()获取重试次数. 如果重试了3次, 记录日志, 补偿业务代码, 直接返回success状态.","link":"/blog/2020/03/02/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-a1.rocketmq%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"rocketmq细节介绍","text":"rocketmq细节介绍 生产者介绍生产者核心参数 producerGroup: 组名, 组名不能相同 createTopicKey: 生产中一般是不能自己创建, 都是经过架构组封装, 我们申请之后才可以使用 defaultTopicQueueNums: 一个topic默认下面是4个队列 sendMsgTimeout: 单位ms, 发送超时 compressMsgBodyOverHowmuch: 发送消息太大了就会压缩发送, 默认发送压缩字节4096 retryTimesWhenSendFailed: 同步重发配置 retryAnotherBrokerWhenNotStoreOk: 没有存储成功是否可以存储在其他broker上, 默认false maxMessageSize: 最大消息设置, 默认128k … 主从同步解析同步信息为: 数据内容(commitLog): 实时同步, 同步message, 主要三个类(HAService, HAconnection, WaitNotfiyObject), 使用原生socket同步(性能最好) 元数据信息: slave才会启动定时任务开启同步, 使用netty, 同步topic配置信息/消费者偏移量/延迟偏移量/订阅组配置信息 123456789101112131415Master节点: AcceptSocketService: 接收slave节点连接 HAConnection: ReadSocketService: 读来自slave节点数据 WriteSocketService: 写入salve节点数据Slave节点: HAService: HAClient: 对Master节点连接,读写数据通信协议: 1. slave-&gt;master: 上报commitLog已经同步到的物理位置, maxPhyOffset commitLog最大的物理位置2. master-&gt;slave: 传输新的commitLog数据, fromPhyOffset, commitLog开始的物理位置(不断对比这两个值, 相等就同步, 不相等就不同步)3. size(传输commitLog数据长度)4. body(传输commitLog数据) 同步/异步发送消息核心实现: DefaultMQProducerImpl producer.send(Message msg) 同步, 有返回值 producer.send(Message msg, SendCallback sendCallback) 异步, 没有返回值 生产者消息返回状态 SEND_OK: 发送成功 FLUSH_DISK_TIMEOUT: 发送成功, 但是刷盘超时. 发送成功直接宕机, 消息可能投递失败. FLUSH_SLAVE_TIMEOUT: master同步到slave的时候超时 SLAVE_NOT_AVAILABLE: slave不可用 2/3/4情况可能导致消息丢失, 考虑是不是要重新发送 延迟投递消息发送到broker后(而不是发送的时候延迟), 要特定时间才会被consumer消费, 只支持固定精度的定时消息.主要类MessageStoreConfig配置类和ScheduleMessageService任务类. 使用: message.setDelayTimeLevel 消息发送要指定队列(MessageQueueSelector)默认一个topic四个队列, 默认会轮询队列去发送 1producer.send(message, new MessageQueueSelect(){}, 1) 消费者消费者核心参数 consumerFromWhere: 从哪开始消费(启动之后会上报offset, 下次启动从这个offset开始消费) CONSUME_FROM_LAST_OFFSET: 从队列尾部开始消费 CONSUME_FROM_FIRST_OFFSET: 从队列开始位置消费 CONSUME_FROM_TIMESTAMP: 指定具体时间点消费 allocateMessageQueueStrategy: 集群模式下, 消费策略, 默认 subscription: 订阅 offsetStore: 存储实际偏移量 consumerThreadMin/consumerThreadMax: consumer线程池调整 consumerConcurrentlyMaxSpan/pullThresholdForQueue: 流控, 单个队列并行消费的最大跨度/一个队列最大消费消息个数 pullinterval/pullBatchSize: 消息拉取时间间隔(pull模式)/一次拉取最大数据,最大32 consumerMessageBatchMaxSize: 默认1, 一次最大拉取几条消息 maxReconsumeTimes: 最大重试次数 messageModel: CLUSTERING(默认), BROADCASTING 消费模式CLUSTERING(默认): groupName相同表示一个集群, 在同一个集群下一个消息只会被消费一次. 达到天然负载均衡. 注意: 现在有TagA, TagB. 在集群模式下, consumerA订阅TagA, consumerB订阅TagB. 那么很多消费很可能消费不到, 因为集群模式下broker会分队列投递, 假设consumerA的订阅队列是queue1, 但是TagA的消息投递到了queue2中, 那么这个消息直接被过滤掉了. BROADCASTING: 在同一个集群下, 一条消息被每一个consumer消费. 如果要实现分Tag来消费的话, 两种方式. 1: 使用广播模式, 这样就不会丢消息了 2: 使用pull模式去自己拉取, 指定tag消费 消费者的groupName如果不同, 那就是不同的集群订阅, 都会收到一份完整的消息的. 消息存储核心-offset offset是消息消费进度的核心 offset指某个topic下的一条消息, 在某个MessageQueue里面的位置 offset可以定位到这条消息 offset存储: 远程文件类型/本地文件类型 集群模式使用远程模式存储(RemoteBrokerOffsetStore) 广播模式使用本地模式存储(LocalFileOffsetStore) 如果使用pull去拉取消息, 就需要自己维护offset了 pushConsumer push(服务器推送): 会导致server压力很大, 而且client消费能力不一致, 导致client消息堆积. pull(客户端拉取): 拉取时间间隔很难控制, 如果过长导致消息消费不及时, 过短导致client浪费性能. pull还要自己维护offset DefaultMQPushConsumer是使用长轮询模式实现的: client主动发起请求, 如果有消息直接返回; 如果没与消息, broker为做一个长时间的阻塞(默认15s, 其实是阻塞5s三次), 15s内有消息直接返回, 到了15s还没有消息, 返回空结果. 缺点: 阻塞的时候consumer会消耗性能, 所以这里需要保证consumer数目在一定可控范围内, 不然会溢出. pullConsumerDefaultMQPullConsumer三步骤: 获取MessageQueue遍历 维护offsetStore 根据不同的消息状态做不同处理 具体示例代码可以看官方rocketmq-api下面的PullConsumer, 或者PullScheduleService 12345678910111213141516171819202122232425262728293031323334353637383940DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(&quot;test_quick_consumer_group&quot;);consumer.setNamesrvAddr(NAME_SERVER);//指定topic下面获取所有的MessageQueueSet&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(&quot;test_topic&quot;);for (MessageQueue mq : mqs) { System.out.println(&quot;MessageQueue = &quot; + mq); SINGLE_MQ: while (true){ try{ //TODO 自己维护offset long offset = 0; //从queue中获取数据, 从什么位置开始拉取数据, 单次最多拉取32条记录 PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, offset, 32); switch (pullResult.getPullStatus()){ case FOUND://找到消息处理 List&lt;MessageExt&gt; list = pullResult.getMsgFoundList(); for (MessageExt messageExt : list) { System.out.println(&quot;消费消息: &quot; + new String(messageExt.getBody())); } break; case NO_NEW_MSG: System.out.println(&quot;没有新消息啦, 接下啦直接退出while(true)循环&quot;); break SINGLE_MQ; case NO_MATCHED_MSG: System.out.println(&quot;没有匹配消息&quot;); break; case OFFSET_ILLEGAL: break; default: break; } } catch (InterruptedException e) { e.printStackTrace(); } catch (RemotingException e) { e.printStackTrace(); } catch (MQBrokerException e) { e.printStackTrace(); } }}consumer.start(); 高可用同步/异步刷盘:消息存储: 内存+磁盘存储 同步刷盘: producer发送到broker中, 存储到内存成功后, 立即通知刷盘机制, 刷盘成功后返回发送成功. 异步刷盘: producer发送到broker中, 存储到内存成功后. broker就直接返回给producer发送成功的消息. 当内存堆积到一定程度, 触发顺序写机制, 写入磁盘中. 优点: 吞吐量非常高 同步/异步复制:master-slave角色的时候: 同步复制: master写盘成功同步到slave之后, 才会返回给producer发送成功. 异步复制: master写盘成功立即返回producer发送成功, 异步复制的任务会同步到slave. 生产中建议: 同步双写(两个master一个宕机, 至少还有一个保存到了消息磁盘里面), 异步刷盘. 当master繁忙或不可用时, 可以自动切换到slave读取消息. NameServer协调者整个集群的状态服务器, 它们是相互独立的(热备份). 为啥不用zk? NameServer是独立的, 而zk是有leader, follower等角色, 还有一系列投票机制, 很多功能用不上. NameServer只需要rpc去维护想要维护的一些简单数据就行了, 代码简单稳定, 可维护性高 主要维护信息有: HashMap&lt;String/*topic*/, List&lt;QueueData&gt;&gt; topicQueueTable HashMap&lt;String/*brokerName*/, BrokerData&gt; brokerAddrTable HashMap&lt;String/*clusterName*/, Set&lt;String/*brokerName*/&gt;&gt; clusterAddrTable HashMap&lt;String/*brokerAddr*/, BrokerLiveInfo&gt; brokerLiveTable HashMap&lt;String/*brokerAddr*/, List&lt;String/*FilterServer*/&gt;&gt; filterServerTable (不用) 零拷贝正常服务器中文件数据通过网络传输到客户端的流程: 应用程序调用read函数, cpu从用户态切换到内核态, 此时DMA引擎直接将磁盘上数据读取到内核缓冲区 将内核缓冲区复制到用户空间缓冲区, 内存复制需要cpu参与, 复制结束, cpu状态由内核态切换到用户态 用户空间的数据发送到客户端，通过调用write函数. cpu状态由用户态转换到内核态。然后用户缓冲区数据拷贝到内核socket发送缓冲区，这个时候的复制也需要cpu进行参与 最后socket缓冲区中的数据需要复制到网卡缓冲区中，由网卡发送到客户端，然后cpu状态切换到用户态 12read(file, tmp_buf, len);write(socket, tmp_buf, len); 发生了2次cpu copy和2次DMA copy，以及发生了数次cpu状态切换. 因此所谓的零拷贝就是，让其中的2次cpu拷贝省略掉，因为这两次cpu拷贝的数据其实已经在内存中，没有必要再让cpu参与进来进行数据的拷贝，浪费cpu 零拷贝的实现方式有两种： mmap结合write(rocketmq使用): mmap通过虚拟内存映射，让多个虚拟地址指向同一个物理内存地址，用户空间的虚拟地址和内核空间的虚拟地址指向同一个物理内存地址，这样用户空间和内核空间共享同一个内存数据。这样DMA引擎从磁盘上加载的数据不需要在内核空间和用户空间进行复制，减少了一次cpu拷贝。 sendfile: sendfile通过系统调用，并且规定了in_fd文件描述符必须是可以mmap的，sendfile只能将文件数据发送到socket中，sendfile减少了一次cpu状态的切换 持久化策略顺序读, 随机写 CommitLog 是消息存储的物理文件，所有消息主题的消息都存储在 CommitLog 文件中，每个 Broker 上的 CommitLog 被当前机器上的所有 ConsumeQueue 共享。CommitLog 中的文件默认大小为1G，可以动态配置；当一个文件写满以后，会生成一个新的 CommitLog 文件。所有的 Topic 数据是顺序写入在 CommitLog 文件中的。 ConsumeQueue 是消息消费的逻辑队列，消息达到 CommitLog文件后将被异步转发到消息消费队列，供消息消费者消费，这里面包含 MessageQueue在CommitLog中的物理位置偏移量Offset，消息实体内容的大小和Message Tag 的 hash 值。每个文件默认大小约为600W个字节，如果文件满了后会也会生成一个新的文件。 IndexFile 是消息索引文件，Index 索引文件提供了对 CommitLog 进行数据检索，提供了一种通过 key 或者时间区间来查找 CommitLog 中的消息的方法。在物理存储中，文件名是以创建的时间戳命名，固定的单个 IndexFile 大小大概为 400M，一个 IndexFile 可以保存 2000W 个索引。 顺序消息 全局顺序: 某个topic所有消息都要顺序消费 局部顺序: 同一个订单的三个消息能顺序消费. 比如订单生成, 付款, 发货需要保持顺序消费 默认情况不保证顺序消费, 比如创建一个topic, 默认四个写四个读队列. 这时候消息可能写入任意一个队列中, 在读取的时候可能有多个consumer, 每个consumer可能启动多个线程并行消费, 所以不能保证顺序消费. 全局顺序: topic读写队列设置为1个, producer和consumer并发设置为1个, 但是这样性能就很差了, 不推荐. 局部顺序: 生产者 使用producer.send(Message msg, MessageQueueSelector(), Object arg)来发送消息, 这里arg传递orderId. MessageQueueSelector里面第三个参数其实对应arg传递的orderId. 可以直接根据orderId取余放入相应的同一个队列. 消费者 使用consumer.registerMessageListener(new MessageListenerOrderly(), 注意这里还是可以设置setConsumeThreadMin, setConsumeThreadMax等并发参数. 因为MessageListenerOrderly不是禁止并发处理, 而是在每个Consumer Queue加锁, 这样同一个Consumer Queue只能消费一个消息. 重复消费问题rocketmq是确保一定投递, 因为投递成功但是返回成功状态遇到了网络波动, 就会重复投递. setRetryTimesWhenSendFailed同步方式下设置自动重试次数, 默认2次. 处理方法: 消费时保持冥等性 维持一个已消费记录, 消费前查询是否消费过此消息 消息过滤TAG过滤对一个应用来说，尽可能只用一个 Topic, 不同的消息子类型用Tag来标识（每条消息只能有一个Tag），服务器端基于Tag进行过滤, 并不需要读取消息体的内容，所以效率很高. ConsumerQueue存储格式中存有Message Tag Hashcode, 过滤的时候直接对比hashcode就可以了, 在消费的时候会对比完整的Tag字符串, 所以不会有hash冲突造成的误读. 1consumer.subscribe(&quot;TopicTest&quot;, &quot;TagA | TagB | TagC&quot;); SQL表达式过滤1234// 指定标签Message msg = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, (&quot;Hello RocketMQ&quot;).getBytes(RemotingHelper.DEFAULT_CHARSET));// 添加属性 amsg.putUserProperty(&quot;a&quot;, 5); 1234consumer.subscribe(&quot;TopicTest&quot;, MessageSelector.bySql( &quot;(TAGS is not null and TAGS in ('TagA', 'TagB'))&quot; + &quot;and (a is not null and a between 0 3)&quot;)); Filter ServerTODO 优化发送消费能力提高Consumer处理能力 添加consumer实例数(不能超过topic下readQueue数量, 不然无效), 提高单个consumer并行线程数consumeThreadMin, consumeThreadMax 以批量方式进行消费 检测延时情况，跳过非重要消息 建议把一个Topic的Message Queue数设置为16, 这样就算consumer只有四台, 也可以扩容到16. 提高producer发送速度 不重要的, 比如日志可以使用oneway方式发送(只发送不等待应答) Producer 的并发量，使用多个Producer同时发送, 不用担心刷盘速度(顺序写和零拷贝)超快 mq分布式事务流程: producer发送消息到MQ集群, 这时候消息对消费端是不可见的(半消息). 同时运行本地事务, -100块钱 本地事务成功, 发送确认半消息到MQ集群; 本地事务失败, 发送删除半消息 事务A成功了, 之后就会发送消息给消费端消费, 消费失败就重试, 一直重试. 除非代码问题或者服务器宕机, 都是可以成功的, 这种情况人工处理就好了 假设半消息确认或者删除的时候网络丢包, 怎么处理呢? rocketmq里面会有一个定时任务去扫描半消息, 如果半消息一直没有存在, 就会回查producer端, 看看事务A是否成功, 再去处理半消息 实现可以参考 https://zhuanlan.zhihu.com/p/115553176 或者代码https://github.com/jishusc/bfxy-master","link":"/blog/2020/03/02/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-a2.rocketmq%E4%BB%8B%E7%BB%8D/"},{"title":"RabbitMQ2","text":"RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。以前用于金融起家 发送方确认机制有时候一些消息很重要, 我们必须确定消息到达了broker, 这里就有两个方式来确定 RabbitMQ为我们提供了两种方式： 通过AMQP事务机制实现，这也是AMQP协议层面提供的解决方案； 通过将channel设置成confirm模式来实现； 事务就是说在发送的时候如果broker崩溃或者其他原因抛出异常, 我们就可以回滚事务. 主要有三个方法: txSelect(), txCommit(), txRollback() 123456789try { channel.txSelect(); channel.basicPublish(exchange, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes()); int result = 1 / 0; channel.txCommit();} catch (Exception e) { e.printStackTrace(); channel.txRollback();} 其实这边RabbitMQ发送的时候多了这几个步骤 1234client发送Tx.Selectbroker发送Tx.Select-Ok(之后publish)client发送Tx.Commitbroker发送Tx.Commit-Ok 如果是回滚操作的话 1234client发送Tx.Selectbroker发送Tx.Select-Ok(之后publish)client发送Tx.Rollbackbroker发送Tx.Rollback-Ok 但是这种方式来确定有一定的弊端, 就是这样来回确认消耗很大, 所以对于性能损失比较大的. 会降低RabbitMQ的吞吐量 这里我们可以使用Confirm模式 Confirm 简介生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号 confirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。 在channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack 。 12# 将autoAck设置为false即可。String basicConsume(String queue, boolean autoAck, Consumer callback); 消费者确认模式123basic.ack 积极（positive）确认，表示消费者成功处理了消息basic.nack 消极（negative）确认，表示消费者没有成功处理消息，仍然删除消息basic.reject 相比nack多了一个限制，表示消费者没有成功处理消息，仍然删除消息 多次确认批量确认，为了减少网络负载。通过设置ack method的multiple属性为true，basic.reject没有这个属性，因此引入basic.nack作为协议扩展。 假如有delivery tags 5,6,7,8在channel Ch上未确认，当一个确认帧（acknowledgement frame）到达携带了delivery_tag为8并且multiple为true, 那么5,6,7,8都会被确认。 忘记ACK只能说后果很严重，因为没有ack的话，RabbitMQ Server会重新分发，并且RabbitMQ Server不会再发送数据给它（直至Server收到ack才会再次发送消息，参看测试用例），因为Server认为这个Consumer处理能力有限。这样就导致消息在RabbitMQ Server上堆积，最终造成内存泄露。 如何排查可以使用以下命令查看没有被ACK的消息，如果有大量消息，那八九不离十就是忘记ack了。 1sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged ACK机制可以起到限流的作用，比如在消费者处理后，sleep一段时间，然后再ACK，这可以帮助消费者负载均衡。 Channel Prefetch Setting (QoS)consumer为了避免消息缓冲区越界，通过设置basic.qos方法的prefetch count参数，这个参数指定了channel上最大未确认的消息数。 达到这个上限后，mq不会继续向channel上投递消息。 由于消息投递和consumer消息确认都是异步的，因此prefetch value如果重新设置了，并且此时channel上还有正在投递的消息， 会临时出现channel上未确认的消息超过prefetch的上限。 重复确认和未知的tags如果client确认同一个delivery tag超过一次，rabbitmq会产生channel error 例如 PRECONDITION_FAILED - unknown delivery tag 100. 还有client确认了一个未知的delivery tag，也会报这个错误。 实例代码生产者 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SendAync { private static final String QUEUE_NAME = &quot;TEST_QUEUE&quot;; // 开启confirm mode模式的示例代码 public static void main(String[] args) throws IOException, InterruptedException, TimeoutException { // 初始化连接工厂 ConnectionFactory factory = new ConnectionFactory();// 设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;);// 创建一个新的连接 Connection connection = factory.newConnection(); // 创建通道channel Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, true, false, false, null); // 设置开启confirm mode模式 channel.confirmSelect(); channel.addConfirmListener(new ConfirmListener() { @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException { System.out.println(&quot;publisher failure deliveryTag=&quot; + deliveryTag + &quot;| multiple=&quot; + multiple); } @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException { // if multiple=true then 表示deliveryTag序号之前的所有消息都投递成功 // if multiple=false then 表示仅deliveryTag序号的消息投递成功 System.out.println(&quot;publisher success deliveryTag=&quot; + deliveryTag + &quot;| multiple=&quot; + multiple); } }); // 循环发送持久化消息，消息内容为helloWorld for (long i = 0; i &lt; 100; ++i) { channel.basicPublish(&quot;&quot;, QUEUE_NAME, MessageProperties.PERSISTENT_BASIC, (&quot;helloWorld === &quot;+ i).getBytes()); } // 关键：阻塞等待100条消息处理完毕，如果存在nack未处理成功的消息则抛出IOException; // 如果在non-Confirm mode of channel下调用此方法则抛出IllegalStateException异常; channel.waitForConfirmsOrDie(); //或关键：等待所有消息的确认，如果处理成功则返回true，否则返回false boolean flag = channel.waitForConfirms(); }} 消费者 12345678910111213141516171819202122232425262728293031323334353637383940public class RecvAync { private final static String QUEUE_NAME = &quot;TEST_QUEUE&quot;; public static void main(String[] argv) throws Exception { // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory();// 设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;);// 创建一个新的连接 Connection connection = factory.newConnection();// 创建一个频道 final Channel channel = connection.createChannel(); channel.confirmSelect();// 声明要关注的队列, 参数2(durable)表示此队列不要持久化,如果rabbitMQ服务器挂了数据丢失 channel.queueDeclare(QUEUE_NAME, true, false, false, null); // 每次从队列中只能获取一个消息, 避免一次强占多个消息. 消费完才能再次获取消息 channel.basicQos(1);// DefaultConsumer类实现了Consumer接口，通过传入一个频道，告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { try { Thread.sleep(1000); String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot;A 处理消息完毕:&quot; + message); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 消息处理完成确认 channel.basicAck(envelope.getDeliveryTag(), false); } } }; // 消息消费完成确认 channel.basicConsume(QUEUE_NAME, false, consumer); }}","link":"/blog/2018/02/03/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97b2.rabbitmq%E6%B6%88%E6%81%AF%E7%A1%AE%E8%AE%A4/"},{"title":"RabbitMQ3","text":"RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。以前用于金融起家 每一个 RabbitMQ 服务器都能创建虚拟的消息服务器，我们称之为虚拟主机(virtual host),简称为vhost。每一个vhost本质上是一个独立的小型RabbitMQ服务器，拥有自己独立的队列、交换器及绑定关系等，井且它拥有自己独立的权限。 vhost就像是虚拟机与物理服务器一样，它们在各个实例间提供逻辑上的分离，为不同程序安全保密地运行数据，它既能将同一个RabbitMQ中的众多客户区分开，又可以避免队列和交换器等命名冲突。 vhost之间是绝对隔离的，无法将vhostl中的交换器与vhost2中的队列进行绑定，这样既保证了安全性，又可以确保可移植性。如果在使用RabbitMQ达到一定规模的时候，建议用户对业务功能、场景进行归类区分，并为之分配独立的vhost. 默认vhost是/, 默认用户名密码为guest rabbitmqctlvhost命令[]表示可选参数, {}表示必选参数 123rabbitmqctl add_vhost vhostl //新增vhost为vhost1rabbitmqctl list vhosts //查看当前所有vhostrabbitmqctl delete_vhost vhost1 //删除vhost1, 同时会删除里面所有内容(交换器/队列等所有信息) AMQP协议中并没有指定权限在vhost级别还是在服务器级别实现，由具体的应用自定义。在RabbitMQ 中，权限控制则是以vhost为单位的。当创建一个用户时，用户通常会被指派给至少一个vhost，并且只能访问被指派的vhost内的队列、交换器和绑定关系等。因此，RabbitMQ中的授予权限是指在vhost级别对用户而言的权限授予。 权限命令1234rabbitmqctl set permissions [-p vhost] {user} {conf} {write} {read} //添加权限rabbitmqctl clear_permissions [-p vhost] {username} //清除权限rabbitmqctl list permissions [-p vhost] //查看vhost下面的权限rabbitmqctl list user permissions {username} //查看用户权限 其中各个参数的含义如下所述。 vhost: 授予用户访问权限的 vhost 名称，可以设置为默认值，即 vhost 为”/“ user: 可以访问指定vhost的用户名。 conf: 一个用于匹配用户在哪些资源上拥有可配置权限的正则表达式 write: 一个用于匹配用户在哪些资源上拥有可写权限的正则表达式 read: 一个用于匹配用户在哪些资源上拥有可读权限的正则表达式 可配直指的是队列和交换器的创建及删除之类的操作; 可写指的是发布消息; 可读指与消息有关的操作,包括读取消息及清空整个队列等。 用户命令1234567rabbitmqctl add user {username} {password} //添加用户rabbitmqctl change_password {username} {newpassword} //修改用户密码rabbitmqctl clear password {username} //清除密码, 这样用户就不能登录了rabbitmqctl authenticate_user {username} {password} //验证用户rabbitmqctl delete user {username} //删除用户rabbitmqctl list users //用户列表, 后面会跟着用户角色rabbitmqctl set user tags {username) {tag ...} //设置角色0-n个 用户的角色分为 5 种类型。 none: 无任何角色。新创建的用户的角色默认为 none management: 可以访问 Web 管理页面。 policymaker: 包含 management 的所有权限，并且可以管理策略Policy和参数Parameter monitoring: 包含 management 的所有权限，并且可以看到所有连接、信道及节点相关的信息。 administartor: 包含 monitoring 的所有权限，井且可以管理用户 、虚拟主机、权限、策略、参数等。administator代表了最高的权限 。 集群123456rabbitmqctl join_cluster {cluster_node} [--ram] //加入集群rabbitmqctl cluster_status //显示集群状态rabbitmqctl change_cluster_node_type {disclram} //修改集群节点的类型rabbitmqctl forget_cluster_node [--offline] //将节点从集群中删除，允许离线执行rabbitmqctl update_cluster_nodes {clusternode} //在集群中的节点应用启动前咨询clusternode节点的最新信息，井更新相应的集群信息... 服务状态1234567891011rabbitmqctl list_queues [-p vhost] [queueinfoitem ...]rabbitmqctl list_exchanges [-p vhost] [exchangeinfoitem ...]rabbitmqctl list_bindings [-p vhost] [bindinginfoitem ...]rabbitmqctl list_connections [connectioninfoitem ...]rabbitmqctl list_ channels [channelinfoitem ... ]rabbitmqctl list_consumers [-p vhost]rabbitmqctl status //显示 Broker 的状态，比如当前 Erlang 节点上运行的应用程序、 RabbitMQ/Erlang 的版本信息、 OS 的名称、内存及文件描述符等统计信息rabbitmqctl node_health_check //对 RabbitMQ 节点进行健康检查，确认应用是否正常运行、list queues和list channels是否能够正常返回等rabbitmqctl environment //显示每个运行程序环境中每个变量的名称和值rabbitmqctl report //为所有服务器状态生成一个服务器状态报告，井将输出重定向到一个文件rabbitmqctl eval {expr} //略 插件RabbitMQ management插件可以提供Web管理界面, 当然RabbitMQ 提供了很多的插件，默认存放在$RABBITMQ HOME/plugins目录下. 123rabbitmq-plugins list //查看插件使用情况[E]的为显式启动，而[e]为隐式启动 rabbitmq-plugins enable [plugin-name] //开启插件rabbitmq-plugins disable [plugin-name] rabbitmq_management插件开启后需要重启, http://localhost:15672/ 访问 HTTP API 接口管理也不喜欢用, 还不如直接用界面","link":"/blog/2018/02/04/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97b3.rabbitmqctl/"},{"title":"常见排序算法","text":"常见排序算法 交换排序冒泡排序冒泡排序是稳定的排序算法，最容易实现的排序, 最坏的情况是每次都需要交换, 共需遍历并交换将近n²/2次, 时间复杂度为O(n²). 最佳的情况是内循环遍历一次后发现排序是对的, 因此退出循环, 时间复杂度为O(n). 平均来讲, 时间复杂度为O(n²). 由于冒泡排序中只有缓存的temp变量需要内存空间, 因此空间复杂度为常量O(1)。 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n2) O(n) O(n2) O(1) 12345678910111213141516171819202122232425262728293031323334353637import java.util.Arrays;/** * 冒泡排序 * Created by zhoujunfu on 2018/8/2. */public class BubbleSort { public static void sort(int[] array) { if (array == null || array.length == 0) { return; } int length = array.length; //外层：需要length-1次循环比较 for (int i = 0; i &lt; length - 1; i++) { //内层：每次循环需要两两比较的次数，每次比较后，都会将当前最大的数放到最后位置，所以每次比较次数递减一次 for (int j = 0; j &lt; length - 1 - i; j++) { if (array[j] &gt; array[j+1]) { //交换数组array的j和j+1位置的数据 swap(array, j, j+1); } } } } /** * 交换数组array的i和j位置的数据 * @param array 数组 * @param i 下标i * @param j 下标j */ public static void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; }} 快速排序快速排序(Quicksort)是对冒泡排序的一种改进 快速排序并不稳定，快速排序每次交换的元素都有可能不是相邻的, 因此它有可能打破原来值为相同的元素之间的顺序。 算法说明看这个https://wiki.jikexueyuan.com/project/easy-learn-algorithm/fast-sort.html 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlogn) O(nlogn) O(n2) O(1) 1234566 1 2 7 9 3 4 5 10 8 //这个是最初始数据, 先以6为基准值. 注意每次都是先从右往左找6 1 2 5 9 3 4 7 10 8 //从右往左找&lt;6就是5, 从左往右找&gt;6就是7, 然后交换6 1 2 5 4 3 9 7 10 8 //从右往左找&lt;6就是4, 从左往右找&gt;6就是9, 然后交换3 1 2 5 4 6 9 7 10 8 //从右往左找&lt;6就是3, 从左往右找&gt;6发现下标相遇了. 那么把基准值6和相遇的下标的值3交换最后就是递归6左边的和6右边的继续以上步骤 123456789101112131415161718192021222324252627282930313233343536373839404142public class QuickSort {public static void main(String[] args) { int[] arr = new int[] {9,4,6,8,3,10,4,6}; quickSort(arr,0,arr.length - 1); System.out.println(Arrays.toString(arr)); }public static void quickSort(int[] arr,int low,int high) { int p,i,j,temp; if(low &gt;= high) { return; } //p就是基准数,这里就是每个数组的第一个 p = arr[low]; i = low; j = high; while(i &lt; j) { //右边当发现小于p的值时停止循环 while(arr[j] &gt;= p &amp;&amp; i &lt; j) { j--; } //这里一定是右边开始，上下这两个循环不能调换（下面有解析，可以先想想） //左边当发现大于p的值时停止循环 while(arr[i] &lt;= p &amp;&amp; i &lt; j) { i++; } //交换 temp = arr[j]; arr[j] = arr[i]; arr[i] = temp; } arr[low] = arr[i];//这里的arr[i]一定是停小于p的，经过i、j交换后i处的值一定是小于p的(j先走) arr[i] = p; quickSort(arr,low,j-1); //对左边快排 quickSort(arr,j+1,high); //对右边快排 }} 插入排序直接插入排序12346 1 2 7 9 3 4 5 10 8 //从第一个元素开始, 认为该元素已经排序好了1 6 2 7 9 3 4 5 10 8 //取第二个元素1, 插入6前面1 2 6 7 9 3 4 5 10 8 //取第三个元素2, 插入1 6之间... 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n2) O(n) O(n2) O(1) 1234567891011121314151617public class InsertSort { public static void main(String[] args) { int[] arr = new int[] { 2, -3, 23, 3, -12, -1, 2, 34, -30, 12, 2 }; for (int i = 1; i &lt; arr.length; i++) { // 依次遍历索引 i 之前的元素，直到找到合适的插入位置 for (int j = i; j &gt; 0; j--) { if (arr[j] &lt; arr[j - 1]) { int temp = arr[j]; arr[j] = arr[j - 1]; arr[j - 1] = temp; } } } System.out.println(Arrays.toString(arr)); }} 希尔排序12349 1 2 5 7 4 8 6 3 5 //长度为10, 不妨设gap1 = N / 2 = 5. 所以距离为5的组成一组, 比如9 1 2 5 7 4, 1 2 5 7 4 8...,分为5组分别直接插入排序3 5 9 8 6 5 7 //把上次的gap缩小一半取整, 即gap2 = 2. 分别为3 5 9, 5 9 8, 9 8 6...直接插入排序2 1 4 3 5 6 5 7 8 9 //gap缩小一半=1, 最后一次排序就好了 123456789101112131415161718public class ShellSort { public static void sort(int[] arr) { int gap = arr.length / 2; for (;gap &gt; 0; gap = gap/2) { for (int j = 0; (j + gap) &lt; arr.length; j++) { //不断缩小gap，直到1为止 for (int k = 0; (k + gap) &lt; arr.length; k+=gap) { //使用当前gap进行组内插入排序 if (arr[k] &gt; arr[k+gap]) { //交换操作 arr[k] = arr[k] + arr[k+gap]; arr[k+gap] = arr[k] - arr[k+gap]; arr[k] = arr[k] - arr[k+gap]; System.out.println(&quot; Sorting: &quot; + Arrays.toString(arr)); } } } } }} 选择排序简单选择排序 从待排序序列中，找到关键字最小的元素； 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换； 从余下的 N - 1 个元素中，找出关键字最小的元素，重复1 2步，直到排序结束 不稳定排序算法，选择排序的简单和直观名副其实，这也造就了它出了名的慢性子，无论是哪种情况，哪怕原数组已排序完成，它也将花费将近n²/2次遍历来确认一遍。 唯一值得高兴的是，它并不耗费额外的内存空间 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n2) O(n2) O(n2) O(1) 12345678910111213141516public class SelectSort { public static void sort(int[] arr) { for (int i = 0; i &lt; arr.length - 1; i++) { int min = i; for (int j = i+1; j &lt; arr.length; j ++) { //选出之后待排序中值最小的位置 if (arr[j] &lt; arr[min]) { min = j; } } if (min != i) { arr[min] = arr[i] + arr[min]; arr[i] = arr[min] - arr[i]; arr[min] = arr[min] - arr[i]; } } } 堆排序归并排序123459 1 2 5 7 4 8 6 3 5 //把相邻两个数字归并排序, 形成19 25 47 68 3519 25 47 68 35 //再把相邻两组归并排序, 形成1259 4678 351259 4678 35 //再归并, 形成 12456789 351234556789 稳定排序算法，从效率上看，归并排序可算是排序算法中的”佼佼者”. 假设数组长度为n，那么拆分数组共需logn, 又每步都是一个普通的合并子数组的过程，时间复杂度为O(n)， 故其综合时间复杂度为O(nlogn)。另一方面， 归并排序多次递归过程中拆分的子数组需要保存在内存空间， 其空间复杂度为O(n)。 和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(nlogn）的时间复杂度。代价是需要额外的内存空间 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlogn) O(nlogn) O(nlogn) O(n) 123456789101112131415161718192021222324252627282930313233343536373839public class MergeSort { public static int[] sort(int [] a) { if (a.length &lt;= 1) { return a; } int num = a.length &gt;&gt; 1; int[] left = Arrays.copyOfRange(a, 0, num); int[] right = Arrays.copyOfRange(a, num, a.length); return mergeTwoArray(sort(left), sort(right)); } public static int[] mergeTwoArray(int[] a, int[] b) { int i = 0, j = 0, k = 0; int[] result = new int[a.length + b.length]; // 申请额外空间保存归并之后数据 while (i &lt; a.length &amp;&amp; j &lt; b.length) { //选取两个序列中的较小值放入新数组 if (a[i] &lt;= b[j]) { result[k++] = a[i++]; } else { result[k++] = b[j++]; } } while (i &lt; a.length) { //序列a中多余的元素移入新数组 result[k++] = a[i++]; } while (j &lt; b.length) {//序列b中多余的元素移入新数组 result[k++] = b[j++]; } return result; } public static void main(String[] args) { int[] b = {3, 1, 5, 4}; System.out.println(Arrays.toString(sort(b))); }} 基数排序面试必备：八种排序算法原理及Java实现","link":"/blog/2018/02/05/%E7%AE%97%E6%B3%95-1.%E6%8E%92%E5%BA%8F/"},{"title":"LRU算法","text":"LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。 使用LinkedHashMap实现在Java中，其实LinkedHashMap已经实现了LRU缓存淘汰算法，需要在构造函数第三个参数传入true，表示按照时间顺序访问。可以直接继承LinkedHashMap来实现。 但是LinkedHashMap会自动扩容，如果想实现限制容量删除队列顶端元素，需要重写removeEldestEntry()方法，当map里面的元素个数大于了缓存最大容量，删除链表的顶端元素。 12345678910111213141516171819202122232425262728293031323334import com.google.common.base.Joiner;import java.util.LinkedHashMap;import java.util.Map;public class LRULinkedHashMap&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt; { private int capacity; LRULinkedHashMap(int capacity) { // 初始大小，0.75是装载因子，true是表示按照访问时间排序 super(capacity, 0.75f, true); //传入指定的缓存最大容量 this.capacity = capacity; } /** * 实现LRU的关键方法，put之后会调用afterNodeInsertion方法. * 如果map里面的元素个数大于了缓存最大容量，则删除链表的顶端元素 */ @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) { return size() &gt; capacity; } public static void main(String[] args) { LRULinkedHashMap&lt;Integer, String&gt; lru = new LRULinkedHashMap&lt;&gt;(8); for (int i = 0; i &lt; 15; i++) { lru.put(i, &quot;this is &quot; + i); System.out.println(&quot;lru = &quot; + Joiner.on(&quot;,&quot;).withKeyValueSeparator(&quot;:&quot;).join(lru)); } }} 使用双向链表结构+HashMap实现可以自定义双向链表的结构，这里定义了内部类Node，存放KV以及前后指针。这样我们通过hashmap找到对应Node，然后根据其前驱节点进行指针的操作，就可以实现复杂度O(1)的删除操作。 同样因为访问HashMap需要key，所以定义Node节点存放了K和V，而不是只存放V。保存队列的头节点和尾节点。 通过调整指针，定义了三个方法，分别是添加元素到队尾，将队列中元素移动到队尾，删除队列头节点并返回，因为是双向链表，特别注意指针变换的顺序以及不要遗漏前驱和后继指针。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import com.google.common.base.Joiner;import java.util.HashMap;public class LRUCache&lt;K, V&gt; { private int size; private HashMap&lt;K, Node&gt; map; private Node head; private Node tail; LRUCache(int size) { this.size = size; map = new HashMap&lt;&gt;(); } /** * 添加元素 * 1.元素存在，将元素移动到队尾 * 2.不存在，判断链表是否满。 * 如果满，则删除队首元素，放入队尾元素，删除更新哈希表 * 如果不满，放入队尾元素，更新哈希表 */ public void put(K key, V value) { Node node = map.get(key); if (node != null) { //更新值 node.v = value; moveNodeToTail(node); } else { Node newNode = new Node(key, value); //链表满，需要删除首节点 if (map.size() == size) { Node delHead = removeHead(); map.remove(delHead.k); } addLast(newNode); map.put(key, newNode); } } public V get(K key) { Node node = map.get(key); if (node != null) { moveNodeToTail(node); return node.v; } return null; } public void addLast(Node newNode) { if (newNode == null) { return; } if (head == null) { head = newNode; tail = newNode; } else { //连接新节点 tail.next = newNode; newNode.pre = tail; //更新尾节点指针为新节点 tail = newNode; } } public void moveNodeToTail(Node node) { if (tail == node) { return; } if (head == node) { head = node.next; head.pre = null; } else { //调整双向链表指针 node.pre.next = node.next; node.next.pre = node.pre; } node.pre = tail; node.next = null; tail.next = node; tail = node; } public Node removeHead() { if (head == null) { return null; } Node res = head; if (head == tail) { head = null; tail = null; } else { head = res.next; head.pre = null; res.next = null; } return res; } class Node { K k; V v; Node pre; Node next; Node(K k, V v) { this.k = k; this.v = v; } @Override public String toString() { return &quot;Node{&quot; + &quot;k=&quot; + k + &quot;, v=&quot; + v + '}'; } } public static void main(String[] args) { LRUCache&lt;Integer, String&gt; lru = new LRUCache&lt;&gt;(8); for (int i = 0; i &lt; 15; i++) { lru.put(i, &quot;this is &quot; + i); System.out.println(&quot;lru = &quot; + Joiner.on(&quot;,&quot;).withKeyValueSeparator(&quot;:&quot;).join(lru.map)); } }}","link":"/blog/2018/02/08/%E7%AE%97%E6%B3%95-2.LRU/"},{"title":"JVM-类装载器","text":"Java虚拟机是一台执行Java字节码的虚拟计算机，它拥有独立的运行机制，其运行的Java字节码也未必由Java语言编译而成。 Java编译器输入的指令流基本上是一种基于栈的指令集架构，另外一种指令集架构则是基于寄存器的指令集架构。 跨平台性 指令集小 指令多 执行性能比寄存器差 整体架构123456789101112131415161718192021class --&gt; CLassLoader --&gt; 运行时数据区 --&gt; [ [ 1. 方法区 MethodArea 2. 堆 Heap ](共享) [ 1. 程序计数器 2. 本地方法栈 3. 虚拟机栈 ](线程私有)] ^ | |执行引擎Execution Engine &lt;--&gt; 本地方法接口 类装载子系统CLassLoader类加载器子系统负责从文件系统或者网络中加载Class文件，class文件在文件开头有特定的文件标识。只负责状态，能否运行是有执行引擎决定。 两个class对象是否相同条件：完整类名一致+ClassLoader一致 查看字节码文件可以idea安装插件jclasslib bytecode vode 里面流程为 加载Loading：通过类的全限定名获取定义此类的二进制字节流 链接Linking：验证Verify-&gt;准备Prepare-&gt;解析Resolve 1231. 验证：验证class中文件是否符合虚拟机要求2. 准备：为类的static变量分配内存并且设置默认值（不包含final变量，这个在编译阶段就会分配了）3. 解析：将常量池内的符号引用转换为直接引用的过程 初始化：初始化阶段就是执行类构造器法&lt;clinit&gt;()的过程 12341. 执行clinit在多线程下会同步加锁2. 只要有static变量或静态代码块就会有clinit方法3. 静态变量和静态代码块按照代码顺序执行4. 如果有父类先会执行父类clinit 类加载器分类 引导类加载器Bootstrap ClassLoader 自定义类加载器User-Defined ClassLoader 扩展类加载器Extension ClassLoader：继承ClassLoader 系统类加载器Application ClassLoader：继承ClassLoader 自定义.. 类加载器获取方式 注意：引导类加载器没有基础java.lang.ClassLoader所以拿不到 1234567891011121314151617181920212223public class ClassLoaderTest { public static void main(String[] args) { // 获取系统类加载器 sun.misc.Launcher$AppClassLoader@18b4aac2 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader); // 获取其上层的：扩展类加载器 sun.misc.Launcher$ExtClassLoader@1540e19d ClassLoader extClassLoader = systemClassLoader.getParent(); System.out.println(extClassLoader); // 试图获取 根（引导）加载器 null ClassLoader bootstrapClassLoader = extClassLoader.getParent(); System.out.println(bootstrapClassLoader); // 获取自定义加载器 sun.misc.Launcher$AppClassLoader@18b4aac2 ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); System.out.println(classLoader); // 获取String类型的加载器 null ClassLoader classLoader1 = String.class.getClassLoader(); System.out.println(classLoader1); }} 自定义加载器使用场景： 隔离加载类 修改类加载的方式 扩展加载源 防止源码泄漏 双亲委派机制 Bootstrap ClassLoader Extension ClassLoader Application ClassLoader 自定义.. 其实原理很简单，一个类需要加载，一层层向上问能否加载，只有上层不能加载之后自己才可以加载。 优点： 避免类的重复加载 保护程序安全，防止核心API被随意篡改 自定义类：java.lang.String 自定义类：java.lang.ShkStart（报错：阻止创建 java.lang开头的类）","link":"/blog/2020/04/01/%E8%99%9A%E6%8B%9F%E6%9C%BA-a1%E7%B1%BB%E8%A3%85%E8%BD%BD%E5%99%A8/"},{"title":"JVM-运行时数据区","text":"当我们通过前面的：类的加载-&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化 这几个阶段完成后，就会用到执行引擎对我们的类进行使用，同时执行引擎将会使用到我们运行时数据区 程序计数器在JVM规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址；或者，如果是在执行native方法，则是未指定值（undefned）。 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 它是唯一一个在Java虚拟机规范中没有规定任何outotMemoryError情况的区域。 虚拟机栈主管Java程序的运行，它保存方法的局部变量（8种基本数据类型和对象引用地址）、部分结果，并参与方法的调用和返回。 异常： StackoverflowError：采用固定大小的Java虚拟机栈 outofMemoryError：如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存 设置线程的最大栈空间：-Xss 虚拟机栈内部由一个个栈帧（Stack Frame）组成 一个栈帧对应一个方法 一个时间点只会有一个活动的栈帧，即栈顶栈帧 栈帧结构： 局部变量表(Local Variables) 12341. 大小在编译时期就确定了2. 最基本的存储单元是Slot（变量槽）3. Slot包括基本数据类型（8种），引用类型（reference），returnAddress类型的变量4. 局部变量过了作用域之后就会复用他的slot 操作数栈（operand Stack） 1231. 主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间 2. 某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈3. 如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中 动态链接（DynamicLinking） 121. 指向运行时常量池的方法引用1. 目的就是为了支持当前方法的代码能够实现动态链接，比如：invokedynamic指令 方法返回地址（Return Address） 1方法正常退出或者异常退出的定义 一些附加信息 局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。 局部变量安全不安全取决于局部两边的作用域是不只在方法内部。 栈顶缓存技术由于操作数是存储在内存中的，因此频繁地执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存（Tos，Top-of-Stack Cashing）技术，将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率。 逃逸分析设置启用逃逸分析，JDK默认开启**-XX:+DoEscapeAnalysis** 判断对象作用域如果只在方法中的话，会进行一些优化： 栈上分配：对象直接分配在栈中 同步省略(锁消除)：如果一个对象被发现只有一个线程被访问到，对象操作不考虑同步 标量替换：允许将对象打散分配在栈上，比如对象拥有id和name两个字段，那么这两个字段将会被视为两个独立的局部变量进行分配。**-xx：+EliminateAllocations**默认打开 1234567891011121314151617public static void main(String args[]) { alloc();}class Point { private int x; private int y;}private static void alloc() { Point point = new Point(1,2); System.out.println(&quot;point.x&quot; + point.x + &quot;;point.y&quot; + point.y);}标量替换之后：private static void alloc() { int x = 1; int y = 2; System.out.println(&quot;point.x = &quot; + x + &quot;; point.y=&quot; + y);} 本地方法栈通过使用本地方法，我们得以用Java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用c写的。还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。比如android中就会使用JNI 当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区。 它甚至可以直接使用本地处理器中的寄存器 直接从本地内存的堆中分配任意数量的内存。 在Hotspot JVM中，直接将本地方法栈和虚拟机栈合二为一 堆一个JVM实例只存在一个堆内存，堆也是Java内存管理的核心区域。《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应当在运行时分配在堆上。 设置最小堆内存：-Xms，设置最大堆内存：-Xmx 通常会将-Xms和-Xmx两个参数配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能。 默认最小堆内存：物理电脑内存大小/64 默认最大堆内存：物理电脑内存大小/4 堆内存细分： 新生代：Eden/S0/S1=8:1:1 老年代：新生代/老年代=1:2 永久区（1.7在堆中）：Permanent Space 元空间（1.8在直接内存）：Meta Space 默认-XX:NewRatio=2，表示新生代占1，老年代占2，新生代占整个堆的1/3 默认-xx:SurvivorRatio=8，表示Eden、S0、S1比例 分配过程： new的对象先放eden区，eden满了进行MinorGC，剩余对象放入S0，对象年龄+1 又满了再次触发MinorGC，剩余放入S1，对象年龄+1 放入老年代，老年代满了MajorGC。放入老年代条件： 对象年龄15 -XX:MaxTenuringThreshold=15 空间担保机制：MinorGC后对象大小大于Survivor大小，会进入老年代 大对象直接进入老年代(-XX:PretenureSizeThreshold=1M，只对Serial和ParNew两款收集器有效) 动态年龄判断：S区同龄对象超过S区的50%，大于等于此年龄的对象会进入老年代。比如1+2+3大于50%，那么&gt;=3进入老年代 MinorGC：新生代的GC MajorGC：老年代的GC，只有CMS会单独收集老年代行为 FullGC：整堆收集，收集整个Java堆和方法区的垃圾收集GC都会stop the word TLABTLAB：Thread Local Allocation Buffer，也就是为每个线程单独分配了一个缓冲区。 设置是否开启TLAB空间：-Xx:UseTLAB JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内。作用是多线程同时分配时可以避免一系列的非线程安全问题。对象首先是通过TLAB开辟空间，如果不能放入，那么需要通过Eden来进行分配(采用CAS配上失败重试) 方法区方法区只是JVM的一个规范，实现则是永久代和元空间。方法区主要存放的是Class 1234567main {A a = new A();}A.class放在方法区中a放在Java栈的局部变量表中new A()存放在Java堆中 内存溢出OutofMemoryError：PermGen space/Metaspace： 加载大量的第三方的jar包 Tomcat部署的工程过多（30~50个） 大量动态的生成反射类 jdk7永久代：**-XX:PermSize=20.75M, -XX:MaxPermSize=82M**jdk8永久代：直接内存中** -XX:MetaspaceSize=21M, -XX:MaxMetaspaceSize=-1** - 建议初始值多，因为到了初始值就会去卸载无用类。不停的调节元空间大小 主要保存数据： 类型信息：完整类名+父类完整类名+类修饰符+类的直接接口一个有序列表 运行时常连池：将在类加载后把常量池存放到方法区的运行时常量池中，符号地址转换为真实地址 常量池：是Class文件的一部分，用于存放编译期生成的各种字面量与符号引用 静态变量 JIT代码缓存 域信息：保存类型的所有域的相关信息以及域的声明顺序，就是成员变量 方法信息：所有方法一些信息 jdk版本方法区变动： 1234567891011121314151617181920212223242526272829303132333435JDK1.6- JVM - 堆 - 方法区 - 类型信息 - 域信息 - 方法信息 - JIT代码缓存 - 运行时常量池 - StringTable - 静态变量JDK1.7- JVM - 堆 - StringTable - 静态变量 - 永久代 - 类型信息 - 域信息 - 方法信息 - JIT代码缓存 - 运行时常量池 JDK1.8- JVM - 堆 - StringTable - 静态变量- 元空间 - 类型信息 - 域信息 - 方法信息 - JIT代码缓存 - 运行时常量池 变化原因： 使用元空间因为方法区中GC回收很少(类卸载很难)，而且方法区大小很难确定(比如动态加载) StringTable放入堆中主要是在堆中回收效率高 静态引用对应的对象实体始终都存在堆空间，比如new byte[1024*1024] 注意：在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及oSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。 HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose:class以及 -XX：+TraceClass-Loading、-XX：+TraceClassUnLoading查看类加载和卸载信息 运行时数据区，是否存在Error和GC？ 运行时数据区 是否存在Error 是否存在GC 程序计数器 否 否 虚拟机栈 是 否 本地方法栈 是 否 方法区 是（OOM） 是 堆 是 是 &lt;番外&gt;对象实例化 加载类对象：加载、链接、初始化clinit 为对象分配内存 处理并发问题：TLAB/CAS 初始化分配到的内存 设置对象的对象头 执行init方法进行初始化 StringTableString是final、实现了Serializable+Comparable接口，jdk8使用final char[] value用于存储字符串数据，JDK9时改为byte[]。替换原因主要是byte使用一个字节，省空间 String s1 = “mogublog”; // 字面量的定义方式 String s2 = new String(“moxi”); 不可变性：每次修改string其实是新生成了一个string。 String.intern()查看字符串常量池中是否有该引用，如果有返回引用。没有常量池增加并返回引用。优化可以new string(&quot;I love atguigu&quot;).intern(); 常量池在jdk1.6放在永久代，jdk1.7放在堆中 如果字符串拼接过程中存在变量，相当于new String 字符串拼接底层使用的StringBuilder","link":"/blog/2020/04/02/%E8%99%9A%E6%8B%9F%E6%9C%BA-a2%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"title":"JVM-直接内存+执行引擎","text":"这两个我们调优用的不多，就一起写了 直接内存直接内存是在Java堆外的、直接向系统申请的内存区间。来源于NIO，通过存在堆中的DirectByteBuffer操作Native内存通常，访问直接内存的速度会优于Java堆。即读写性能高。 因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。 Java的NIO库允许Java程序使用直接内存，用于数据缓冲区 设置MaxDirectMemorySize，不设置和堆最大内存一致 缺点： 分配回收成本较高 不受JVM内存回收管理 执行引擎执行引擎（Execution Engine）的任务就是将字节码指令解释/编译为对应平台上的本地机器指令才可以。 分为两种类型： 解释器：对字节码采用逐行解释的方式执行，慢但启动快 编译器(JIT)：将源代码直接编译成和本地机器平台相关的机器语言，启动慢但快 JAVA属于半编译半解释型语言，启动的时候解释器执行，热点代码缓存在方法区中编译器执行。 HotSpot是两个都用，JRockit只有JIT编译器。因为这个机制的存在，所以有些发布需要预热发布。 切换执行引擎模式： -Xint：完全采用解释器模式执行程序； -Xcomp：完全采用即时编译器模式执行程序。如果即时编译出现问题，解释器会介入执行 -Xmixed：采用解释器+即时编译器的混合模式共同执行程序。 JIT编译器类型： C1编译器：Client模式下启用，对字节码进行简单和可靠的优化，耗时短 123- 方法内联：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程- 去虚拟化：对唯一的实现类进行内联- 冗余消除：在运行期间把一些不会执行的代码折叠掉 C2编译器：server模式下启用，对字节码进行耗时较长的优化，代码效率更高 123- 标量替换：用标量值代替聚合对象的属性值- 栈上分配：对于未逃逸的对象分配对象在栈而不是堆- 同步消除：清除同步操作，通常指synchronized Graal编译器：未来可期，还在实验阶段 热点探测技术HotSpot采用基于计数器的热点探测，每个方法建立两个计数器 调用计数器(Invocation Counter)：统计方法的调用次数 回边计数器(Back Edge Counter)：统计循环体执行的循环次数 方法调用Server模式下是10000次，超过触发JIT编译。**-XX:CompileThreshold**设置 热点衰减：方法调用计数器不是绝对次数，而是相对频率来说。如果一定时间频率不够就会计数衰减一半，这段时间称为此方法统计的半衰周期（Counter Half Life Time）。**-XX:-UseCounterDecay**关闭热点衰减，这样如果运行时间足够长，绝大部分代码都会是本地代码。","link":"/blog/2020/04/03/%E8%99%9A%E6%8B%9F%E6%9C%BA-a3%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98+%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/"},{"title":"JVM-优化命令+工具","text":"介绍jvm优化时候到的命令和工具 命令JpsJVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。 格式 jps [options] [hostid] 其中[option]、[hostid]参数也可以不写 参数option参数 l : 输出主类全名或jar路径 long q : 只输出LVMID quit m : 输出JVM启动时传递给main()的参数 v : 输出JVM启动时显示指定的JVM参数 Jstatjstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。没有GUI界面，是检测垃圾回收和内存泄露首选工具 格式 jstat [option] [-t] [-h&lt;lines&gt;] LVMID [interval] [count] [option] : 操作参数 [-t]：程序执行的总时间 [-h]： 每隔几次打印出现一次表头， 比如-h10就是打印10行之后出现一个表头 LVMID : 本地虚拟机进程ID [interval] : 连续输出的时间间隔，默认只打印一次 [count] : 连续输出的次数 下面介绍option参数 classclass loader的行为统计, 监视类装载、卸载数量、总空间以及耗费的时间 123[root@iZwz9b4zp8flndh7pb8o0qZ /]# jstat -class 11752Loaded Bytes Unloaded Bytes Time 14074 26039.7 288 364.1 32.75 Loaded : 加载class的数量 Bytes : class字节大小 Unloaded : 未加载class的数量 Bytes : 未加载class的字节大小 Time : 加载时间 垃圾回收相关-gc 垃圾回收堆的行为统计 123[root@iZwz9b4zp8flndh7pb8o0qZ /]# jstat -gc 30593 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 512.0 512.0 160.0 0.0 459776.0 174477.1 464384.0 393415.3 149248.0 138211.8 14848.0 13429.1 244930 1560.761 98 52.611 1613.372 C即Capacity 总容量，U即Used 已使用的容量 S0C : survivor0区的总容量 S1C : survivor1区的总容量 S0U : survivor0区已使用的容量 S1U : survivor1区已使用的容量 EC : Eden区的总容量 EU : Eden区已使用的容量 OC : Old区的总容量 OU : Old区已使用的容量(如果这个一直再涨，可能就是因为内存泄露) PC 当前perm的容量 (KB) PU perm的使用 (KB) MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC : 新生代垃圾回收次数 YGCT : 新生代垃圾回收时间 FGC : 老年代垃圾回收次数 FGCT : 老年代垃圾回收时间 GCT : 垃圾回收总消耗时间 jstat -gc 30593 2000 20 每隔2000ms输出1262的gc情况，一共输出20次 -gccapacity同-gc，不过还会输出Java堆各区域使用到的最大、最小空间 NGCMN : 新生代占用的最小空间 NGCMX : 新生代占用的最大空间 OGCMN : 老年代占用的最小空间 OGCMX : 老年代占用的最大空间 OGC：当前年老代的容量 (KB) OC：当前年老代的空间 (KB) PGCMN : perm占用的最小空间 PGCMX : perm占用的最大空间 -gcutil垃圾回收统计概述. 同-gc，不过输出的是已使用空间占总空间的百分比 -gccause垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因 LGCC：最近垃圾回收的原因 GCC：当前垃圾回收的原因 -gcnew新生代行为统计 TT：Tenuring threshold(提升阈值) MTT：最大的tenuring threshold DSS：survivor区域大小 (KB) -gcnewcapacity新生代与其相应的内存空间的统计 NGC:当前年轻代的容量 (KB) S0CMX:最大的S0空间 (KB) S0C:当前S0空间 (KB) ECMX:最大eden空间 (KB) EC:当前eden空间 (KB) -gcold显示老年代GC状况 -gcoldcapacity显示老年代GC状况，主要关注使用到最大、最小空间 -gcpermcapacity显示永久代使用到的最大、最小空间 JIT相关-compiler HotSpt JIT编译器行为统计, 输出JIT编译过的方法数量耗时等 123[root@iZwz9b4zp8flndh7pb8o0qZ /]# jstat -compiler 30593Compiled Failed Invalid Time FailedType FailedMethod 43948 5 0 299.39 1 org/eclipse/jdt/internal/compiler/lookup/ReferenceBinding computeId Compiled : 编译数量 Failed : 编译失败数量 Invalid : 无效数量 Time : 编译耗时 FailedType : 失败类型 FailedMethod : 失败方法的全限定名 -printcompilationHotSpot编译方法统计 Compiled：被执行的编译任务的数量 Size：方法字节码的字节数 Type：编译类型 Method：编译方法的类名和方法名。类名使用”/” 代替 “.” 作为空间分隔符. 方法名是给出类的方法名. 格式是一致于HotSpot - XX:+PrintComplation 选项 Jinfojinfo(JVM Configuration info)这个命令作用是实时查看和调整虚拟机运行参数。 之前的jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令 格式jinfo [option] [args] LVMID option参数 -flag : 输出指定args参数的值 -flags : 不需要args参数，输出所有JVM参数的值 -sysprops : 输出系统属性，等同于System.getProperties() 1234567891011121314λ jinfo -flag UseG1GC 21568-XX:-UseG1GC //-表示不使用//查看PrintGCDetails没有使用C:\\cmderλ jinfo -flag PrintGCDetails 21568-XX:-PrintGCDetails//设置PrintGCDetails，注意重启后失效，而且设置的参数非常有限C:\\cmderλ jinfo -flag +PrintGCDetails 21568//查看PrintGCDetails已经被使用C:\\cmderλ jinfo -flag PrintGCDetails 21568-XX:+PrintGCDetails Jmapjmap(JVM Memory Map)命令用于生成heap dump文件，如果不使用这个命令，还阔以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候·自动生成dump文件。 jmap不仅能生成dump文件，还阔以查询finalize执行队列、Java堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。 格式jmap [option] LVMID option参数 dump : 生成堆转储快照 finalizerinfo : 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象 heap : 显示Java堆详细信息 histo : 显示堆中对象的统计信息 permstat : to print permanent generation statistics F : 当-dump没有响应时，强制生成dump快照 导出内存映像文件1234567891011//手动//全部对象jmap -dump:format=b,file=1.hprof &lt;pid&gt;//只保存存活对象,生产一般用这个jmap -dump:live,format=b,file=1.hprof &lt;pid&gt;//自动-XX:+HeapDumpOnOutOfMemoryError //oom之前调用-XX:+HeapDumpBeforeFullGC //fullGC之前调用-XX:HeapDumpPath=C:\\m.hprof //指定路径 内存使用情况12345//展示某个时间点内存占用jmap -heap &lt;pid&gt; &gt; c:\\a.txt //内存中有什么对象，占用字节数多少jmap -histo &lt;pid&gt; &gt; c:\\b.txt Jhat分析dump，jdk9之后去删掉了，官方推荐jvisualvm Jstackjstack用于生成java虚拟机当前时刻的线程快照。 线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 格式jstack [option] LVMID option参数 -F : 当正常输出请求不被响应时，强制输出线程堆栈 -l : 除堆栈外，显示关于锁的附加信息 -m : 如果调用到本地方法的话，可以显示C/C++的堆栈 Jcmd除了前面jstat之外所有功能，官方建议替换 GUIjava自带JconsoleVisualVM（自带推荐）安装插件VisualGC JMC第三方工具MAT（专门分析dump）最吸引人的还是可以快速生成内存泄漏报表 JProfilerArthasBtrace内存泄漏 静态集合类1234567//静态集合类生命周期很长，在方法中add对象进入之后回收不了static List list = new ArrayList();public void test(){ Object obj = new Object(); list.add(obj);} 单例模式，持有外部引用就不会被回收 内部类持有外部类，如果外部类实例对象返回了一个内部类实例。这时候如果内部类实例周期很长，外部类也回收不了 各种连接，比如数据库close等 变量不合理作用域。可以局部变量就不要去成员变量 改变哈希值。当一个对象被存储到hashSet中，就不能修改这个对象中参与计算的字段。因为存进去了之后修改了参与计算的字段，hash就变了。对象就取不出来了。 缓存，一旦把对象放入缓存就很容易被遗忘。所以建议用弱引用WeakHashMap实现 回调，如果在api中注册回调但是没有显示取消，那么就会聚集。建议使用弱引用WeakHashMap实现 出栈的时候记得把值设置为null","link":"/blog/2020/04/05/%E8%99%9A%E6%8B%9F%E6%9C%BA-a5%E4%BC%98%E5%8C%96%E5%91%BD%E4%BB%A4+%E5%B7%A5%E5%85%B7/"},{"title":"JVM-运行时参数","text":"介绍使用到的一些参数 JVM参数选项标准参数选项 比较稳定，后续版本基本不会变化， 以-开头。 直接在DOS窗口中运行java或者java -help可以看到所有的标准选项。 补充内容：-server与-client -X参数选项 非标准化参数 功能还是比较稳定的。但官方说后续版本可能会变更 以-X开头 直接在DOS窗口中运行java -X命令可以看到所有的X选项。 JVM的JIT编译模式相关的选项： -Xint ： 只使用解释器：所有字节码都被解释执行，这个模式的速度是很慢的 -Xcomp ： 只使用编译器：所有字节码第一次使用就被编译成本地代码，然后在执行 -Xmixed ： 混合模式：这是默认模式，刚开始的时候使用解释器慢慢解释执行，后来让JIT即时编译器根据程序运行的情况，有选择地将某些热点代码提前编译并缓存在本地，在执行的时候效率就非常高了 -Xmx -Xms -Xss属于XX参数？ -Xms&lt;size&gt; 设置初始Java堆大小，等价于-XX:InitialHeapSize -Xmx&lt;size&gt; 设置最大Java堆大小，等价于-XX:MaxHeapSize -Xss&lt;size&gt; 设置Java线程堆栈大小，等价于-XX:ThreadStackSize -XX参数选项 非标准化参数 使用的最多的参数类型 这类选项属于实验性，不稳定 以-XX开头 用于开发和调试JVM Boolean类型格式： -XX:+ 表示启用option属性 -XX:-表示禁用option属性 非Boolean类型格式（key-value类型） ： 子类型1：数值型格式-XX:= 子类型2：非数值型格式-XX:= -XX:+PrintFlagsFinal 输出所有参数的名称和默认值， 默认不包括Diagnostic和Experimental的参数 ， 可以配合-XX:+UnlockDiagnosticVMOptions和-XX:UnlockExperimentalVMOptions使用 添加JVM参数选项 运行jar包：java -Xms50m -Xmx50m -XX:+PrintGCDetails -XX:+PrintGYTimeStamps -jar demo.jar 通过Tomcat运行war包 ： Linux系统下可以在tomcat/bin/catalina.sh中添加类似如下配置：JAVA_OPTS=&quot;-Xms512M -Xmx1024M&quot;。 Windows系统下载catalina.bat中添加类似如下配置：set &quot;JAVA_OPTS=-Xms512M -Xmx1024M&quot; 程序运行过程中 ： 使用jinfo -flag &lt;name&gt;=&lt;value&gt; &lt;pid&gt;设置非Boolean类型参数。 使用jinfo -flag [+|-]&lt;name&gt; &lt;pid&gt;设置Boolean类型参数 常用的JVM参数选项打印设置的XX选项及值123456789101112//可以让程序运行前打印出用户手动设置或者JVM自动设置的XX选项-XX:+PrintCommandLineFlags//表示打印出所有XX选项的默认值-XX:+PrintFlagsInitial//表示打印出XX选项在运行程序时生效的值//如果值的前面加上了:=，说明该值不是初始值，该值可能被jvm自动改变了，也可能被我们设置的参数改变了-XX:+PrintFlagsFinal//打印JVM的参数-XX:+PrintVMOptions 堆、栈、方法区等内存大小设置栈1-Xss128k 堆123456789101112131415161718192021222324252627282930313233343536373839//等价于-XX:InitialHeapSize，设置JVM初始堆内存为3500M-Xms3550m//等价于-XX:MaxHeapSize，设置JVM最大堆内存为3500M-Xmx3550m//设置年轻代大小为2G，即等价于-XX:NewSize=2g -XX:MaxNewSize=2g，也就是设置年轻代初始值和年轻代最大值都是2G//官方推荐配置为整个堆大小的3/8-Xmn2g//设置年轻代初始值为1024M-XX:NewSize=1024m//设置年轻代最大值为1024M-XX:MaxNewSize=1024m//设置年轻代中Eden区与一个Survivor区的比值，默认为8//推荐使用默认打开的-XX:+UseAdaptiveSizePolicy设置，并且不显示设置-XX:SurvivorRatio-XX:SurvivorRatio=8//自动选择各区大小比例，默认开启-XX:+UseAdaptiveSizePolicy//设置老年代与年轻代（包括1个Eden区和2个Survivor区）的比值，默认为2-XX:NewRatio=2//设置让大于此阈值的对象直接分配在老年代，单位为字节(不好控制)//只对Serial、ParNew收集器有效-XX:PretenureSizeThreadshold=1024//默认值为15，使用比较少，一般用默认值//新生代每次MinorGC后，还存活的对象年龄+1，当对象的年龄大于设置的这个值时就进入老年代-XX:MaxTenuringThreshold=15//让JVM在每次MinorGC后打印出当前使用的Survivor中对象的年龄分布-XX:+PrintTenuringDistribution//表示MinorGC结束后Survivor区域中占用空间的期望比例-XX:TargetSurvivorRatio 方法区永久代 12345//设置永久代初始值为256M-XX:PermSize=256m//设置永久代最大值为256M-XX:MaxPermSize=256m 元空间 1234567891011121314//初始空间大小-XX:MetaspaceSize//最大空间，默认没有限制-XX:MaxMetaspaceSize//使用压缩对象指针-XX:+UseCompressedOops//使用压缩类指针-XX:+UseCompressedClassPointers//设置Class Metaspace的大小，默认1G-XX:CompressedClassSpaceSize 直接内存12//指定DirectMemory容量，若未指定，则默认与Java堆最大值一样-XX:MaxDirectMemorySize OutOfMemory相关的选项12345678910111213//表示在内存出现OOM的时候，生成Heap转储文件，以便后续分析//-XX:+HeapDumpBeforeFullGC和-XX:+HeapDumpOnOutMemoryError只能设置1个-XX:+HeapDumpOnOutMemoryError//表示在出现FullGC之前，生成Heap转储文件，以便后续分析//-XX:+HeapDumpBeforeFullGC和-XX:+HeapDumpOnOutMemoryError只能设置1个，请注意FullGC可能出现多次，那么dump文件也会生成多个-XX:+HeapDumpBeforeFullGC//指定heap转存文件的存储路径，如果不指定，就会将dump文件放在当前目录中-XX:HeapDumpPath=&lt;path&gt;//指定一个可行性程序或者脚本的路径，当发生OOM的时候，去执行这个脚本-XX:OnOutOfMemoryError 垃圾收集器相关选项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//查看默认的垃圾回收器//先查看命令行相关参数-XX:+PrintCommandLineFlagsjinfo -flag [比如：UseG1GC] [pid]//Serial回收器-XX:+UseSerialGC//Parnew回收器-XX:+UseParNewGC//设置年轻代并行收集线程数//CPU小于8个，设置等于CPU数目。CPU大于8个，3+[5*CPU_Count]/8-XX:+ParallelGCThreads//Parallel回收器-XX:+UseParallelGC//手动指定老年代GC回收器(和上面设置相互激活)-XX:+UseParallelOldGC//CPU小于8个，设置等于CPU数目。CPU大于8个，3+[5*CPU_Count]/8-XX:ParallelGCThreads//设置垃圾收集器最大停顿时间（STW），这个设置需谨慎-XX:MaxGCPauseMillis//垃圾收集时间占总时间比例（0~100，默认99，也就是垃圾回收时间不超过1%）。和-XX:MaxGCPauseMillis成反比，两个不要同时使用-XX:GCTimeRatio//是否开启自适应调节策略-XX:+UseAdaptiveSizePoliy//CMS回收器略//G1回收器-XX:+UseG1GC//设置每个Region大小，值是2的幂，范围1MB~32MB之间。//目标是根据最小的堆大小划分出2048个区域，默认是堆内存的1/2000-XX:G1HeapRegionSize//设置期望达到最大GC停顿时间（尽力实现不保证达到），默认200ms-XX:MaxGCPauseMillis//设置STW时GC线程数，最多8个-XX:ParallelGCThread//设置并发标记的线程数，设置为-XX:ParallelGCThread的1/4左右-XX:ConcGCThreads//设置出发并发GC周期的堆占用率阈值，超过阈值出发GC。默认45-XX:InitiatingHeapOccupancyPercent//新生代占用整个堆内存最小百分比（默认5%）-XX:G1NewSizePercent//新生代占用整个堆内存最大百分比（默认60%）-XX:G1MaxNewSizePercent//保存内存区域，防止SurvivorTo区溢出-XX:G1ReservePercent=10//############//如果使用G1垃圾收集器，不建议设置-Xmn和-XX:NewRatio，毕竟可能影响G1的自动调节//############ GC日志相关选项常用参数 1234567891011121314151617181920//输出日志信息，默认输出的标准输出。两个功能一样-verbose:gc -XX:+PrintGC//在发生垃圾回收时打印内存回收详细的日志，并在进程退出时输出当前内存各区域的分配情况-XX:+PrintGCDetails//程序启动到GC发生的时间秒数//需要配合-XX:+PrintGCDetails使用-XX:+PrintGCTimeStamps//输出GC发生时的时间戳（以日期的形式，例如：2013-05-04T21:53:59.234+0800）//配合-XX:+PrintGCDetails使用-XX:+PrintGCDateStamps//每一次GC前和GC后，都打印堆信息-XX:+PrintHeapAtGC//把GC日志写入到一个文件中去，而不是打印到标准输出中-XIoggc:&lt;file&gt; 其他参数 1234567891011121314151617181920212223//监控类的加载-XX:TraceClassLoading//打印GC时线程的停顿时间-XX:PrintGCApplicationStoppedTime//垃圾收集之前打印出应用未中断的执行时间-XX:+PrintGCApplicationConcurrentTime//记录回收了多少种不同引用类型的引用-XX:+PrintReferenceGC//让JVM在每次MinorGC后打印出当前使用的Survivor中对象的年龄分布-XX:+PrintTenuringDistribution//启用GC日志文件的自动转储-XX:+UseGCLogFileRotation//GC日志文件的循环数目-XX:NumberOfGCLogFiles=1//控制GC日志文件的大小-XX:GCLogFileSize=1M 其他参数123456789101112131415161718192021222324//禁用hotspot执行System.gc()，默认禁用-XX:+DisableExplicitGC//指定代码缓存的大小-XX:ReservedCodeCacheSize=&lt;n&gt;[g|m|k]、-XX:InitialCodeCacheSize=&lt;n&gt;[g|m|k]//使用该参数让jvm放弃一些被编译的代码，避免代码缓存被占满时JVM切换到interpreted-only的情况-XX:+UseCodeCacheFlushing//开启逃逸分析-XX:+DoEscapeAnalysis//开启偏向锁-XX:+UseBiasedLocking//开启使用大页面-XX:+UseLargePages//打印TLAB的使用情况-XX:+PrintTLAB//设置TLAB大小-XX:TLABSize 通过Java代码获取JVM参数1234567891011121314MemoryMXBean memorymbean = ManagementFactory.getMemoryMXBean();MemoryUsage usage = memorymbean.getHeapMemoryUsage();System.out.println(&quot;INIT HEAP: &quot; + usage.getInit() / 1024 / 1024 + &quot;m&quot;);System.out.println(&quot;MAX HEAP: &quot; + usage.getMax() / 1024 / 1024 + &quot;m&quot;);System.out.println(&quot;USE HEAP: &quot; + usage.getUsed() / 1024 / 1024 + &quot;m&quot;);System.out.println(&quot;\\nFull Information:&quot;);System.out.println(&quot;Heap Memory Usage: &quot; + memorymbean.getHeapMemoryUsage());System.out.println(&quot;Non-Heap Memory Usage: &quot; + memorymbean.getNonHeapMemoryUsage());System.out.println(&quot;=======================通过java来获取相关系统状态============================ &quot;);System.out.println(&quot;当前堆内存大小totalMemory &quot; + (int) Runtime.getRuntime().totalMemory() / 1024 / 1024 + &quot;m&quot;);// 当前堆内存大小System.out.println(&quot;空闲堆内存大小freeMemory &quot; + (int) Runtime.getRuntime().freeMemory() / 1024 / 1024 + &quot;m&quot;);// 空闲堆内存大小System.out.println(&quot;最大可用总堆内存maxMemory &quot; + Runtime.getRuntime().maxMemory() / 1024 / 1024 + &quot;m&quot;);// 最大可用总堆内存大小","link":"/blog/2020/04/06/%E8%99%9A%E6%8B%9F%E6%9C%BA-a6%E8%BF%90%E8%A1%8C%E6%97%B6%E5%8F%82%E6%95%B0/"},{"title":"脱敏","text":"就是对敏感数据的隐蔽性处理 思路 因为要脱敏, 先来个接口 1234public interface SensitiveTypeHandler { SensitiveType getType(); //判断脱敏那种数据, 比如手机,身份证 String handle(Object source); //脱敏处理方式} 枚举定义一下脱敏类型 123456789101112131415161718public enum SensitiveType { ID_CARD(&quot;身份证&quot;), MOBILE_PHONE(&quot;手机号&quot;), BANK_CARD(&quot;银行卡&quot;); private String title; SensitiveType(String title) { this.title = title; } public String getTitle() { return title; }} 三种脱敏数据数据类型 1234567891011121314151617181920public class BandCardSensitiveHandler implements SensitiveTypeHandler{ @Override public SensitiveType getType() { return SensitiveType.BANK_CARD; } @Override public String handle(Object source) { if (source == null) { return null; } String bankCard = source.toString(); return StringUtils.left(bankCard, 2) .concat( StringUtils.removeStart(StringUtils.leftPad(StringUtils.right(bankCard, 4), StringUtils.length(bankCard), &quot;*&quot;), &quot;***&quot;) ); }} 123456789101112131415public class IDCardSensitiveHandler implements SensitiveTypeHandler { @Override public SensitiveType getType() { return SensitiveType.ID_CARD; } @Override public String handle(Object source) { if (source == null) { return null; } String idCard = source.toString(); return StringUtils.left(idCard, 3).concat(StringUtils.removeStart(StringUtils.leftPad(StringUtils.right(idCard, 4), StringUtils.length(idCard), &quot;*&quot;), &quot;***&quot;)); }} 1234567891011121314151617181920public class MobilePhoneSensitiveHandler implements SensitiveTypeHandler { @Override public SensitiveType getType() { return SensitiveType.MOBILE_PHONE; } @Override public String handle(Object source) { if (source == null) { return null; } String value = source.toString(); return StringUtils.left(value, 3) .concat(StringUtils.removeStart(StringUtils.leftPad(StringUtils.right(value, 4), StringUtils.length(value), &quot;*&quot;), &quot;***&quot;) ); }} 封装一个脱敏的register 123456789101112131415161718192021222324252627282930313233public class SensitiveTypeRegistry { private static final Map&lt;SensitiveType, SensitiveTypeHandler&gt; HANDLER_REGISTY = new ConcurrentHashMap&lt;&gt;(); static { HANDLER_REGISTY.put(SensitiveType.ID_CARD, new IDCardSensitiveHandler()); HANDLER_REGISTY.put(SensitiveType.MOBILE_PHONE, new MobilePhoneSensitiveHandler()); HANDLER_REGISTY.put(SensitiveType.BANK_CARD, new BandCardSensitiveHandler()); } public void put(SensitiveTypeHandler sensitiveTypeHandler) { HANDLER_REGISTY.put(sensitiveTypeHandler.getType(), sensitiveTypeHandler); } public SensitiveTypeHandler get(SensitiveType sensitiveType) { SensitiveTypeHandler sensitiveTypeHandler = HANDLER_REGISTY.get(sensitiveType); if (sensitiveTypeHandler == null) { throw new IllegalArgumentException(&quot;none sensitiveTypeHandler be found!, type:&quot; + sensitiveType.name()); } return sensitiveTypeHandler; } /** * 是否已经是脱敏过的内容了 * * @param src 原始数据 * @return 是否已经脱敏了 */ public static boolean alreadyBeSentisived(Object src) { return src == null || src.toString().indexOf(&quot;*&quot;) &gt; 0; }} mybatis拦截器处理脱敏 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@Intercepts({ @Signature(type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = {java.sql.Statement.class})})public class SensitiveWordInterceptor implements Interceptor { private static final String MAPPED_STATEMENT = &quot;mappedStatement&quot;; private final SensitiveTypeRegistry sensitiveTypeRegistry; @Setter private Boolean enabled = Boolean.TRUE; public SensitiveWordInterceptor(SensitiveTypeRegistry sensitiveTypeRegistry) { this.sensitiveTypeRegistry = sensitiveTypeRegistry; } @Override public Object intercept(Invocation invocation) throws Throwable { if (enabled) { final List&lt;Object&gt; results = (List&lt;Object&gt;) invocation.proceed(); if (results.isEmpty()) { return results; } final ResultSetHandler statementHandler = PluginUtils.realTarget(invocation.getTarget()); final MetaObject metaObject = SystemMetaObject.forObject(statementHandler); final MappedStatement mappedStatement = (MappedStatement) metaObject.getValue(MAPPED_STATEMENT); final ResultMap resultMap = mappedStatement.getResultMaps().isEmpty() ? null : mappedStatement.getResultMaps().get(0); Object result0 = results.get(0); EnableSensitive enableSensitive = result0.getClass().getAnnotation(EnableSensitive.class); if (enableSensitive == null || !enableSensitive.value()) { return results; } final Map&lt;String, Sensitive&gt; encryptedMap = getSensitiveMap(resultMap); for (Object obj : results) { final MetaObject objMetaObject = mappedStatement.getConfiguration().newMetaObject(obj); for (Map.Entry&lt;String, Sensitive&gt; entry : encryptedMap.entrySet()) { String property = entry.getKey(); Sensitive sensitive = entry.getValue(); String bindProperty = sensitive.bind(); String value = (String) objMetaObject.getValue(property); if (StringUtils.hasText(bindProperty)) { value = (String) objMetaObject.getValue(bindProperty); } if (value != null) { String decryptValue = handle(sensitive, value); objMetaObject.setValue(property, decryptValue); } } } return results; } else { return invocation.proceed(); } } private Map&lt;String, Sensitive&gt; getSensitiveMap(ResultMap resultMap) { Map&lt;String, Sensitive&gt; sensitiveMap = new HashMap&lt;&gt;(16); if (resultMap == null) { return sensitiveMap; } Class&lt;?&gt; clazz = resultMap.getType(); for (Field field : clazz.getDeclaredFields()) { Sensitive sensitive = field.getAnnotation(Sensitive.class); if (sensitive != null) { sensitiveMap.put(field.getName(), sensitive); } } return sensitiveMap; } private String handle(Sensitive sensitive, String value) { return sensitiveTypeRegistry.get(sensitive.value()).handle(value); } @Override public Object plugin(Object o) { return Plugin.wrap(o, this); } @Override public void setProperties(Properties properties) { }}","link":"/blog/2017/01/08/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%881.%E8%84%B1%E6%95%8F/"},{"title":"签名","text":"再给第三方系统提供接口的时候, 考虑到安全新的问题, 必须用到签名.比如: 数据是否被篡改, 数据是否已经过时, 数据是否可以重复提交等问题. 和第三方规则要实现必须和第三方制定一个规则, 比如: 设所有发送或者接收到的数据为集合M, 将集合M内非空参数值的参数按照参数名ASCII码从小到大排序(字典序) 参数名称区分大小写 传送的signature不参与签名 必须传送appid,timestamp,nonce,signature参数 timestamp字段为Unix时间戳,精度到毫秒 为避免中文编码不一致的问题，需对参数值进行utf8编码 Body的请求参数需将请求内容求md5值，并以payload参数传递 介绍传递参数的含义: appid 该第三方的标识 timestamp 判断是否请求过期 nonce 判断是否可以重复提交 signature签名的验证 比如传递参数为 12345appid = 123456timestamp = 1585559019670nonce = dfsdfsdfsfdfsignature = xxxxxxxname = 张三 对参数按照key=value的格式，并按照参数名ASCII字典序排序如下StrA=”appid=123456&amp;name=%E5%BC%A0%E4%B8%89&amp;nonce=dfsdfsdfsfdf&amp;stimestamp=1585559019670” 使用hash_hmac运算, signature=hash_hmac(sha256,123456,StrA)获得signature 获得所有的参数之后. 将参数放入Headers中请求 验证签名定义注解 1234567@Target({TYPE, METHOD})@Retention(RUNTIME)@Documentedpublic @interface Signature { // boolean resubmit() default true;//允许重复请求} 切面判断签名是否正确 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697@Aspect@Component@Order(2)public class SignatureValidatorAspect { /* 签名参数 */ public static final String REQUEST_BODY_PARAM_NAME = &quot;payload&quot;; public static final String SIGNATURE_HEADER_APPID = &quot;appid&quot;;//签名appid public static final String SIGNATURE_HEADER_TIMESTAMP = &quot;timestamp&quot;;//签名时间戳 public static final String SIGNATURE_HEADER_NONCE = &quot;nonce&quot;;//签名随机字符串 public static final String SIGNATURE_HEADER_SIGNATURE = &quot;signature&quot;;//签名 private static final Long EXPIRE_TIME = 60 * 1000 * 1000L; private ObjectMapper mapper = new ObjectMapper(); @Autowired private JedisUtils jedisUtils; @Autowired private ITenantSecretConsumer tenantSecretConsumer; @Around(&quot;execution(public * com.**.controller..*.*(..)) &amp;&amp; @annotation(com.**.annotation.Signature)&quot;) public Object doAroud(ProceedingJoinPoint pjp) throws Throwable { HttpServletRequest request = ((ServletRequestAttributes)RequestContextHolder.currentRequestAttributes()).getRequest(); Map&lt;String, String&gt; map = validateAndGetHeaderSignParam(request); TTenantSecretEntity secretInfo = tenantSecretConsumer.getSecretByAppId(map.get(SmpConstant.SIGNATURE_HEADER_APPID)); String appSecret = secretInfo.getAppSecret(); Map&lt;String, String&gt; pathMap = (Map&lt;String, String&gt;) request.getAttribute(HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE); Map&lt;String, String[]&gt; parameterMap = request.getParameterMap(); parameterMap.forEach((k, v) -&gt; { map.put(k, StringUtils.join(v)); }); map.putAll(pathMap); String jsonStr = getBodyJsonStr(pjp); if (jsonStr != null) { map.put(SmpConstant.REQUEST_BODY_PARAM_NAME, HmacUtils.hmacMd5Hex(appSecret, jsonStr)); } StringBuilder splice = new StringBuilder(); map.forEach((k,v) -&gt; { splice.append(k).append(&quot;=&quot;).append(v).append(&quot;&amp;&quot;); }); String serverSignature = HmacUtils.hmacSha256Hex(appSecret, splice.substring(0, splice.length() - 1)); String clientSignature = request.getHeader(SmpConstant.SIGNATURE_HEADER_SIGNATURE); if (!clientSignature.equals(serverSignature)) { throw new ApiException(ResponseCode.SIGN_ERROR.value(), ResponseCode.SIGN_ERROR.getDescription()); } jedisUtils.setForTimeMS(clientSignature, String.valueOf(secretInfo.getTenantId()), EXPIRE_TIME); return pjp.proceed(); } //校验并获取header中的签名参数 private Map&lt;String,String&gt; validateAndGetHeaderSignParam(HttpServletRequest request) { String appid = request.getHeader(SmpConstant.SIGNATURE_HEADER_APPID); String timestamp = request.getHeader(SmpConstant.SIGNATURE_HEADER_TIMESTAMP); String nonce = request.getHeader(SmpConstant.SIGNATURE_HEADER_NONCE); String signature = request.getHeader(SmpConstant.SIGNATURE_HEADER_SIGNATURE); if (StringUtils.isEmpty(appid)) { throw new ApiException(ResponseCode.SIGN_APPID_IS_NULL.value(), ResponseCode.SIGN_APPID_IS_NULL.getDescription()); } if (StringUtils.isEmpty(timestamp)) { throw new ApiException(ResponseCode.SIGN_TIMESTAMP_IS_NULL.value(), ResponseCode.SIGN_TIMESTAMP_IS_NULL.getDescription()); } if (StringUtils.isEmpty(nonce)) { throw new ApiException(ResponseCode.SIGN_NONCE_IS_NULL.value(), ResponseCode.SIGN_NONCE_IS_NULL.getDescription()); } if (StringUtils.isEmpty(signature)) { throw new ApiException(ResponseCode.SIGNATURE_IS_NULL.value(), ResponseCode.SIGNATURE_IS_NULL.getDescription()); } long now = System.currentTimeMillis(); long requestTimestamp = Long.parseLong(timestamp); if (now - requestTimestamp &gt; EXPIRE_TIME) {//请求是范围验证 throw new ApiException(ResponseCode.REQUEST_TIME_EXPIRE.value(), ResponseCode.REQUEST_TIME_EXPIRE.getDescription()); } Map&lt;String,String&gt; headerMap = Maps.newTreeMap(); headerMap.put(SmpConstant.SIGNATURE_HEADER_APPID, appid); headerMap.put(SmpConstant.SIGNATURE_HEADER_TIMESTAMP, timestamp); headerMap.put(SmpConstant.SIGNATURE_HEADER_NONCE, nonce); return headerMap; } //获取body中参数 private String getBodyJsonStr(ProceedingJoinPoint pjp) throws Exception { MethodSignature methodSignature = (MethodSignature) pjp.getSignature(); Object[] args = pjp.getArgs(); Method method = methodSignature.getMethod(); for (int i = 0; i &lt; method.getParameterCount(); ++i) { MethodParameter mp = new MethodParameter(method, i); for (Annotation anno : mp.getParameterAnnotations()) { if (anno instanceof RequestBody) { return mapper.writeValueAsString(args[i]); } } } return null; }}","link":"/blog/2017/01/09/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%882.%E7%AD%BE%E5%90%8D/"},{"title":"限流","text":"限制流量, 服务降级的一种. 流量超了之后以延迟处理, 拒绝处理, 部分拒绝处理. 以此来保护系统 一般网关都会有对应的限流实现, 比如Zuul, spring cloud gateway等 计数法单位时间内只能允许一定数目的请求数.比如说: 每分钟只能允许100个请求通过. 实现的话只需要计算每分钟请求数目的多少, 如果多于100个请求就限流 缺点: 如果在00:59发送100个请求, 在01:00有发送100个请求, 这个是不会被限流的.但是实际上在2s中内已经请求了200次, 远远超出了每秒钟处理数量的阈值. 滑动窗口是计数法的一种改进, 其实道理一样. 就是把计算法本来是每分钟为时间单位, 现在拆分成10s甚至更小为单位.每一份上设置一个独立的计算器. LeakyBucket漏桶漏桶算法强制一个常量的输出速率而不管输入数据流的突发性.当输入空闲时, 该算法不执行任何动作.就像用一个底部开了个洞的漏桶接水一样, 水进入到漏桶里, 桶里的水通过下面的孔以固定的速率流出, 当水流入速度过大会直接溢出, 可以看出漏桶算法能强行限制数据的传输速率.通过它，突发流量可以被整形以便为网络提供一个稳定的流量 TokenBucket令牌桶令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌, 而如果请求需要被处理, 则需要先从桶里获取一个令牌.当桶里没有令牌可取时, 则拒绝服务; 当桶满时, 新添加的令牌被丢弃或拒绝. 令牌桶算法是一个存放固定容量令牌(token)的桶, 按照固定速率往桶里添加令牌. 主要区别在于漏桶算法能够强行限制数据的传输速率, 而令牌桶算法在能够限制数据的平均传输速率外, 还允许某种程度的突发传输. 在令牌桶算法中, 只要令牌桶中存在令牌, 那么就允许突发地传输数据直到达到用户配置的门限, 因此它适合于具有突发特性的流量.","link":"/blog/2017/01/10/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%883.%E9%99%90%E6%B5%81/"},{"title":"分布式锁","text":"注意: 缓存雪崩，缓存击穿，缓存穿透 前期准备 秒杀服务单独部署 资源静态化, 把能提前放入cdn服务器的东西都放进去 前端优化 禁止重复提交，比如点了秒杀前端显示排队弹框，redis记录用户id，下次请求过滤掉 秒杀到了，前端按钮置灰 秒杀接口开始了才会返回给前端接口url和md5，防止一开始就刷接口 后端逻辑 在秒杀前把库存放入redis，用lua脚本处理库存判断和扣除的原子性问题 redis库存为0之后用mq出处理后续业务逻辑，发送消息等通知、生成订单修改库存、通知用户支付","link":"/blog/2017/01/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%884.%E7%A7%92%E6%9D%80/"},{"title":"面向对象七大设计原则","text":"面向对象设计原则为支持可维护性复用而诞生，这些原则蕴含在很多设计模式中，它们是从许多设计方案中总结出的指导性原则。 7种常用的面向对象设计原则 开闭原则: 对扩展开放，对修改关闭(总纲, 就是基本原则) 单一职责原则: 类要职责单一(如何定义类) 接口隔离原则: 设计接口的时候要精简单一(接口如何定义) 里氏替换原则: 不要破坏继承体系(如何玩继承) 依赖倒转原则: 面向接口编程(如何玩继承和多态) 合成复用原则: 优先使用组合或者聚合关系复用，少用继承关系复用(如何处理继承和组合聚合关系) 迪米特法则: 降低耦合度(如何处理类于类的关系) 开闭原则是目标，里氏代换原则是基础，依赖倒转原则是手段 开闭原则(总纲) 开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 比如说: 书籍接口 12345public interface IBook{ public String getName(); public String getPrice(); public String getAuthor();} 小说类书籍实现 1234567891011121314151617181920212223public class NovelBook implements IBook{ private String name; private int price; private String author; public NovelBook(String name,int price,String author){ this.name = name; this.price = price; this.author = author; } public String getAutor(){ return this.author; } public String getName(){ return this.name; } public int getPrice(){ return this.price; } } 现在实现售卖书籍 123456public class Client{ public static void main(Strings[] args){ IBook novel = new NovelBook(&quot;笑傲江湖&quot;,100,&quot;金庸&quot;); System.out.println(&quot;书籍名字：&quot;+novel.getName()+&quot;书籍作者：&quot;+novel.getAuthor()+&quot;书籍价格：&quot;+novel.getPrice()); }} 但是现在问题来了, 因为种种需求, 现在只有小说类书籍现在需要打折, 现在怎么改呢? 有三种方案: 直接添加打折接口, 小说类书籍实现打折接口.(否定: 因为打折不是通用行为, 而且一般来说总接口是比较稳定的, 是不能经常修改, 不然契约作用就失去了) 直接修改小说类书籍的getPrice方法(否定: 这种肯定不行, 如果需要获取打折前的价格呢) 直接在小说实现类中添加一个打折方法(否定: 这样的确可以实现, 但是这样小说就会有两个读取价格的方法了, 也不是最优) 增加一个打折小说的子类, 重写getPrice方法(肯定: 对原有代码没有任何影响, 修改也小, 风险少) 单一原则 单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。 里氏代换原则 里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象 父类所有公开方法, 子类都要实现. 否则在调用父类方法的时候, 如果替换为子类,会出现问题 父类已经实现的方法, 子类不要去改动(其实就是实现的时候用this.super()再加上自己的逻辑) 依赖倒转原则 依赖倒转原则(Dependency Inversion Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。 我们经常在controller中会注入service, 这时候我们成员变量service的接口, 但是不能把serviceImpl作为成员变量, 这就是依赖倒转原则 接口分离原则 接口隔离原则(Interface Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。 就是把接口细分开来, 不要全部融合在一起 合成复用原则 合成复用原则(Composite Reuse Principle, CRP)：尽量使用对象组合，而不是继承来达到复用的目的。 因为java中不能多继承, 所以继承很宝贵, 而且继承需要有相同关系才能去继承.复用时要尽量使用组合/聚合关系（关联关系），少用继承。 迪米特原则不要和陌生人说话、只与你的直接朋友通信, 以下是朋友: 当前对象本身(this)； 以参数形式传入到当前对象方法中的对象； 当前对象的成员对象； 如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友； 当前对象所创建的对象。 应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用","link":"/blog/2017/01/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fa1-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%83%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"},{"title":"设计模式-创建型","text":"设计模式（Design pattern）按照功能分为三类23种： 创建型（5种） ： 工厂模式、抽象工厂模式、单例模式、原型模式、构建者模式 结构型（7种）： 适配器模式、装饰模式、代理模式 、外观模式、桥接模式、组合模式、享元模式 行为型（11种）： 模板方法模式、策略模式 、观察者模式、中介者模式、状态模式、责任链模式、命令模式、迭代器模式、访问者模式、解释器模式、备忘录模式 工厂模式 简单工厂: 万能工厂, 来啥造啥 工厂方法: 我只造工厂, 一样产品造一个工厂 抽象工厂: 简单工厂工厂类拥有一个工厂方法（create），接受了一个参数，通过不同的参数实例化不同的产品类。 1234567891011121314151617181920212223public class AnimalFactory { //简单工厂设计模式（负担太重、不符合开闭原则） public static Animal createAnimal(String name){ if (&quot;cat&quot;.equals(name)) { return new Cat(); }else if (&quot;dog&quot;.equals(name)) { return new Dog(); }else if (&quot;cow&quot;.equals(name)) { return new Dog(); }else{ return null; } }} //该简单工厂，也称为静态方法工厂 public class AnimalFactory2 { public static Dog createDog(){ return new Dog(); } public static Cat createCat(){ return new Cat(); } } 优点： 很明显，简单工厂的特点就是”简单粗暴”，通过一个含参的工厂方法，我们可以实例化任何产品类，上至飞机火箭，下至土豆面条，无所不能。 所以简单工厂有一个别名：上帝类。 缺点： 任何”东西”的子类都可以被生产，负担太重。当所要生产产品种类非常多时，工厂方法的代码量可能会很庞大。 在遵循开闭原则（对拓展开放，对修改关闭）的条件下，简单工厂对于增加新的产品，无能为力。因为增加新产品只能通过修改工厂方法来实现。 spring中是通过配置文件和反射解决了简单工厂中的缺点 工厂方法正好可以解决简单工厂的这两个缺点。 工厂方法模式工厂方法是针对每一种产品提供一个工厂类. 通过不同的工厂实例来创建不同的产品实例 12345678910111213// 抽象出来的动物工厂----它只负责生产一种产品public interface AnimalFactory { // 工厂方法 Animal createAnimal();}// 具体的工厂实现类public class CatFactory implements AnimalFactory { @Override public Animal createAnimal() { return new Cat(); }} 抽象工厂模式抽象工厂是应对产品族概念的 实例 -&gt; 类 -&gt; 类工厂实例 -&gt; 类 -&gt; 类工厂 -&gt; 抽象工厂 123456789101112131415interface AbstractFactory { public Product1 newProduct1(); public Product2 newProduct2();}class ConcreteFactory1 implements AbstractFactory { public Product1 newProduct1() { System.out.println(&quot;具体工厂 1 生成--&gt;具体产品 11...&quot;); return new ConcreteProduct11(); } public Product2 newProduct2() { System.out.println(&quot;具体工厂 1 生成--&gt;具体产品 21...&quot;); return new ConcreteProduct21(); }} 单例模式饿汉式单例为什么不用饿汉式, 因为单例不一定会被用到, 如果一来就直接new出来可能造成资源浪费 1234567891011public class Student1 { // 2：成员变量初始化本身对象 private static Student1 student = new Student1(); // 1：构造私有 private Student1() { } // 3：对外提供公共方法获取对象 public static Student1 getSingletonInstance() { return student; }} 懒汉式单例双重检查锁方式123456789101112131415161718class Singleton { private static volatile Singleton singleton = null; private Singleton (){} public static Singleton getInstance(){ //2. 这一层判断: new出来之后不用每次都加一次锁, 很消耗性能 if (singleton == null){ //1. 加锁: 只能一个线程进去, 防止一个线程进去但是还没有new之前, 又进去了一个线程, 就会new出两个 synchronized (Singleton.class){ if (singleton == null){ //3. volatile关键字: 禁止指令重排(他还有一个特性是可见性), (1)在堆上开辟空间；(2)属性初始化;(3)引用指向对象 // 如果指令重排1-3-2的话, 这时候指令只执行到1-3, 这时有一个线程getInstance(), 就会拿到一个没有初始化的对象 singleton = new Singleton(); } } } return singleton; }} 静态内部类方式 JVM通过类加载器去加载一个类的时候，默认针对该流程是加锁的，也就是线程安全的。 调用getInstance()时候才会触发SingletonHolder类加载，会初始化类的静态成员，所以也是懒汉式 这个之后再才回去初始化内部类的成员变量 123456789public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton (){} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } 枚举方式 枚举类先天就是线程安全，且每一个枚举类型极其定义的枚举变量在JVM中都是唯一 而且反射枚举是会报错的12345678910111213141516enum Singleton { INSTANCE; public Singleton getInstance(){ return INSTANCE; } private int age; public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 原型模型一般用于大对象频繁复制, 比如工作流复制流程 原型模式虽然是创建型的模式，但是与工程模式没有关系，从名字即可看出，该模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。本小结会通过对象的复制，进行讲解。在Java中，复制对象是通过clone()实现的. 一般原型模式都会搭配工厂模式使用 优点 : 性能提高 避免构造函数的约束 例子先创建一个原型类： 123456789101112131415161718192021222324252627282930public abstract class Animal implements Cloneable { private String name; protected String type; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getType() { return type; } abstract void eat(); public Object clone(){ Object clone = null; try { clone = super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return clone; }} 很简单，一个原型类，只需要实现Cloneable接口，覆写clone方法，此处clone方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名，如cloneA或者cloneB，因为此处的重点是super.clone()这句话，super.clone()调用的是Object的clone()方法，而在Object类中，clone()是native的 子类 12345678910111213public class Cat extends Animal { public static final String TYPE_CAT = &quot;type_cat&quot;; public Cat() { type = TYPE_CAT; } @Override void eat() { System.out.println(getName() + &quot; --&gt; Cat is eat&quot;); }} 12345678910111213public class Dog extends Animal { public static final String TYPE_DOG = &quot;type_dog&quot;; public Dog() { type = TYPE_DOG; } @Override void eat() { System.out.println(getName() + &quot; --&gt; Dog is eat&quot;); }} 一个管理类 12345678910111213141516public class AnimalManager { private static ConcurrentHashMap&lt;String, Animal&gt; hashMap = new ConcurrentHashMap&lt;&gt;(); public static void load(){ hashMap.put(Dog.TYPE_DOG, new Dog()); hashMap.put(Cat.TYPE_CAT, new Cat()); } public static Animal getPrototype(String type){ Animal animal = hashMap.get(type); if (animal == null) throw new RuntimeException(&quot;此原型还没有注册&quot;); return (Animal)animal.clone(); }} 运行Main 123456789101112131415161718public class MainPrototype { public static void main(String[] args) { AnimalManager.load(); Animal dog = AnimalManager.getPrototype(Dog.TYPE_DOG); dog.setName(&quot;My name is DOG!!&quot;); dog.eat(); Animal cat = AnimalManager.getPrototype(Cat.TYPE_CAT); cat.setName(&quot;My name is CAT!!&quot;); cat.eat(); Animal cat2 = AnimalManager.getPrototype(Cat.TYPE_CAT); cat2.setName(&quot;My name is CAT2!!&quot;); cat2.eat(); }} 结果打印 My name is DOG!! –&gt; Dog is eatMy name is CAT!! –&gt; Cat is eatMy name is CAT2!! –&gt; Cat is eat 深复制和浅复制 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Prototype implements Cloneable, Serializable { private static final long serialVersionUID = 1L; private String string; private SerializableObject obj; /* 浅复制 */ public Object clone() throws CloneNotSupportedException { Prototype proto = (Prototype) super.clone(); return proto; } /* 深复制 */ public Object deepClone() throws IOException, ClassNotFoundException { /* 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); /* 读出二进制流产生的新对象 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return ois.readObject(); } public String getString() { return string; } public void setString(String string) { this.string = string; } public SerializableObject getObj() { return obj; } public void setObj(SerializableObject obj) { this.obj = obj; } } class SerializableObject implements Serializable { private static final long serialVersionUID = 1L; } 要实现深复制，需要采用流的形式读入当前对象的二进制输入，再写出二进制数据对应的对象。 构建者模式1234567891011121314151617181920212223242526272829303132333435363738394041424344class Person { private final int age; private final String name; //初始化私有 private Person(Builder build) { this.age = build.age; this.name = build.name; } //也可以不写 public static Person.Builder create() { return new Builder(); } public static final class Builder { private int age; private String name; //Return this public Builder setAge(int age) { this.age = age; return this; } public Builder setName(String name) { this.name = name; return this; } public Person build() { return new Person(this); } } //属性只提供get方法 public int getAge() { return age; } public String getName() { return name; }}","link":"/blog/2017/01/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fa2-%E5%88%9B%E5%BB%BA%E5%9E%8B/"},{"title":"设计模式-行为型","text":"主要介绍行为型：策略模式、模板方法模式 策略模式策略模式（Strategy Pattern）, 创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象. context对象中就是各种执行的方法, 策略对象就是实现各种算法. 比如qq登录, 微信登录等一系列实现等, 可以理解为多种算法. 这种就可以使用策略模式实现 优点 : 算法可以自由切换 避免使用多重条件判断 扩展性好 例子通用接口 1234public interface Strategy { int doOperation(int i, int j);} 各种算法实现 12345678//加法实现public class OperationAdd implements Strategy{ @Override public int doOperation(int i, int j) { return i + j; }} 12345678//减法实现public class OperationSubstract implements Strategy { @Override public int doOperation(int i, int j) { return i - j; }} Context来转接各种算法 12345678910111213public class Context { private Strategy strategy; public Context(Strategy strategy) { this.strategy = strategy; } public int executeStrategy(int i, int j) { return strategy.doOperation(i, j); }} 运行 1234567891011public class MainStrategy { public static void main(String[] args) { OperationAdd operationAdd = new OperationAdd(); OperationSubstract operationSubstract = new OperationSubstract(); int addResult = new Context(operationAdd).executeStrategy(2, 5); int subResult = new Context(operationSubstract).executeStrategy(2, 5); System.out.println(&quot;addResult = [&quot; + addResult + &quot;], subResult = [&quot; + subResult + &quot;]&quot;); }} 结果 addResult = [7], subResult = [-3] 模板方法模式用抽象类 主要解决: 当完成一个操作具有固定的流程时，由抽象固定流程步骤，具体步骤交给子类进行具体实现（固定的流程，不同的实现） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class Client { public static void main(String[] args) { System.out.println(&quot;准备炒豆芽&quot;); CookVegetable cookVegetable = new CookBeanSprout(); cookVegetable.cook(); System.out.println(); System.out.println(&quot;准备炒茄子&quot;); cookVegetable = new CookEggplant(); cookVegetable.cook(); } // 抽象模板类：定义炒菜流程 static abstract class CookVegetable { protected void wash() { System.out.println(&quot;洗菜&quot;); } protected void pourOil() { System.out.println(&quot;热油下锅&quot;); } protected void fry() { System.out.println(&quot;下菜翻炒&quot;); } // 具体调料由菜决定 protected abstract void pourSauce(); // 具体炒菜流程 public final void cook() { this.wash(); this.pourOil(); this.fry(); this.pourSauce(); System.out.println(&quot;起锅吃菜&quot;); } } // 豆芽 static class CookBeanSprout extends CookVegetable { @Override protected void pourOil() { System.out.println(&quot;热锅少油&quot;); } @Override protected void fry() { System.out.println(&quot;快速翻炒&quot;); } @Override protected void pourSauce() { System.out.println(&quot;加盐和少量生抽&quot;); } } // 茄子 static class CookEggplant extends CookVegetable { @Override protected void wash() { System.out.println(&quot;去除头尾，然后用水洗下&quot;); } @Override protected void pourOil() { System.out.println(&quot;热锅多油&quot;); } @Override protected void pourSauce() { System.out.println(&quot;加盐和鸡精&quot;); } }}","link":"/blog/2017/01/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fa3-%E8%A1%8C%E4%B8%BA%E5%9E%8B/"},{"title":"设计模式-结构型","text":"主要介绍结构型：适配器模式、装饰模式、代理模式 适配器模式适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。 应用场景: 类的适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。 接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 类的适配器模式1234567891011121314151617181920212223242526272829//被适配类class Source { public void method1() { System.out.println(&quot;this is original method!&quot;); }}interface Targetable { /* 与原类中的方法相同 */ void method1(); /* 新类的方法 */ void method2();}//适配器类, 这时候适配器拥有了Source类的功能class Adapter extends Source implements Targetable { @Override public void method2() { System.out.println(&quot;this is the targetable method!&quot;); }}class AdapterTest { public static void main(String[] args) { // Targetable 接口的实现类就具有了 Source 类的功能 Targetable target = new Adapter(); target.method1(); target.method2(); }} 对象的适配器模式基本思路和类的适配器模式相同，只是将 Adapter 类作修改，这次不继承 Source 类，而是持有Source 类的实例，以达到解决兼容性的问题 123456789101112131415public class Wrapper implements Targetable { private Source source; public Wrapper(Source source){ super(); this.source = source; } @Override public void method2() { System.out.println(&quot;this is the targetable method!&quot;); } @Override public void method1() { source.method1(); }} 接口的适配器模式比如我们一个接口中定义了很多方法, 但是其实不是所有方法都是会用到的, 这个时候需要借助于一个抽象类，该抽象类实现了该接口，实现了所有的方法，而我们不和原始的接口打交道，只和该抽象类取得联系，所以我们写一个类，继承该抽象类，重写我们需要的方法就行 123456789101112131415161718192021222324interface Sourceable { void method1(); void method2(); void method3();}//默认实现所有方法逻辑, 后面只需要用到什么接口就去重写什么就好了 abstract class Wrapper2 implements Sourceable{ public void method1(){} public void method2(){} public void method3(){}}class SourceSub1 extends Wrapper2 { public void method1(){ System.out.println(&quot;the sourceable interface's first Sub1!&quot;); }}class SourceSub2 extends Wrapper2 { public void method2(){ System.out.println(&quot;the sourceable interface's second Sub2!&quot;); }} 装饰模式装饰器模式（Decorator Pattern）, 允许向一个现有的对象添加新的功能，同时又不改变其结构。装饰者可以在所委托被装饰者的行为之前或之后加上自己的行为，以达到特定的目的。 假设我们现在去咖啡店要了一杯咖啡，可以加奶、加糖等等。咖啡和奶、糖分别有不同的价格。 咖啡就是我们的组件，奶和糖是我们的装饰者，现在我们要计算调制这样一杯咖啡花费多少。 Drink 接口类： 1234public interface Drink { public float cost(); public String getDescription();} Coffee 类： 1234567891011public class Coffee implements Drink { final private String description = &quot;coffee&quot;; //每杯 coffee 售价 10 元 public float cost() { return 10; } public String getDescription() { return description; }} CondimentDecorator 调味抽象类： 123456789101112131415public abstract class CondimentDecorator implements Drink { protected Drink decoratorDrink; public CondimentDecorator(Drink decoratorDrink) { this.decoratorDrink = decoratorDrink; } public float cost() { return decoratorDrink.cost(); } public String getDescription() { return decoratorDrink.getDescription(); }} Milk 牛奶装饰类： 123456789101112131415public class Milk extends CondimentDecorator { public Milk(Drink decoratorDrink) { super(decoratorDrink); } @Override public float cost() { return super.cost() + 2; } @Override public String getDescription() { return super.getDescription() + &quot; milk&quot;; }} Sugar 装饰类： 123456789101112131415public class Sugar extends CondimentDecorator { public Sugar(Drink decoratorDrink) { super(decoratorDrink); } @Override public float cost() { return super.cost() + 1; } @Override public String getDescription() { return super.getDescription() + &quot; sugar&quot;; }} 测试代码： 12345678910111213141516public class CoffeeShop { public static void main(String[] args) { //点一杯coffee Drink drink = new Coffee(); System.out.println(drink.getDescription() + &quot;:&quot; + drink.cost()); //加一份奶 drink = new Milk(drink); System.out.println(drink.getDescription() + &quot;:&quot; + drink.cost()); //加一份糖 drink = new Sugar(drink); System.out.println(drink.getDescription() + &quot;:&quot; + drink.cost()); //再加一份糖 drink = new Sugar(drink); System.out.println(drink.getDescription() + &quot;:&quot; + drink.cost()); }} 场景 扩展一个类的功能。 动态增加功能，动态撤销。 优点 装饰类和被装饰类可以独立发展，不会相互耦合 动态的将责任附加到对象身上。 缺点 多层装饰比较复杂。 装饰和代理模式的区别 装饰器模式强调的是增强自身，在被装饰之后你能够在被增强的类上使用增强后的功能。增强后你还是你，只不过能力更强了而已；代理模式强调要让别人帮你去做一些本身与你业务没有太多关系的职责（记录日志、设置缓存）。代理模式是为了实现对象的控制，因为被代理的对象往往难以直接获得或者是其内部不想暴露出来。 装饰模式是以对客户端透明的方式扩展对象的功能，是继承方案的一个替代方案；代理模式则是给一个对象提供一个代理对象，并由代理对象来控制对原有对象的引用； 装饰模式是为装饰的对象增强功能；而代理模式对代理的对象施加控制，但不对对象本身的功能进行增强； 来自https://zhuanlan.zhihu.com/p/97499017 代理模式静态代理如果已有的方法在使用的时候需要对原有的方法进行改进，此时有两种办法： 修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。 就是采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。 1234567891011121314151617181920212223242526272829303132333435363738394041interface Sourceable { void method();}class Source implements Sourceable { @Override public void method() { System.out.println(&quot;the original method!&quot;); }}class Proxy implements Sourceable { private Source source; public Proxy() { super(); this.source = new Source(); } @Override public void method() { before(); source.method(); atfer(); } private void atfer() { System.out.println(&quot;after proxy!&quot;); } private void before() { System.out.println(&quot;before proxy!&quot;); }}class ProxyTest { public static void main(String[] args) { Sourceable source = new Proxy(); source.method(); }} 动态代理JDK动态代理一定要继承接口 123456789101112131415161718public class DynamicProxyHandler implements InvocationHandler { private Object object; public DynamicProxyHandler(Object object) { this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;坐车去香港&quot;); Object result = method.invoke(object, args); System.out.println(&quot;坐车回香港&quot;); return result; }} 12345678BuyMacImpl buyMac = new BuyMacImpl(); BuyMac newProxyInstance = (BuyMac) Proxy.newProxyInstance( BuyMac.class.getClassLoader(), new Class[]{BuyMac.class}, new DynamicProxyHandler(buyMac)); newProxyInstance.buy(); CGLIB代理不需要继承接口,性能比JDK好.对于final方法不能代理 1234567891011121314151617181920public class CglibProxy implements MethodInterceptor { private Object target; public Object getInstance(final Object target){ this.target = target; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.target.getClass()); enhancer.setCallback(this); return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { System.out.println(&quot;坐车去香港&quot;); Object result = methodProxy.invoke(target, args); System.out.println(&quot;坐车回香港&quot;); return result ; }} 12345BuyMacImpl buyMac = new BuyMacImpl(); ((BuyMac) new CglibProxy().getInstance(buyMac)).buy(); ((BuyMacImpl) new CglibProxy().getInstance(buyMac)).buy();","link":"/blog/2017/01/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fa4-%E7%BB%93%E6%9E%84%E5%9E%8B/"},{"title":"设计模式-实战","text":"场景：QQ登陆、微信登陆等各种登陆方式，使用策略和工厂模式来实现 1234567891011121314151617181920212223242526272829303132333435363738394041@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = {&quot;classpath:jarvis-services.xml&quot;, &quot;classpath:jarvis-client.xml&quot;})public class GeneralTest { /** * 一般if操作 */ @Test public void test() { String loginType = &quot;QQ&quot;; if (&quot;QQ&quot;.equals(loginType)) { System.out.println(&quot;QQ&quot;); } else if (&quot;weixin&quot;.equals(loginType)) { System.out.println(&quot;weixin&quot;); } else if (&quot;weibo&quot;.equals(loginType)) { System.out.println(&quot;weibo&quot;); } } /** * 工厂+策略模式 */ @Test public void strategy() { String loginType = &quot;QQ&quot;; LoginHandle handle = LoginFactory.getStrategy(loginType); handle.login(); } /** * 工厂+策略+模板 * 比如在if中除了登陆逻辑之外还有其他逻辑 */ @Test public void pattern() { String loginType = &quot;QQ&quot;; AbstractHandle handle = LoginFactory2.getStrategy(loginType); handle.login(); handle.other(); }} 12345678910111213141516171819# 策略public interface LoginHandle extends InitializingBean { void login();}# 模板public abstract class AbstractHandle implements InitializingBean { public void login(){ throw new UnsupportedOperationException(); } public void other(){ throw new UnsupportedOperationException(); }} 工厂类 1234567891011121314151617181920212223242526272829public class LoginFactory { private static Map&lt;String, LoginHandle&gt; strategyMap = Maps.newConcurrentMap(); public static LoginHandle getStrategy(String type){ return strategyMap.get(type); } public static void register(String type, LoginHandle handle){ if (type != null &amp;&amp; handle != null){ strategyMap.put(type, handle); } }}public class LoginFactory2 { private static Map&lt;String, AbstractHandle&gt; strategyMap = Maps.newConcurrentMap(); public static AbstractHandle getStrategy(String type){ return strategyMap.get(type); } public static void register(String type, AbstractHandle handle){ if (type != null &amp;&amp; handle != null){ strategyMap.put(type, handle); } }} 具体实现 1234567891011121314151617181920212223242526272829303132@Componentpublic class QQLoginHandle implements LoginHandle{ @Override public void login() { System.out.println(&quot;QQ登陆&quot;); } @Override public void afterPropertiesSet() throws Exception { LoginFactory.register(&quot;QQ&quot;, this); }}@Componentpublic class QQLoginHandle2 extends AbstractHandle{ @Override public void login() { System.out.println(&quot;QQ登陆&quot;); } @Override public void other() { System.out.println(&quot;不同于登陆的其他操作&quot;); } @Override public void afterPropertiesSet() throws Exception { LoginFactory2.register(&quot;QQ&quot;, this); }}","link":"/blog/2017/01/05/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fb-%E4%BD%BF%E7%94%A8/"},{"title":"mysql-事务和锁","text":"简单介绍mysql事务和锁 事物的四大特性(ACID) 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 并发事务带来哪些问题 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复读和幻读区别：不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。 SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读READ-UNCOMMITTED √ √ √READ-COMMITTED × √ √REPEATABLE-READ × × √SERIALIZABLE × × × MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看，MySQL8.0 该命令改为SELECT @@transaction_isolation; 这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server) 是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读） 并不会有任何性能损失。 InnoDB存储引擎在分布式事务的情况下一般会用到SERIALIZABLE(可串行化) 隔离级别。 mysql锁mysql都是悲观锁 MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁 行级锁和表级锁 https://blog.csdn.net/qq_34337272/article/details/80611486 InnoDB存储引擎的锁的算法有三种： Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 相关知识点： innodb对于行的查询使用next-key lock Next-locking keying为了解决Phantom Problem幻读问题 当查询的索引含有唯一属性时，将next-key lock降级为record key Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1 https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB(%E5%9B%BE%E6%96%87%E8%AF%A6%E8%A7%A3).md 表级锁 表锁(在MysqlLayer层): 手动 元数据锁(在MysqlLayer层): 自动 意向锁(InnoDB): 内部使用 行级锁(InnoDB) 共享读锁: 手动加 排他写锁: 自动加 查看行锁状态: show STATUS like 'innodb_row_lock%'; Innodb_row_lock_current_waits:当前正在等待锁定的数量; Innodb_row_lock_time:从系统启动到现在锁定总时间长度; Innodb_row_lock_time_avg:每次等待所花平均时间; Innodb_row_lock_time_max:从系统启动到现在等待最常的一次所花的时间; Innodb_row_lock_waits:系统启动后到现在总共等待的次数; 行级锁InnoDB存储引擎实现 按照范围分为三种: 记录锁(Record Locks):锁定索引中一条记录. 主键指定 where id=3 间隙锁(Gap Locks): 锁定记录前.记录中.记录后的行 RR隔离级 (可重复读)– MySQL默认隔离级, 其实就是左开右开 临键锁(Next-Key): 记录锁 + 间隙锁, 其实就是左开右闭 记录锁(行锁)记录锁是封锁记录，记录锁也叫行锁 重点!重点!重点! InnoDB行锁是通过给索引上的索引项加锁来实现的,因此InnoDB这种行锁实现特点意味着:只有通过索引条件检索的数据,InnoDB才使用行级锁,否则,InnoDB将使用表锁! 共享读锁(S): 允许一个事务去读一行,阻止其他事务获得相同数据集的排他锁. 栗子: 1234begin;select * from [table_name] where id = 1 lock in share mode;update [table_name] set name = 'name修改了' where id = 1;COMMIT; 总结: 本事务可以修改被锁的行, 其他事物如果修改这一行都会被阻塞 本事务已经获取共享读锁的前提下, 其他事物依旧可以获取共享读锁 本事务已经获取共享读锁的前提下, 就不能在获取同行的排他写锁 使用场景: 确保本事务查到最新的数据 排他写锁(X): 允许获得排他写锁的事务更新数据,阻止其他事务取得相同数据集的共享读锁(不是)和排他写锁. wher条件只能索引使用, 不然直接锁表. 自动加: 对于UPDATE.DELETE和INSERT语句,InnoDB会自动给涉及数据集加排他锁(X) 手动加: SELECT * FROM [table_name] WHERE ... FOR UPDATE 总结: 本事务已经获取排他写锁的前提下, 其他事物可以查询(快照读), 但是不能修改 本事务已经获取排他写锁的前提下, 其他事物不能获取同行的共享读锁和排他写锁 使用场景: 确保某个事务查到最新的数据；并且只有该事务能对数据进行修改、删除等操作。 缺点: 因为排它锁只允许一个事务获取，所以如果是业务繁忙的情况下，一旦有某个业务不能及时的释放锁，则会导致其它事务的锁等待、锁等待超时、死锁等问题； 虽然共享锁可以给多个事务共享，但一旦有多个事务同时拥有共享锁，则所有事务都不能对数据进行 UPDATE DETELE 等操作，也会导致其它事务的锁等待、锁等待超时、死锁等问题； 都会影响数据库的并发能力。 间隙锁间隙锁就是为了解决幻读的情况, 只有在可重复读RR的隔离机制下(mysql默认隔离级别)才会生效 主键索引12345678910CREATE TABLE `test` ( `id` int(1) NOT NULL AUTO_INCREMENT, `name` varchar(8) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `test` VALUES ('1', '小罗');INSERT INTO `test` VALUES ('5', '小黄');INSERT INTO `test` VALUES ('7', '小明');INSERT INTO `test` VALUES ('11', '小红'); 这之后间隙为(左开右闭): (-infinity, 1] (1, 5] (5, 7] (7, 11] (11, +infinity] 123456789101112BEGIN;SELECT * FROM `test` WHERE `id` = 5 FOR UPDATE; -- 使用索引并且只会锁定一条数据, 只会产生记录锁...BEGIN;SELECT * FROM `test` WHERE `id` BETWEEN 5 AND 7 FOR UPDATE; -- TODO 这时候会产生间隙锁(5, 7](7, 11]两个间隙锁...BEGIN;SELECT * FROM `test` WHERE `id` = 3 FOR UPDATE; -- 查询不存在的主键也会产生间隙锁, 会产生(1, 5]... 普通索引1234567891011CREATE TABLE `test1` ( `id` int(1) NOT NULL AUTO_INCREMENT, `number` int(1) NOT NULL COMMENT '数字', PRIMARY KEY (`id`), KEY `number` (`number`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;INSERT INTO `test1` VALUES (1, 1);INSERT INTO `test1` VALUES (5, 3);INSERT INTO `test1` VALUES (7, 8);INSERT INTO `test1` VALUES (11, 12); 这之后间隙为: (-infinity, 1] (1, 3] (3, 8] (8, 12] (12, +infinity] 这时候查询 1SELECT * FROM `test1` WHERE `number` = 3 FOR UPDATE; 的间隙锁(1, 3]和(3, 8)注意这里的8是开的, 因为普通索引不唯一, 他永远不知道最后一个3是在哪一个位置, 必须找到一个不为3的, 所以开8 还有一种情况 12345678910111213141516171819//还原数据TRUNCATE test1;INSERT INTO `test1` VALUES (1, 1);INSERT INTO `test1` VALUES (5, 3);INSERT INTO `test1` VALUES (7, 8);INSERT INTO `test1` VALUES (11, 12);//开一个窗口BEGIN;SELECT * FROM `test1` WHERE `number` = 3 FOR UPDATE;//再开一个窗口INSERT INTO `test1` (`id`, `number`) VALUES (2, 1); # 阻塞INSERT INTO `test1` (`id`, `number`) VALUES (3, 2); # 阻塞INSERT INTO `test1` (`id`, `number`) VALUES (6, 8); # 阻塞INSERT INTO `test1` (`id`, `number`) VALUES (8, 8); # 正常执行INSERT INTO `test1` (`id`, `number`) VALUES (9, 9); # 正常执行INSERT INTO `test1` (`id`, `number`) VALUES (10, 12); # 正常执行UPDATE `test1` SET `number` = 5 WHERE `id` = 11 AND `number` = 12; # 阻塞 这里有一个奇怪的现象： 添加id = 6, number = 8的数据, 给阻塞了 添加id = 8, number = 8的数据, 正常执行了 将id = 11, number = 12的数据修改为id = 11, number = 5的操作, 给阻塞了 其实这里是会一个主键排序的 ID NUMBER 是否原始数据1 1 原始2 1 间隙数据, 阻塞3 2 间隙数据, 阻塞4 2 间隙数据, 阻塞5 3 原始数据, 加锁6 8 间隙数据, 阻塞7 8 原始数据8 8 间隙数据,正常9 9 间隙数据,正常10 12 间隙数据,正常11 12 原始数据 感谢MySQL的锁机制 - 记录锁、间隙锁、临键锁 https://www.jianshu.com/p/32904ee07e56 两阶段锁(2PL)12345begin;insert into...; // 加insert对应的锁update table ...; // 加update对应的锁delete from ... where ...; // 加delete对应的锁commit; //解锁阶段: 同时释放以上全部锁 注意这里分为加锁和解锁阶段, 两个阶段不相交 表级锁MySQL实现的表级锁定的争用状态变量show status like 'table%'; Table_locks_immediate: 产生表级锁定的次数 Table_locks_waited: 目前表锁等待次数 表锁(一般不用)两种形式: 表共享读锁(Read Lock): 加读锁后可以继续加读锁, 不能加写锁 表独占写锁(Write Lock): 加写锁后不能加读锁和写锁 手动添加表锁: 12345678// 手动添加表锁lock table [tableName] [read/write],[tableName] [read/write] ...;// 查看表锁情况show open tables;//删除表锁unlock tables; 添加锁表之后所有的session只能读取被锁的表, 都不能更新操作 12345678//给t_user添加读锁lock table t_user read;//这时候只可以查询锁住的表, 其他的表都不能查询select * from t_user where id = 1;//所有的更新操作都会阻塞update t_user set name = 'a' where id = 1;//删除表锁之后更新成功, 并且其他表也可以查询unlock tables; 元数据锁MDL (metaDataLock) 元数据:表结构 在 MySQL 5.5 版本中引入了 MDL,元数据锁主要是面向DML(Data Manipulation Language, 数据库操纵语言)和DDL(Data Definition Language, 数据库定义语言)之间的并发控制,如果对一张表做DML增删改查操作的同时,有一个线程在做DDL操作,不加控制的话,就会出现错误和异常.元数据锁不需要我们显式的加,系统默认会加.当做DML操作时,会申请一个MDL读锁; 当做DDL操作时,会申请一个MDL写锁; 读锁之间不互斥,读写和写写之间都互斥. session1: begin;–开启事务 select * from mylock;–加MDL读锁 session2: alter table mylock add f int; – 修改阻塞 session1:commit; –提交事务 或者 rollback 释放读锁 session2:Query OK, 0 rows affected (38.67 sec) –修改完成 意向锁意向锁的主要作用是为了全表更新数据时的性能提升.否则在全表更新数据时,需要先检索该表是否某些记录上面有行锁.意向锁是mysql内部使用的,不需要用户干预. 意向共享锁(IS):事务打算给数据行加行共享锁,事务在给一个数据行加共享锁前必须先取得该的IS锁. 意向排他锁(IX):事务打算给数据行加行排他锁,事务在给一个数据行加排他锁前必须先取得该表的IX锁. 比如: 事务A锁住了表中的一行,让这一行只能读,不能写. 之后,事务B申请整个表的写锁. 如果事务B申请成功,那么理论上它就能修改表中的任意一行,这与A持有的行锁是冲突的. 数据库需要避免这种冲突,就是说要让B的申请被阻塞,直到A释放了行锁. 数据库要怎么判断这个冲突呢?step1:判断表是否已被其他事务用表锁锁表step2:判断表中的每一行是否已被行锁锁住.注意step2,这样的判断方法效率实在不高,因为需要遍历整个表.于是就有了意向锁.在意向锁存在的情况下,事务A必须先申请表的意向共享锁,成功后再申请一行的行锁.在意向锁存在的情况下,上面的判断可以改成step1:不变step2:发现表上有意向共享锁,说明表中有些行被共享行锁锁住了,因此,事务B申请表的写锁会被阻塞.注意:申请意向锁的动作是数据库完成的,就是说,事务A申请一行的行锁的时候,数据库会自动先开始申请表的意向锁,不需要我们程序员使用代码来申请. 来自知乎-作者发条地精 死锁死锁是高并发环境下, 对热点数据更新时, 不同的事务加锁顺序不一致造成的. 产生死锁并不可怕, 应用端发现死锁后重新发起事务就行了, 并不会对数据库造成什么危害. 即使是在正常的业务中, 死锁也会时不时的发生. 当然, 若死锁太频繁, 导致事务无法进行, 那问题就很严重了. MySQL内部有一套死锁检测机制, 一旦发生死锁会立即回滚一个事务, 让另一个事务执行下去. 并且这个死锁回滚的的错误消息也会发送给客户端. InnoDB中有一个变量innodb_deadlock_detect={ON|OFF}就是来控制是否检测死锁. 死锁检测要遍历查询很多的队列, 在高并发环境中死锁检测将会是一个CPU密集型操作, 特别是当大量用户线程在等待同一个锁的时候, 系统性能会明显降低. 是否可以关闭这个功能呢? 可以的 如果关了发生死锁也不会一直等待. 因为InnoDB中还有一个变量, 对事务的等待时间做了限制innodb_lock_wait_timeout, 这个变量默认是50秒, 也就是说会死等五十秒而已. 减少死锁产生： 避免大事务，尽量使用索引 访问表顺序最好一致 隔离级别设置为rc，取消间隙锁","link":"/blog/2020/01/03/mysql-3.%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81/"},{"title":"redis-数据结构","text":"介绍redis数据结构 Redis是一种key/value型数据库, 比如SET message &quot;hello redis&quot;. 其中的key是message, 是一个包含了字符串”message”的对象. 而value是一个包含了”hello redis”的对象. RedisObject结构123456789101112131415161718192021typedef struct redisObject { // 类型 unsigned type:4; // 对齐位 unsigned notused:2; // 编码方式 unsigned encoding:4; // LRU 时间（相对于 server.lruclock） unsigned lru:22; // 引用计数 int refcount; // 指向对象的值 void *ptr;} robj; redis中的键值是通过全局哈希表来保存数据, 其实就是一个哈希桶组成的数组.哈希桶中的entry元素中保存了*key和*value指针, 分别指向了实际的键和值.这边最快的好处是, 只要算出键的哈希值, 就可以O(1)的获取哈希桶的位置, 访问对应entry元素. 问题来了, 哈希表的冲突问题和rehash可能带来操作阻塞怎么解决? 解决哈希冲突就是哈希冲突的多个都保存在一个哈希桶中, 用链表连接. 那如果链表过长, 就会就需要rehash, 就是增加哈希桶的数量, 使冲突变少.redis中默认使用两个全局哈希表, 开始的时候只用哈希表1, 数据变多执行渐进式rehash: 给哈希表2分配更大空间 把哈希表1数据重新映射并拷贝到哈希表2中. 拷贝时redis正常处理客户端请求, 每处理一次请求就顺带将这个索引位置上的所有entries拷贝到哈希表2中 释放哈希表1 存储类型 string: 简单动态字符串 list: 双向链表 O(N)/压缩列表 O(N) hash: 压缩列表/哈希表 O(1) set: 哈希表/整数数组 O(N) zset: 压缩列表/跳表 O(logN) 12345#define REDIS_STRING 0 // 字符串#define REDIS_LIST 1 // 列表#define REDIS_SET 2 // 集合#define REDIS_ZSET 3 // 有序集#define REDIS_HASH 4 // 哈希表 编码方式12345678910#define REDIS_ENCODING_RAW 0 // 编码为字符串#define REDIS_ENCODING_INT 1 // 编码为整数#define REDIS_ENCODING_HT 2 // 编码为哈希表#define REDIS_ENCODING_ZIPMAP 3 // 编码为 zipmap#define REDIS_ENCODING_LINKEDLIST 4 // 编码为双端链表#define REDIS_ENCODING_ZIPLIST 5 // 编码为压缩列表#define REDIS_ENCODING_INTSET 6 // 编码为整数集合#define REDIS_ENCODING_SKIPLIST 7 // 编码为跳跃表#define OBJ_ENCODING_EMBSTR 8 // 编码为跳跃表#define OBJ_ENCODING_QUICKLIST 9 // 编码为快速列表 通过object encoding [key]获取对象编码方式 string编码方式三种 int字符串键值的内容可以用一个 64位有符号整形 来表示时, Redis会将键值转化为 long型来进行存储 Redis 启动时会预先建立 10000 个分别存储 0~9999 的 redisObject 变量作为共享对象, 如果在这个范围, 直接指向共享对象, 不占用空间 embstrRedis 在保存长度小于 44 字节的字符串时 从内存结构上来讲 即字符串 sds结构体与其对应的 redisObject 对象分配在 同一块连续的内存空间, 比如redisObject内存后面就是embstr raw当字符串的键值为长度大于 44 的 超长字符串 时 和embstr不一样的是, redisObject内存和sds内存不在连续, 创建分配两次对象, 第一次sds, 第二次object分配对象 sdsredis没有直接使用c字符串(既以空字符串\\0结束), 而是使用了SDS(simple dynamic string). 123456789struct sdshdr{ //记录buf数组中已使用字节数量 //等于sds保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组, 用于保存字符串 char buf[];} buf[]长度=free+len+1, 因为最后面还有一个\\0.优点: 获取字符串长度, SDS是O(1), C字符串是O(n) 缓冲区溢出: 因为SDS记录了长度, 所以在将要溢出的时候重新分配内存, 杜绝缓冲区溢出. c字符串每次修改都要重新分配内存, 因为长度增大造成内存溢出, 长度减小造成内存泄漏. 注意: SDS不能存取二进制数据, 因为\\0是结束标识. 相关api1234567891011set [key] [value]get [key]setex [key] [expire] [value] //表示存储有效期为10秒setnx [key] [value]//setnx/msetnx相当于add操作,不会覆盖已有值, 返回是否成功getset [key] [value] //set操作, 返回替换前的值//incrby/incr/decrby/decr 对值的递增和递减exists [key]//检测是否存在某值type [key]ttl 返回有效期expire 设置有效期... list相关api1234567lpush foo a b c d //return 4lpop foo //return d, 注意这里是队列形式, 所以会这样rpushrpopllen 长度lindex 返回指定位置list元素, 不会弹出... 3.0及之前版本编码是ziplist或者linkedlist ziplistziplist是一种压缩列表. 当列表的元素个数小于list-max-ziplist-entries配置(默认512个), 同时所有值都小于list-maxziplist-value配置(默认为64字节), Redis会使用ziplist做为哈希的内部实现 压缩列表ziplist结构本身就是一个连续的内存块, 由表头+若干个entry节点和压缩列表尾部标识符zlend组成, 通过一系列编码规则, 提高内存的利用率, 使用于存储整数和短字符串 好处: 非常节省空间, 因为它存储的内容都是在连续内存区域当中.缺点: 为了保证他存储内存的连续性, 每次重新插入删除都要重新分配内存. linkedlist当列表类型无法满足ziplist要求时, redis会采用linkedlist做为列表的内部实现. linkedlist是一种双向链表. 它的结构比较简单, 节点中存放pre和next两个指针, 还有节点相关的信. 当每增加一个node的时候, 就需要重新malloc一块内存. 1234567891011121314151617181920212223typedef struct listNode{ //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value;}listNode;typedef struct list{ //表头节点 listNode.head; //表尾节点 listNode.tail; //链表包含的节点数量 unsigned long len; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void *(*free)(void *ptr); //节点值对比函数 int (*match)(void *ptr, void *key)}list; 优点: 双向链表具有前置节点和后置节点的引用, 两个节点时间复杂度都是O(1) 无环: head的prev节点和tail的next节点都指向null 带链表长度计算器, 获取长度O(1) 多态: 节点使用指针来保存节点值, 可以保存各种不同类型 在3.2版本开始编码方式为quicklist quicklist是一个双向链表, 而且是一个每个节点是ziplist的双向链表 12345678910111213141516171819202122232425262728typedef struct quicklistNode { struct quicklistNode *prev; //指向链表前一个节点的指针 struct quicklistNode *next; //指向链表后一个节点的指针 unsigned char *zl; //数据指. 如果当前节点的数据没有压缩, 那么它指向一个ziplist结构；否则, 它指向一个quicklistLZF结构 unsigned int sz; //表示zl指向的ziplist的总大小, 如果被压缩还是压缩前ziplist大小 unsigned int count : 16; //表示ziplist里面包含的数据项个数 unsigned int encoding : 2; //表示ziplist是否压缩了 unsigned int container : 2; //表明一个quicklist节点下面是直接存数据, 还是使用ziplist存数据, 或者用其它的结构来存数据 unsigned int recompress : 1; //当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时, 需要把数据暂时解压, 这时就设置recompress=1做一个标记, 等有机会再把数据重新压缩 unsigned int attempted_compress : 1; //这个值只对Redis的自动化测试程序有. 我们不用管它 unsigned int extra : 10; //其它扩展字段} quicklistNode;//quicklistLZF结构表示一个被压缩过的ziplisttypedef struct quicklistLZF { unsigned int sz; //表示压缩后的ziplist大小 char compressed[]; //存放压缩后的ziplist字节数组} quicklistLZF;typedef struct quicklist { quicklistNode *head; quicklistNode *tail; unsigned long count; //所有ziplist数据项的个数总和 unsigned long len; //quicklist节点的个数 int fill : 16; //ziplist大小设置, 存放list-max-ziplist-size参数的值 unsigned int compress : 16; //节点压缩深度设置, 存放list-compress-depth参数的值} quicklist; hash对应api123456hset [hashKey] [k] [v]hget [hashKey] [k]hexists [hashKey] [k]hdelhlen... htziplist 可以是ziplist或者hashtable ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储. 当对象数目不多且内容不大时, 这种方式效率是很高的 创建空白哈希表时, 程序默认使用REDIS_ENCODING_ZIPLIST编码, 当以下任何一个条件被满足时, 程序将编码从REDIS_ENCODING_ZIPLIST切换为 REDIS_ENCODING_HT： 哈希表中某个键或某个值的长度大于server.hash_max_ziplist_value （默认值为 64) . 压缩列表中的节点数量大于server.hash_max_ziplist_entries（默认值为 512) . redis的hash架构就是标准的hashtab的结构, 通过挂链解决冲突问. 12345678910111213//哈希表是由数组table组成, table每个元素都是指向dictEntry结构typedef struct dictEntry{ //键 void *key; //值 union{ void *val; uint64_tu64; int64_ts64; }v; //指向下一个哈希表节点, 形成链表 struct dictEntry *next;}dictEntry; dict中存储的键值对, 是通过dictEntry这个结构间接持有的, k通过指针间接持有键, v通过指针间接持有值. 注意, 若值是整数值的话, 是直接存储在v字段中的, 而不是间接持有. 同时next指针用于指向, 在bucket索引值冲突时, 以链式方式解决冲突, 指向同索引的下一个dictEntry结构. 12345678910111213typedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ int iterators; /* number of iterators currently running */ } dict; typedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; dict即为字典. 其中type字段中存储的是本字典使用到的各种函数指针, 包括散列函数, 键与值的复制函数, 释放函数, 以及键的比较函数. privdata是用于存储用户自定义数据. 这样, 字典的使用者可以最大化的自定义字典的实现, 通过自定义各种函数实现, 以及可以附带私有数据, 保证了字典有很大的调优空间. 字典为了支持平滑扩容, 定义了ht[2]这个数组字段. 其用意是这样的: 一般情况下, 字典dict仅持有一个哈希表dictht的实例, 即整个字典由一个bucket实现. 随着插入操作, bucket中出现冲突的概率会越来越大, 当字典中存储的结点数目, 与bucket数组长度的比值达到一个阈值(1:1)时, 字典为了缓解性能下降, 就需要扩容 扩容的操作是平滑的, 即在扩容时, 字典会持有两个dictht的实例, ht[0]指向旧哈希表, ht[1]指向扩容后的新哈希表. set对应api1234567sadd [key] [value] //返回是否成功srem [key] [value] //删除spop [key] //弹出首元素scard [key] //返回元素个数smembers [key] //返回所有元素//sinter/sunion/sdiff&amp;nbsp; 返回两个表中元素的交集/并集/补集//sinterstore/sunionstore/sdiffstore 将两个表交集/并集/补集元素copy到第三个表中 集合对象的编码可以是intset或者hashtable intsetht使用intset存储必须满足下面两个条件, 否则使用hashtable, 条件如下： 结合对象保存的所有元素都是整数值 集合对象保存的元素数量不超过512个 intset是一个整数集合, 里面存的为某种同一类型的整数, 支持如下三种长度的整数： 123#define INTSET_ENC_INT16 (sizeof(int16_t)) #define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t)) intset是一个有序集合, 查找元素的复杂度为O(logN), 但插入时不一定为O(logN), 因为有可能涉及到升级操. 比如当集合里全是int16_t型的整数, 这时要插入一个int32_t, 那么为了维持集合中数据类型的一致, 那么所有的数据都会被转换成int32_t类型, 涉及到内存的重新分配, 这时插入的复杂度就为O(N).intset不支持降级操. 1234567891011121314//intset内部其实是一个数组（int8_t coentents[]数组）, 而且存储数据的时候是有序的, 因为在查找数据的时候是通过二分查找来实现的typedef struct intset { // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];} intset; zsetziplist有序集合的编码可能两种, 一种是ziplist, 另一种是skiplist与dict的结. 在同时满足以下两个条件的时候使用ziplist, 其他时候使用skiplist, 两个条件如下： 有序集合保存的元素数量小于128个 有序集合保存的所有元素的长度小于64字节 skiplist1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* * 有序集合 */typedef struct zset { // 字典, 键为成员, 值为分值 // 用于支持 O(1) 复杂度的按成员取分值操作 dict *dict; // 跳跃表, 按分值排序成员 // 用于支持平均复杂度为 O(log N) 的按分值定位成员操作 // 以及范围操作 zskiplist *zsl;} zset;/* * 跳跃表 */typedef struct zskiplist { // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;} zskiplist;/* * 跳跃表节点 */typedef struct zskiplistNode { // 成员对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; } level[];} zskiplistNode; 自定义数据类型redis基本对象结构 RedisObject内部组成包括type、encoding、lru和refcount , 还有*ptr指针 type：表示值的类型，涵盖了我们前面学习的五大基本类型 encoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等； lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对 refcount：记录了对象的引用计数 *ptr：是指向数据的指针。 只需定义新的数据类型还有type,coding之后用*ptr指针指向新类型的实现就好了. 问题假设保存一亿个键值对, 用什么数据类型? 12photo_id: 1101000051photo_obj_id: 3301000051 用string会比较消耗内存, 因为string是sds类型, 还需要额外的数据保存数据长度, 空间使用等, 本身其实就保存了两个10位数的Long类型. buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\\0”，这就会额外占用1个字节的开销。 len：占4个字节，表示buf的已用长度。 alloc：也占个4字节，表示buf的实际分配长度，一般大于len。 除了SDS占用, 还有就是redisObject结构体. 因为每一个key都会有一个RedisObject统一记录这些元数据, 一个RedisObject包含了8字节的元数据和一个8字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向String类型的SDS结构所在的内存地址. 还有就是因为一个个key是分散的, Redis会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个dictEntry的结构体，用来指向一个键值对。dictEntry结构中有三个8字节的指针，分别指向key、value以及下一个dictEntry，三个指针共24字节.但是这三个指针只有24字节，为什么会占用了32字节呢？这就要提到Redis使用的内存分配库jemalloc了。jemalloc在分配内存时，会根据我们申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，这样可以减少频繁分配的次数。所以会使用32字节. 感谢: 漫画算法：什么是跳跃表？ 跳表介绍 https://www.jianshu.com/p/28138a5371d0 https://segmentfault.com/a/1190000018887256 https://stor.51cto.com/art/201910/605032.htm","link":"/blog/2020/02/02/redis-2.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"springboot-自动配置","text":"一直都在用springboot的自动化配置，但是一直没有总结。 1234567@SpringBootApplicationpublic class DemoSpringbootApplication { public static void main(String[] args) { SpringApplication.run(DemoSpringbootApplication.class, args); }} @SpringBootApplication @SpringBootApplication包含了@EnableAutoConfiguration注解 @EnableAutoConfiguration注解主要点在@Import(AutoConfigurationImportSelector.class)和@AutoConfigurationPackage @AutoConfigurationPackage源码 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(AutoConfigurationPackages.Registrar.class)public @interface AutoConfigurationPackage { String[] basePackages() default {}; Class&lt;?&gt;[] basePackageClasses() default {};} Registrar源码 1234567891011121314static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports { @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) { //这里其实扫描了项目的顶级包名，这就是为什么Springboot可以扫描Application包名以下所有包名 register(registry, new PackageImports(metadata).getPackageNames().toArray(new String[0])); } @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) { return Collections.singleton(new PackageImports(metadata)); }} AutoConfigurationImportSelector源码，主要方法是在getAutoConfigurationEntry下面的List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); 1234567protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) { List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations;} 这里会去找META-INF/spring.factories的key为org.springframework.boot.autoconfigure.EnableAutoConfiguration对应的value。这个值就是自动化加载的类名，这里只是放入一个ConcurrentReferenceHashMap缓存中。 SpringApplication.run() new SpringApplication()并且初始化了一些参数的配置和监听器的处理 run()这里面主要就是启动了初始化的监听器，设置一些初始参数 run()调用createApplicationContext() 这里如果用SERVLET会实例化一个AnnotationConfigServletWebServerApplicationContext，这个构造方法是 1234public AnnotationConfigServletWebServerApplicationContext() { this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this);} 然而AnnotatedBeanDefinitionReader构造 123456789public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) { Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); Assert.notNull(environment, &quot;Environment must not be null&quot;); this.registry = registry; //用于处理 @ConditionalOnBean @ConditionalOnClass this.conditionEvaluator = new ConditionEvaluator(registry, environment, null); //为IOC容器注册相关的后置处理器 AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry);} AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); 1234567891011121314151617181920212223***Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8);/**检查IOC容器是否有ConfigurationClassPostProcessor，没有加入BeanDefinitionRegistry**/if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) { //如果不存在， 创建RootBeanDefinition RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); //往IOC容器注册 ConfigurationClassPostProcessor beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME));}***private static BeanDefinitionHolder registerPostProcessor( BeanDefinitionRegistry registry, RootBeanDefinition definition, String beanName) { definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); //往IOC容器注册 BeanDefinition registry.registerBeanDefinition(beanName, definition); return new BeanDefinitionHolder(definition, beanName);} ConfigurationClassPostProcessor继承了BeanDefinitionRegistryPostProcessor，IOC容器在启动后会优先先加载容器中的后置处理器，并执行后置处理器的方法。 在run()中会调用refreshContext()方法，最终还是调到spring的refresh方法 123456789101112131415161718192021222324252627282930313233343536373839// 容器初始化前的准备工作prepareRefresh();// 初始化 DefaultListableBeanFactoryConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();// 为beanFactory设置容器特性，例如类加载器、事件处理器等prepareBeanFactory(beanFactory);try { //空实现，为容器的某些子类指定特殊的beanPost事件处理器 postProcessBeanFactory(beanFactory); //调用所有注册的BeanFactoryPostProcessor的bean invokeBeanFactoryPostProcessors(beanFactory); //将BeanPostProcessor后置处理器的bean追加到BeanFactory的Bean后置处理器列表中，用于触发bean的生命周期 registerBeanPostProcessors(beanFactory); //初始化信息源，和国际化相关 initMessageSource(); //初始化容器事件传播器 initApplicationEventMulticaster(); //调用子类的某些特殊bean初始化方法 onRefresh(); //为事件传播器注册事件监听器 registerListeners(); //初始化所有剩余的单例bean finishBeanFactoryInitialization(beanFactory); //初始化容器的生命周期时间处理器，并发布容器的生命周期事件 finishRefresh();} invokeBeanFactoryPostProcessors()方法会把BeanFactory里注册的BeanBeanFactoryPostProcessor类型的bean优先实例化并进行调用 ConfigurationClassPostProcessor作用是修改IOC容器中的元数据，SpringBoot就是在此加载自动装配类注册到IOC容器中 123456789101112131415161718public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) { //为入参的IOC容器生成唯一的id int registryId = System.identityHashCode(registry); //如果处理过了，则抛异常 if (this.registriesPostProcessed.contains(registryId)) { throw new IllegalStateException( &quot;postProcessBeanDefinitionRegistry already called on this post-processor against &quot; + registry); } //如果处理过了，则抛异常 if (this.factoriesPostProcessed.contains(registryId)) { throw new IllegalStateException( &quot;postProcessBeanFactory already called on this post-processor against &quot; + registry); } //追加处理过的标识 this.registriesPostProcessed.add(registryId); //开始进行自动装配类的加载 processConfigBeanDefinitions(registry);} processConfigBeanDefinitions 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) { //缓存拥有@Configuration注解的bean List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); //获取容器中所有已注册的bean名称 String[] candidateNames = registry.getBeanDefinitionNames(); //遍历所有bean for (String beanName : candidateNames) { //得到 BeanDefinition BeanDefinition beanDef = registry.getBeanDefinition(beanName); //检查 BeanDefinition 是否有包含configurationClass属性的值，有值证明已处理过，则忽略加入缓存 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) { if (logger.isDebugEnabled()) { logger.debug(&quot;Bean definition has already been processed as a configuration class: &quot; + beanDef); } } //检查 BeanDefinition 的目标类是否包含@Configuration 注解 else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) { //追加到缓存中 configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); } } // 缓存为空 则忽略 if (configCandidates.isEmpty()) { return; } // 进行排序 configCandidates.sort((bd1, bd2) -&gt; { int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); }); // 从容器中获取自定义的bean名称生成策略 SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) { sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) { BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) { this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; } } } /** 如果环境变量为空，则进行初始化，但SpringBoot在初始化 ApplicationContext 之前会初始化Environment , 并注入到ApplicationContext中,所以下面的条件不会成立 **/ if (this.environment == null) { this.environment = new StandardEnvironment(); } // 初始化 @Configuration 注解处理器 ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); //缓存要处理的自动装配类 Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); //缓存处理过的自动装配类 Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do { //重点关注该方法，自动装配类的加载在里面完成 parser.parse(candidates); //校验工作 parser.validate(); //把加载的装配类放到Set中 Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); //删除已处理过的自动装配类 configClasses.removeAll(alreadyParsed); // 初始化 自动装配类的bean读取器 ConfigurationClassBeanDefinitionReader if (this.reader == null) { this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); } /** 主要逻辑是把装配类的所有被@Bean修饰的方法转换成 ConfigurationClassBeanDefinition 并注册到IOC **/ this.reader.loadBeanDefinitions(configClasses); //追加到处理过的自动装配类缓存中 alreadyParsed.addAll(configClasses); //清空要处理的自动装配类缓存 candidates.clear(); //如果此时IOC容器注册的bean数量大于加载装配类前缓存的bean数量，说明成功注册了新的 BeanDefinition 到IOC容器中 if (registry.getBeanDefinitionCount() &gt; candidateNames.length) { //IOC容器最新bean名称集合 String[] newCandidateNames = registry.getBeanDefinitionNames(); //老的bean名称集合 Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); //初始化处理过的装配类集合 Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) { alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); } //遍历IOC容器最新bean名称集合 for (String candidateName : newCandidateNames) { //如果老的bean名称集合不包含最新的bean名称 if (!oldCandidateNames.contains(candidateName)) { //获取对应的BeanDefinition BeanDefinition bd = registry.getBeanDefinition(candidateName); //检查BeanDefinition 拥有@Configuration注解 ，并且在处理过的装配类缓存中不存在 if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) { //追加到candidates缓存，下一次循环会继续处理 candidates.add(new BeanDefinitionHolder(bd, candidateName)); } } } candidateNames = newCandidateNames; } } while (!candidates.isEmpty()); //往IOC容器注册自动装配类队列，队列里面包含了符合条件的自动装配类 //名称为ConfigurationClassPostProcessor.importRegistry if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) { sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); } if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) { // Clear cache in externally provided MetadataReaderFactory; this is a no-op // for a shared cache since it'll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); }} 从IOC容器遍历所有注册的BeanDefinition，并对目标Class的注解进行递归查找拥有@Configuration注解的BeanDefinition，第一次加载会加载到启动类对应的BeanDefinition，我们查看@SpringBootApplication源码会看到@SpringBootConfiguration，点击查看@SpringBootConfiguration会看到@Configuration。在run()方法的prepareContext()中注册的 ConfigurationClassParser.parse() 123456789101112131415161718192021222324252627282930public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) { //初始化缓存集合 this.deferredImportSelectors = new LinkedList&lt;&gt;(); //遍历装配包装类 for (BeanDefinitionHolder holder : configCandidates) { //得到真正装配类的 BeanDefinition BeanDefinition bd = holder.getBeanDefinition(); try { //根据BeanDefinition 的不同实现类，委派给相应的解析方法 if (bd instanceof AnnotatedBeanDefinition) { parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); } else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) { parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); } else { parse(bd.getBeanClassName(), holder.getBeanName()); } } catch (BeanDefinitionStoreException ex) { throw ex; } catch (Throwable ex) { throw new BeanDefinitionStoreException( &quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex); } } //最后处理DeferredImportSelector的实现类 processDeferredImportSelectors();} 三个不同的parse()解析方法，可以看到最终是委派给processConfigurationClass(ConfigurationClass configClass)进行处理 123456789101112131415161718192021222324252627282930313233343536373839protected void processConfigurationClass(ConfigurationClass configClass) throws IOException { //检查装配类是否需要跳过装配 if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) { return; } //检查缓存是否加载过此装配类 ConfigurationClass existingClass = this.configurationClasses.get(configClass); if (existingClass != null) { //如果装配类已加载 if (configClass.isImported()) { //如果缓存装配类已加载 if (existingClass.isImported()) { //合并加载类是由哪个装配类带出来的，可以理解为合并装配类的leader existingClass.mergeImportedBy(configClass); } // Otherwise ignore new imported config class; existing non-imported class overrides it. return; } else { //从缓存中删除装配类 this.configurationClasses.remove(configClass); this.knownSuperclasses.values().removeIf(configClass::equals); } } // 将装配类转换为 SourceClass SourceClass sourceClass = asSourceClass(configClass); /** 开始循环解析 ConfigurationClass 重点关注！ **/ do { sourceClass = doProcessConfigurationClass(configClass, sourceClass); } while (sourceClass != null); //缓存装配类 this.configurationClasses.put(configClass, configClass);} 这里主要做了3个事情 检查装配类是否需要跳过装配，此处用于解析包含@Conditional注解的装配类，例如@ConditionalOnClass @ConditionalOnBean @ConditionalOnProperty 检查是否重复加载，如果缓存里存在，则忽略 将装配类转换为SourceClass，并委派给doProcessConfigurationClass() 进行解析，如果返回的结果不为空，则继续循环解析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException { //检查是否有Component注解，如果拥有的话， 遍历其内部类拥有@Configuration注解的类，递归processConfigurationClass()解析 if (configClass.getMetadata().isAnnotated(Component.class.getName())) { processMemberClasses(configClass, sourceClass); } //检查是否有 @PropertySource 注解，有的话则加载配置文件，追加到环境变量Environment中 for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) { if (this.environment instanceof ConfigurableEnvironment) { processPropertySource(propertySource); } else { logger.info(&quot;Ignoring @PropertySource annotation on [&quot; + sourceClass.getMetadata().getClassName() + &quot;]. Reason: Environment must implement ConfigurableEnvironment&quot;); } } // 获取@ComponentScan注解配置信息 Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); //检查是否拥有@ComponentScan注解信息，并且满足加载条件进入扫描代码块 if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) { for (AnnotationAttributes componentScan : componentScans) { /** 委派给 ComponentScanAnnotationParser 把带有自动装配注解的类（例如：@Compoent @Service）扫描出来，并加载到IOC容器中, 因为 @SpringBootApplication 注解中包含了@ComponentScan注解， 所以会扫描启动类所在包下的所有类 **/ Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // 遍历扫描出来的元数据BeanDefinitionHolder for (BeanDefinitionHolder holder : scannedBeanDefinitions) { BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) { bdCand = holder.getBeanDefinition(); } //检查扫描的类是否包含@Configuration，包含则优先解析扫描出来的ConfigurationClass配置类 if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) { parse(bdCand.getBeanClassName(), holder.getBeanName()); } } } } /** 处理 @Import 注解， 主要逻辑是： 1. 遍历 @Import 的值 2. 判断值的所属类型 2.1. 如果是ImportSelector的实现类，则调用 selectImports() 返回 一组配置类递归给 processImports() 方法加载 2.2. 如果是 DeferredImportSelector 的实现类，则加载到 deferredImportSelectors 内存中 ，延迟加载 2.3. 如果是 ImportBeanDefinitionRegistrar 的实现类，则会追加到对应的 ConfigurationClass 的importBeanDefinitionRegistrars属性中 最后在ConfigurationClassParser.loadBeanDefinitions() 对所有ConfigurationClass进行加载时， 会调用 ImportBeanDefinitionRegistrar.registerBeanDefinitions() 通过编码的方式扩展，加载Bean元数据 2.4. 如果都不是，当成一个配置类， 递归processConfigurationClass() 加载解析 我们重点关注DeferredImportSelector，因为@EnableAutoConfiguration注解里导入的类是 AutoConfigurationImportSelector **/ processImports(configClass, sourceClass, getImports(sourceClass), true); /** 处理@ImportResource注解，把spring的bean配置文件缓存到ConfigurationClass.importedResources中， 最后在ConfigurationClassParser.loadBeanDefinitions()对所有ConfigurationClass进行加载时，会使用 XmlBeanDefinitionReader 进行解析加载 **/ AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class); if (importResource != null) { String[] resources = importResource.getStringArray(&quot;locations&quot;); Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;); for (String resource : resources) { String resolvedResource = this.environment.resolveRequiredPlaceholders(resource); configClass.addImportedResource(resolvedResource, readerClass); } } // 处理带有@Bean注解修饰的方法，并缓存到ConfigurationClass.beanMethods Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass); for (MethodMetadata methodMetadata : beanMethods) { configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass)); } processInterfaces(configClass, sourceClass); // 查看是否拥有父类，并且父类不是java开头的包，则返回父类，循环加载父类配置信息 if (sourceClass.getMetadata().hasSuperClass()) { String superclass = sourceClass.getMetadata().getSuperClassName(); if (superclass != null &amp;&amp; !superclass.startsWith(&quot;java&quot;) &amp;&amp; !this.knownSuperclasses.containsKey(superclass)) { this.knownSuperclasses.put(superclass, configClass); // Superclass found, return its annotation metadata and recurse return sourceClass.getSuperClass(); } } // 没有父类，外层循环结束 return null;}","link":"/blog/2021/04/20/springboot-1.%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/"},{"title":"zookeeper-原理","text":"介绍zookeeper原理 概述ZooKeeper 是一个开源的分布式协调服务 用于数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能 分布式应用的优点 可靠性 - 单个或几个系统的故障不会使整个系统出现故障。 可扩展性 - 可以在需要时增加性能，通过添加更多机器，在应用程序配置中进行微小的更改，而不会有停机时间。 透明性 - 隐藏系统的复杂性，并将其显示为单个实体/应用程序。 分布式应用的挑战 竞争条件 - 两个或多个机器尝试执行特定任务，实际上只需在任意给定时间由单个机器完成。例如，共享资源只能在任意给定时间由单个机器修改。 死锁 - 两个或多个操作等待彼此无限期完成。 不一致 - 数据的部分失败。 什么是Apache ZooKeeperApache ZooKeeper是由集群（节点组）使用的一种服务，用于在自身之间协调，并通过稳健的同步技术维护共享数据。ZooKeeper本身是一个分布式应用程序，为写入分布式应用程序提供服务。 ZooKeeper提供的常见服务如下 : 命名服务 - 按名称标识集群中的节点。它类似于DNS，但仅对于节点。 配置管理 - 加入节点的最近的和最新的系统配置信息。 集群管理 - 实时地在集群和节点状态中加入/离开节点。 选举算法 - 选举一个节点作为协调目的的leader。 锁定和同步服务 - 在修改数据的同时锁定数据。此机制可帮助你在连接其他分布式应用程序（如Apache HBase）时进行自动故障恢复。 高度可靠的数据注册表 - 即使在一个或几个节点关闭时也可以获得数据。 分布式应用程序提供了很多好处，但它们也抛出了一些复杂和难以解决的挑战。ZooKeeper框架提供了一个完整的机制来克服所有的挑战。竞争条件和死锁使用故障安全同步方法进行处理。另一个主要缺点是数据的不一致性，ZooKeeper使用原子性解析。 ZooKeeper的好处以下是使用ZooKeeper的好处： 简单的分布式协调过程 同步 - 服务器进程之间的相互排斥和协作。此过程有助于Apache HBase进行配置管理。 有序的消息 序列化 - 根据特定规则对数据进行编码。确保应用程序运行一致。这种方法可以在MapReduce中用来协调队列以执行运行的线程。 可靠性 原子性 - 数据转移完全成功或完全失败，但没有事务是部分的。 基础在深入了解ZooKeeper的运作之前，让我们来看看ZooKeeper的基本概念。我们将在本章中讨论以下主题：1、Architecture（架构）2、Hierarchical namespace（层次命名空间）3、Session（会话）4、Watches（监视） ZooKeeper的架构看看下面的图表。它描述了ZooKeeper的“客户端-服务器架构”。 作为ZooKeeper架构的一部分的每个组件在下表中进行了说明。 部分 描述 Client（客户端） 客户端，我们的分布式应用集群中的一个节点，从服务器访问信息。对于特定的时间间隔，每个客户端向服务器发送消息以使服务器知道客户端是活跃的。类似地，当客户端连接时，服务器发送确认码。如果连接的服务器没有响应，客户端会自动将消息重定向到另一个服务器。 Server（服务器） 服务器，我们的ZooKeeper总体中的一个节点，为客户端提供所有的服务。向客户端发送确认码以告知服务器是活跃的。 Ensemble ZooKeeper服务器组。形成ensemble所需的最小节点数为3。 Leader 服务器节点，如果任何连接的节点失败，则执行自动恢复。Leader在服务启动时被选举。 Follower 跟随leader指令的服务器节点。 层次命名空间下图描述了用于内存表示的ZooKeeper文件系统的树结构。ZooKeeper节点称为 znode 。每个znode由一个名称标识，并用路径(/)序列分隔。 在图中，首先有一个由“/”分隔的znode。在根目录下，你有两个逻辑命名空间 config 和 workers 。 config 命名空间用于集中式配置管理，workers 命名空间用于命名。 在 config 命名空间下，每个znode最多可存储1MB的数据。这与UNIX文件系统相类似，除了父znode也可以存储数据。这种结构的主要目的是存储同步数据并描述znode的元数据。此结构称为 ZooKeeper数据模型。 ZooKeeper数据模型中的每个znode都维护着一个 stat 结构。一个stat仅提供一个znode的元数据。它由版本号，操作控制列表(ACL)，时间戳和数据长度组成。 版本号 - 每个znode都有版本号，这意味着每当与znode相关联的数据发生变化时，其对应的版本号也会增加。当多个zookeeper客户端尝试在同一znode上执行操作时，版本号的使用就很重要。 操作控制列表(ACL) - ACL基本上是访问znode的认证机制。它管理所有znode读取和写入操作。 时间戳 - 时间戳表示创建和修改znode所经过的时间。它通常以毫秒为单位。ZooKeeper从“事务ID”(zxid)标识znode的每个更改。Zxid 是唯一的，并且为每个事务保留时间，以便你可以轻松地确定从一个请求到另一个请求所经过的时间。 数据长度 - 存储在znode中的数据总量是数据长度。你最多可以存储1MB的数据。 Znode类型 持久节点(PERSISTENT): zk集群宕机或client宕机都不会丢失, 默认类型 临时节点(EPHEMERAL): client宕机或者client在指定超时时间内没有给zk群发消息, 节点就会消失. 因此只有临时节点不允许有子节点, 如果临时节点被删除, 则下一个合适的节点将填充其位置. 临时节点在leader选举中起着重要作用。 顺序节点: 当一个新的znode被创建为一个顺序节点时, ZooKeeper通过将10位的序列号附加到原始名称来设置znode的路径. 如果将具有路径/myapp会将路径更改为/myapp0000000001, 并将下一个序列号设置为0000000002. 顺序节点在锁定和同步中起重要作用 持久顺序节点(PERSISTENT_SEQUENTIAL) 临时顺序节点(EPHEMERAL_SEQUENTIAL) Sessions（会话）会话对于ZooKeeper的操作非常重要。会话中的请求按FIFO顺序执行。一旦客户端连接到服务器，将建立会话并向客户端分配会话ID 。 客户端以特定的时间间隔发送心跳以保持会话有效。如果ZooKeeper集合在超过服务器开启时指定的期间（会话超时）都没有从客户端接收到心跳，则它会判定客户端死机。 会话超时通常以毫秒为单位。当会话由于任何原因结束时，在该会话期间创建的临时节点也会被删除。 Watches（监视）Watcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。 工作流一旦ZooKeeper集合启动，它将等待客户端连接。客户端将连接到ZooKeeper集合中的一个节点。它可以是leader或follower节点。一旦客户端被连接，节点将向特定客户端分配会话ID并向该客户端发送确认。如果客户端没有收到确认，它将尝试连接ZooKeeper集合中的另一个节点。 一旦连接到节点，客户端将以有规律的间隔向节点发送心跳，以确保连接不会丢失。 如果客户端想要读取特定的znode，它将会向具有znode路径的节点发送读取请求，并且节点通过从其自己的数据库获取来返回所请求的znode。为此，在ZooKeeper集合中读取速度很快。 如果客户端想要将数据存储在ZooKeeper集合中，则会将znode路径和数据发送到服务器。连接的服务器将该请求转发给leader，然后leader将向所有的follower重新发出写入请求。如果只有大部分节点成功响应，而写入请求成功，则成功返回代码将被发送到客户端。 否则，写入请求失败。绝大多数节点被称为 Quorum 。 ZooKeeper集合中的节点让我们分析在ZooKeeper集合中拥有不同数量的节点的效果。 如果我们有单个节点，则当该节点故障时，ZooKeeper集合将故障。它有助于“单点故障”，不建议在生产环境中使用。 如果我们有两个节点而一个节点故障，我们没有占多数，因为两个中的一个不是多数。 如果我们有三个节点而一个节点故障，那么我们有大多数，因此，这是最低要求。ZooKeeper集合在实际生产环境中必须至少有三个节点。 如果我们有四个节点而两个节点故障，它将再次故障。类似于有三个节点，额外节点不用于任何目的，因此，最好添加奇数的节点，例如3，5，7。 我们知道写入过程比ZooKeeper集合中的读取过程要贵，因为所有节点都需要在数据库中写入相同的数据。因此，对于平衡的环境拥有较少数量（例如3，5，7）的节点比拥有大量的节点要好。 下图描述了ZooKeeper工作流，后面的表说明了它的不同组件。 组件 描述 写入（write） 写入过程由leader节点处理。leader将写入请求转发到所有znode，并等待znode的回复。如果一半的znode回复，则写入过程完成。 读取（read） 读取由特定连接的znode在内部执行，因此不需要与集群进行交互。 复制数据库（replicated database） 它用于在zookeeper中存储数据。每个znode都有自己的数据库，每个znode在一致性的帮助下每次都有相同的数据。 Leader Leader是负责处理写入请求的Znode。 Follower follower从客户端接收写入请求，并将它们转发到leader znode。 请求处理器（request processor） 只存在于leader节点。它管理来自follower节点的写入请求。 原子广播（atomic broadcasts） 负责广播从leader节点到follower节点的变化。 leader选举选取一些概念服务器状态服务器具有四种状态 LOOKING：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入Leader选举状态。 FOLLOWING：跟随者状态。表明当前服务器角色是Follower。 LEADING：领导者状态。表明当前服务器角色是Leader。 OBSERVING：观察者状态。表明当前服务器角色是Observer。 投票数据结构每个投票中包含了两个最基本的信息，所推举服务器的SID和ZXID，投票（Vote）在Zookeeper中包含字段如下 id：被推举的Leader的SID。 zxid：被推举的Leader事务ID。 electionEpoch：逻辑时钟，用来判断多个投票是否在同一轮选举周期中，该值在服务端是一个自增序列，每次进入新一轮的投票后，都会对该值进行加1操作。 peerEpoch：被推举的Leader的epoch。 state：当前服务器的状态。 QuorumCnxManager：网络I/O每台服务器在启动的过程中，会启动一个QuorumPeerManager，负责各台服务器之间的底层Leader选举过程中的网络通信。 消息队列。QuorumCnxManager内部维护了一系列的队列，用来保存接收到的、待发送的消息以及消息的发送器，除接收队列以外，其他队列都按照SID分组形成队列集合，如一个集群中除了自身还有3台机器，那么就会为这3台机器分别创建一个发送队列，互不干扰。 recvQueue：消息接收队列，用于存放那些从其他服务器接收到的消息。 queueSendMap：消息发送队列，用于保存那些待发送的消息，按照SID进行分组。 senderWorkerMap：发送器集合，每个SenderWorker消息发送器，都对应一台远程Zookeeper服务器，负责消息的发送，也按照SID进行分组。 lastMessageSent：最近发送过的消息，为每个SID保留最近发送过的一个消息。 建立连接。为了能够相互投票，Zookeeper集群中的所有机器都需要两两建立起网络连接。QuorumCnxManager在启动时会创建一个ServerSocket来监听Leader选举的通信端口(默认为3888)。开启监听后，Zookeeper能够不断地接收到来自其他服务器的创建连接请求，在接收到其他服务器的TCP连接请求时，会进行处理。为了避免两台机器之间重复地创建TCP连接，Zookeeper只允许SID大的服务器主动和其他机器建立连接，否则断开连接。在接收到创建连接请求后，服务器通过对比自己和远程服务器的SID值来判断是否接收连接请求，如果当前服务器发现自己的SID更大，那么会断开当前连接，然后自己主动和远程服务器建立连接。一旦连接建立，就会根据远程服务器的SID来创建相应的消息发送器SendWorker和消息接收器RecvWorker，并启动。 消息接收与发送。消息接收：由消息接收器RecvWorker负责，由于Zookeeper为每个远程服务器都分配一个单独的RecvWorker，因此，每个RecvWorker只需要不断地从这个TCP连接中读取消息，并将其保存到recvQueue队列中。消息发送：由于Zookeeper为每个远程服务器都分配一个单独的SendWorker，因此，每个SendWorker只需要不断地从对应的消息发送队列中获取出一个消息发送即可，同时将这个消息放入lastMessageSent中。在SendWorker中，一旦Zookeeper发现针对当前服务器的消息发送队列为空，那么此时需要从lastMessageSent中取出一个最近发送过的消息来进行再次发送，这是为了解决接收方在消息接收前或者接收到消息后服务器挂了，导致消息尚未被正确处理。同时，Zookeeper能够保证接收方在处理消息时，会对重复消息进行正确的处理。 服务器启动时期的Leader选举若进行Leader选举，则至少需要两台机器，这里选取3台机器组成的服务器集群为例。在集群初始化阶段，当有一台服务器Server1启动时，其单独无法进行和完成Leader选举，当第二台服务器Server2启动时，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。选举过程如下 每个Server发出一个投票。由于是初始情况，Server1和Server2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时Server1的投票为(1, 0)，Server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下 优先检查ZXID。ZXID比较大的服务器优先作为Leader。 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。 对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时Server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，对于Server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING 服务器运行时期的Leader选举在Zookeeper运行期间，Leader与非Leader服务器各司其职，即便当有非Leader服务器宕机或新加入，此时也不会影响Leader，但是一旦Leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮Leader选举，其过程和启动时期的Leader选举过程基本一致。假设正在运行的有Server1、Server2、Server3三台服务器，当前Leader是Server2，若某一时刻Leader挂了，此时便开始Leader选举。选举过程如下 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定Server1的ZXID为123，Server3的ZXID为122；在第一轮投票中，Server1和Server3都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。 接收来自各个服务器的投票。与启动时过程相同。 处理投票。与启动时过程相同，此时，Server1将会成为Leader。 统计投票。与启动时过程相同。 改变服务器的状态。与启动时过程相同。 投票比对规则使用ZXID来和别人的ZXID比对 自己的ZXID大于别人的ZXID, 坚持自己的投票，不做任何变更 小于别人的ZXID, 认可当前收到的投票，并再次将该投票发送出去 等于, 这里就需要比对myid 使用myid来和别人的myid比对 自己的myid大于别人的myid, 坚持自己的投票，不做任何变更 小于别人的myid, 认可当前收到的投票，并再次将该投票发送出去 等于, 坚持自己的投票，不做任何变更 使用zkCli使用 1234567891011121314151617181920212223242526272829303132333435//查看帮助help//查看/目录ls ///获取节点状态stat /zookeeper//获取节点数据内容get /zookeeper//创建节点create [-s] [-e] path data acl, -s:顺序节点, -e:顺序节点 create /app test//修改数据节点, 如果指定版本, 需要和当前版本一致set path data [version]//删除指定路径的节点 如果有子节点要先删除子节点delete path [version]//删除当前路径节点及其所有子节点rmr path//设置节点配额,比如限制节点数据长度，限制节点中子节点个数//-n 是限制子节点个数 -b是限制节点数据长度//超出配额后,ZooKeeper不会报错,而是在日志信息中记录. tail zookeeper.outsetquota -n|-b val path //查看路径节点的配额信息listquota path //删除节点路径的配额信息delquota [-n|-b] path Zookeeper类使用 123456789101112131415161718//构造public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher) throws IOException { this(connectString, sessionTimeout, watcher, false);}//主要方法create(path, data, flags: 指定znode类型)delete(path, version)exists(path, watch)getData(path, watch)setData(path, data, version)getChildren(path, watch)sync(path)//把客户端session连接节点和leader节点同步//所有读取znode数据的api都可以设置一个watch//所有更新znode数据都可以设置version或者不设置//所有方法都有同步和异步两个版本, 同步等待zk响应,异步把请求放入客户端请求队列, 直接返回. 通过callback接受之后的响应 参考: http://www.cnblogs.com/leesf456/p/6107600.html https://blog.xiaohansong.com/zab.html W3Cschool - Zookeeper教程 视频教程 ZAB/Paxos介绍","link":"/blog/2018/02/07/zookeeper-1.%E5%8E%9F%E7%90%86/"},{"title":"分布式事务Txlcn","text":"简介LCN框架(详情请看官网)是一个分布式事务的解决方案, 他的定义是LCN并不生产事务，LCN只是本地事务的协调工 TX-LCN定位于一款事务协调性框架，框架其本身并不操作事务，而是基于对事务的协调从而达到事务一致性的效果。 原理TX-LCN由两大模块组成, TxClient、TxManager，TxClient作为模块的依赖框架，提供TX-LCN的标准支持，TxManager作为分布式事务的控制放。事务发起方或者参与反都由TxClient端来控制。 核心步骤 创建事务组是指在事务发起方开始执行业务代码之前先调用TxManager创建事务组对象，然后拿到事务标示GroupId的过程。 加入事务组添加事务组是指参与方在执行完业务方法以后，将该模块的事务信息通知给TxManager的操作。 通知事务组是指在发起方执行完业务代码以后，将发起方执行结果状态通知给TxManager,TxManager将根据事务最终状态和事务组的信息来通知相应的参与模块提交或回滚事务，并返回结果给事务发起方。 模式LCN模式LCN模式是通过代理Connection的方式实现对本地事务的操作，然后在由TxManager统一协调控制事务。当本地事务提交回滚或者关闭连接时将会执行假操作，该代理的连接将由LCN连接池管理。 特点: 该模式对代码的嵌入性为低。 该模式仅限于本地存在连接对象且可通过连接对象控制事务的模块。 该模式下的事务提交与回滚是由本地事务方控制，对于数据一致性上有较高的保障。 该模式缺陷在于代理的连接需要随事务发起方一共释放连接，增加了连接占用的时间。 TCC模式TCC事务机制相对于传统事务机制（X/Open XA Two-Phase-Commit），其特征在于它不依赖资源管理器(RM)对XA的支持，而是通过对（由业务系统提供的）业务逻辑的调度来实现分布式事务。主要由三步操作，Try: 尝试执行业务、 Confirm:确认执行业务、 Cancel: 取消执行业务。 特点: 该模式对代码的嵌入性高，要求每个业务需要写三种步骤的操作。 该模式对有无本地事务控制都可以支持使用面广。 数据一致性控制几乎完全由开发者控制，对业务开发难度要求高。 TXC模式TXC模式命名来源于淘宝，实现原理是在执行SQL之前，先查询SQL的影响数据，然后保存执行的SQL快走信息和创建锁。当需要回滚的时候就采用这些记录数据回滚数据库，目前锁实现依赖redis分布式锁控制。 特点: 该模式同样对代码的嵌入性低。 该模式仅限于对支持SQL方式的模块支持。 该模式由于每次执行SQL之前需要先查询影响数据，因此相比LCN模式消耗资源与时间要多。 该模式不会占用数据库的连接资源。 如果调用服务存储结构不一样，mysql端用lcn，redis/mongodb用tcc 栗子(SpringCloud)搭建环境consul下载https://www.consul.io/downloads.html, 这边是windows, cmd直接到所在目录consul agent -dev启动. mysql1234567891011121314create database `tx-manager`;CREATE TABLE `t_tx_exception` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `group_id` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `unit_id` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `mod_id` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `transaction_state` tinyint(4) NULL DEFAULT NULL, `registrar` tinyint(4) NULL DEFAULT NULL, `remark` varchar(4096) NULL DEFAULT NULL, `ex_state` tinyint(4) NULL DEFAULT NULL COMMENT '0 未解决 1已解决', `create_time` datetime(0) NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; tx-manager模块注意: mysql,mybatis,Spring等依赖全部忽略,只写txlcn依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.codingapi.txlcn&lt;/groupId&gt; &lt;artifactId&gt;txlcn-tm&lt;/artifactId&gt;&lt;/dependency&gt; Application启动类上添加@EnableTransactionManagerServer注解 配置文件下文会给出,端口为7970 开始这边我们事务是ServerA - ServerB - ServerC ServerA这边每个服务都是在demo表中插入一条数据, 要不全部成功, 要不全部失败 这边用的是LcnTransaction 这里的serivce类中的方法是 123456789101112131415161718192021222324252627282930@LcnTransaction@Transactional@Overridepublic String execute(String value, String exFlag) { // step1. call remote ServiceD // String dResp = serviceBClient.rpc(value); //调用ServiceB服务 String dResp = restTemplate.getForObject(&quot;http://127.0.0.1:12002/rpc?value=&quot; + value, String.class); // step2. call remote ServiceE // String eResp = serviceCClient.rpc(value); //调用ServiceC服务 String eResp = restTemplate.getForObject(&quot;http://127.0.0.1:12003/rpc?value=&quot; + value, String.class); // step3. execute local transaction Demo demo = new Demo(); demo.setGroupId(TracingContext.tracing().groupId()); demo.setDemoField(value); demo.setCreateTime(new Date()); demo.setAppName(Transactions.getApplicationId()); demoMapper.save(demo); // 置异常标志，DTX 回滚 出现异常就回滚, 这里如果传递exFlag进来, 就直接自己抛出一个异常 if (Objects.nonNull(exFlag)) { throw new IllegalStateException(&quot;by exFlag&quot;); } return dResp + &quot; &gt; &quot; + eResp + &quot; &gt; &quot; + &quot;ok-service-a&quot;;} 这里配置一定要配置tx-lcn.client.manager-address=127.0.0.1:8070, 之后会给出全部配置 ServerB这边用的是TxcTransaction 1234567891011121314@Override@TxcTransaction(propagation = DTXPropagation.SUPPORTS)@Transactionalpublic String rpc(String value) { Demo demo = new Demo(); demo.setGroupId(TracingContext.tracing().groupId()); demo.setDemoField(value); demo.setAppName(Transactions.getApplicationId()); demo.setCreateTime(new Date()); demoMapper.save(demo); return &quot;ok-service-b&quot;;} 配置一定要添加tx-lcn.client.manager-address=127.0.0.1:8070 ServerC这边用的是TccTransaction 12345678910111213141516171819202122232425262728293031@Override@TccTransaction(executeClass = DemoServiceImpl.class, confirmMethod = &quot;confirmRpc&quot;, cancelMethod = &quot;cancelRpc&quot;, propagation = DTXPropagation.SUPPORTS)@Transactionalpublic String rpc(String value) { Demo demo = new Demo(); demo.setDemoField(value); demo.setCreateTime(new Date()); demo.setAppName(Transactions.getApplicationId()); demo.setGroupId(TracingContext.tracing().groupId()); demoMapper.save(demo); ids.putIfAbsent(TracingContext.tracing().groupId(), Sets.newHashSet(demo.getId())); ids.get(TracingContext.tracing().groupId()).add(demo.getId()); return &quot;ok-service-c&quot;;}public void confirmRpc(String value) { ids.get(TracingContext.tracing().groupId()).forEach(id -&gt; { log.info(&quot;tcc-confirm-{}-{}&quot; + TracingContext.tracing().groupId(), id); ids.get(TracingContext.tracing().groupId()).remove(id); });}public void cancelRpc(String value) { ids.get(TracingContext.tracing().groupId()).forEach(id -&gt; { log.info(&quot;tcc-cancel-{}-{}&quot;, TracingContext.tracing().groupId(), id); demoMapper.deleteByKId(id); });} 配置一定要添加tx-lcn.client.manager-address=127.0.0.1:8070 每个Client都需要添加pom 1234&lt;dependency&gt; &lt;groupId&gt;com.codingapi.txlcn&lt;/groupId&gt; &lt;artifactId&gt;txlcn-tc&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件TC配置application.properties123456789101112131415161718192021222324252627282930313233343536# 是否启动LCN负载均衡策略(优化选项，开启与否，功能不受影响)tx-lcn.ribbon.loadbalancer.dtx.enabled=true# tx-manager 的配置地址，可以指定TM集群中的任何一个或多个地址# tx-manager 下集群策略，每个TC都会从始至终&lt;断线重连&gt;与TM集群保持集群大小个连接。# TM方，每有TM进入集群，会找到所有TC并通知其与新TM建立连接。# TC方，启动时按配置与集群建立连接，成功后，会再与集群协商，查询集群大小并保持与所有TM的连接tx-lcn.client.manager-address=127.0.0.1:8070# 该参数是分布式事务框架存储的业务切面信息。采用的是h2数据库。绝对路径。该参数默认的值为{user.dir}/.txlcn/{application.name}-{application.port}tx-lcn.aspect.log.file-path=logs/.txlcn/demo-8080# 调用链长度等级，默认值为3（优化选项。系统中每个请求大致调用链平均长度，估算值。）tx-lcn.client.chain-level=3# 该参数为tc与tm通讯时的最大超时时间，单位ms。该参数不需要配置会在连接初始化时由tm返回。tx-lcn.client.tm-rpc-timeout=2000# 该参数为分布式事务的最大时间，单位ms。该参数不允许TC方配置，会在连接初始化时由tm返回。tx-lcn.client.dtx-time=8000# 该参数为雪花算法的机器编号，所有TC不能相同。该参数不允许配置，会在连接初始化时由tm返回。tx-lcn.client.machine-id=1# 该参数为事务方法注解切面的orderNumber，默认值为0.tx-lcn.client.dtx-aspect-order=0# 该参数为事务连接资源方法切面的orderNumber，默认值为0.tx-lcn.client.resource-order=0# 是否开启日志记录。当开启以后需要配置对应logger的数据库连接配置信息。tx-lcn.logger.enabled=falsetx-lcn.logger.driver-class-name=${spring.datasource.driver-class-name}tx-lcn.logger.jdbc-url=${spring.datasource.url}tx-lcn.logger.username=${spring.datasource.username}tx-lcn.logger.password=${spring.datasource.password} 特别配置 微服务集群且用到 LCN事务模式时，为保证性能请开启TX-LCN重写的负载策略 **tx-lcn.springcloud.loadbalance.enabled**=true 关闭业务RPC重试 12# 关闭Ribbon的重试机制ribbon.MaxAutoRetriesNextServer=0 1、TxClient所有配置均有默认配置，请按需覆盖默认配置。2、为什么要关闭服务调用的重试。远程业务调用失败有两种可能： （1），远程业务执行失败 （2）、远程业务执行成功，网络失败。对于第2种，事务场景下重试会发生，某个业务执行两次的问题。 如果业务上控制某个事务接口的幂等，则不用关闭重试。 通过AOP配置本地事务与分布式事务 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration@EnableTransactionManagementpublic class TransactionConfiguration { /** * 本地事务配置 * @param transactionManager * @return */ @Bean @ConditionalOnMissingBean public TransactionInterceptor transactionInterceptor(PlatformTransactionManager transactionManager) { Properties properties = new Properties(); properties.setProperty(&quot;*&quot;, &quot;PROPAGATION_REQUIRED,-Throwable&quot;); TransactionInterceptor transactionInterceptor = new TransactionInterceptor(); transactionInterceptor.setTransactionManager(transactionManager); transactionInterceptor.setTransactionAttributes(properties); return transactionInterceptor; } /** * 分布式事务配置 设置为LCN模式 * @param dtxLogicWeaver * @return */ @ConditionalOnBean(DTXLogicWeaver.class) @Bean public TxLcnInterceptor txLcnInterceptor(DTXLogicWeaver dtxLogicWeaver) { TxLcnInterceptor txLcnInterceptor = new TxLcnInterceptor(dtxLogicWeaver); Properties properties = new Properties(); properties.setProperty(Transactions.DTX_TYPE,Transactions.LCN); properties.setProperty(Transactions.DTX_PROPAGATION, &quot;REQUIRED&quot;); txLcnInterceptor.setTransactionAttributes(properties); return txLcnInterceptor; } @Bean public BeanNameAutoProxyCreator beanNameAutoProxyCreator() { BeanNameAutoProxyCreator beanNameAutoProxyCreator = new BeanNameAutoProxyCreator(); //需要调整优先级，分布式事务在前，本地事务在后。 beanNameAutoProxyCreator.setInterceptorNames(&quot;txLcnInterceptor&quot;,&quot;transactionInterceptor&quot;); beanNameAutoProxyCreator.setBeanNames(&quot;*Impl&quot;); return beanNameAutoProxyCreator; }} TXC模式定义表的实际主键 TXC 是基于逆向sql的方式实现对业务的回滚控制，在逆向sql操作数据是会检索对应记录的主键作为条件处理回滚业务。但是在有些情况下可能表中并没有主键字段(primary key)，仅存在业务上的名义主键，此时可通过重写PrimaryKeysProvider方式定义表对应的主键关系。 123456789@Componentpublic class MysqlPrimaryKeysProvider implements PrimaryKeysProvider { @Override public Map&lt;String, List&lt;String&gt;&gt; provide() { //t_demo 表的回滚主键为 kid字段 return Maps.newHashMap(&quot;t_demo&quot;, Collections.singletonList(&quot;kid&quot;)); }} TC模块标识策略 TC模块在负载时，TM为了区分具体模块，会要求TC注册时提供唯一标识。默认策略是，应用名称加端口方式标识。也可以自定义，自定义需要保证各个模块标识不能重复。 12345678@Componentpublic class MyModIdProvider implements ModIdProvider { @Override public String modId() { return ip + port; }} TM配置application.properties1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162spring.application.name=TransactionManagerserver.port=7970# JDBC 数据库配置spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://127.0.0.1:3306/tx-manager?characterEncoding=UTF-8spring.datasource.username=rootspring.datasource.password=123456# 数据库方言spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialect# 第一次运行可以设置为: create, 为TM创建持久化数据库表spring.jpa.hibernate.ddl-auto=validate# TM监听IP. 默认为 127.0.0.1tx-lcn.manager.host=127.0.0.1# TM监听Socket端口. 默认为 ${server.port} - 100tx-lcn.manager.port=8070# 心跳检测时间(ms). 默认为 300000tx-lcn.manager.heart-time=300000# 分布式事务执行总时间(ms). 默认为36000tx-lcn.manager.dtx-time=8000# 参数延迟删除时间单位ms 默认为dtx-time值tx-lcn.message.netty.attr-delay-time=${tx-lcn.manager.dtx-time}# 事务处理并发等级. 默认为机器逻辑核心数5倍tx-lcn.manager.concurrent-level=160# TM后台登陆密码，默认值为codingapitx-lcn.manager.admin-key=codingapi# 分布式事务锁超时时间 默认为-1，当-1时会用tx-lcn.manager.dtx-time的时间tx-lcn.manager.dtx-lock-time=${tx-lcn.manager.dtx-time}# 雪花算法的sequence位长度，默认为12位.tx-lcn.manager.seq-len=12# 异常回调开关。开启时请制定ex-urltx-lcn.manager.ex-url-enabled=false# 事务异常通知（任何http协议地址。未指定协议时，为TM提供内置功能接口）。默认是邮件通知tx-lcn.manager.ex-url=/provider/email-to/***@**.com# 开启日志,默认为falsetx-lcn.logger.enabled=truetx-lcn.logger.enabled=falsetx-lcn.logger.driver-class-name=${spring.datasource.driver-class-name}tx-lcn.logger.jdbc-url=${spring.datasource.url}tx-lcn.logger.username=${spring.datasource.username}tx-lcn.logger.password=${spring.datasource.password}# redis 的设置信息. 线上请用Redis Clusterspring.redis.host=127.0.0.1spring.redis.port=6379spring.redis.password= 1注意（NOTE） (1) TxManager所有配置均有默认配置，请按需覆盖默认配置。 (2) 特别注意 TxManager进程会监听两个端口号，一个为TxManager端口，另一个是事务消息端口。TxClient默认连接事务消息端口是8070， 所以，为保证TX-LCN基于默认配置运行良好，请设置TxManager端口号为8069 或者指定事务消息端口为8070 (3) 分布式事务执行总时间 a 与 TxClient通讯最大等待时间 b、TxManager通讯最大等待时间 c、微服务间通讯时间 d、微服务调用链长度 e 几个时间存在着依赖关系。 a &gt;= 2c + (b + c + d) * (e - 1), 特别地，b、c、d 一致时，a &gt;= (3e-1)b。你也可以在此理论上适当在减小a的值，发生异常时能更快得到自动补偿，即 a &gt;= (3e-1)b - Δ（原因）。 最后，调用链小于等于3时，将基于默认配置运行良好 (4) 若用tx-lcn.manager.ex-url=/provider/email-to/xxx@xx.xxx 这个配置，配置管理员邮箱信息(如QQ邮箱)： 1234spring.mail.host=smtp.qq.comspring.mail.port=587spring.mail.username=xxxxx@**.comspring.mail.password=*********","link":"/blog/2019/03/30/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1Txlcn/"},{"title":"ReentrantLock源码解析","text":"123456789# 整体结构- ReentrantLock：存在三个内部类 - FairSync - NonfairSync - Sync - AbstractQueuedSynchronizer - AbstractOwnableSynchronizer：只有一个transient Thread，这个线程表示当前持有锁线程 主要子类NonfairSync和FairSync他们分别重写了lock和tryAcquire方法 1234567891011# NonfairSync1. lock方法：一进来先CAS，如果竞争到锁直接set当前线程到AOS。否则acquire(1)2. tryAcquire方法：调用了Sync#nonfairTryAcquire - 思路：如果state==0&amp;&amp;CAS尝试获取锁可以拿到，直接标识返回true；如果state!=0&amp;&amp;获取锁的线程就是现在线程表示重入，state+1返回true；其他情况返回false# FairSync1. lock方法：直接acquire(1)2. tryAcquire方法： - 思路：如果state==0&amp;&amp;[等待队列没有线程]&amp;&amp;CAS尝试获取锁可以拿到，直接标识返回true；如果state!=0&amp;&amp;获取锁的线程就是现在线程表示重入，state+1返回true；其他情况返回false 12345678910111213141516171819202122232425262728293031323334353637383940前文：Node为双向链表的节点，成员变量：1. int waitStatus：等待状态 - -1表示此节点后面存在等待node - 0表示初始化状态 - 1表示取消了等待的node，比如等待超时2. Node prev：前一个3. Node next：下一个4. Thread thread：node的线程5. Node nextWaiter：下一个等待的node节点注意：阻塞队列不包含head节点，head一般指的是占有锁的线程# 加锁操作acquire(1)public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();}1. tryAcquire如果获取到了锁返回true，那么取反为false就不会往下走了addWaiter就是加入到阻塞队列中1. 如果tail不是空，尝试CAS快速加队；成功直接返回入队成功的node2. 否则调用enq自旋入队；3. 如果tail是空，就初始化head，这时候head和tail都是new Node(). 4. 然后tail肯定不为空了，CAS插入到最后；成功直接返回入队成功的node 加入了队列之后acquireQueued(入队成功的node, 1)1. 自旋2. 获取入队成功的node的prev节点，如果prev==head &amp;&amp; tryAcquire(arg)表示当前节点就是队列第一个节点并且成功获取到锁了。就将当前的节点设置为head，返回false结束3. shouldParkAfterFailedAcquire设置前驱等待状态。判断当前节点的prev是否为-1（表示等待），前驱都等待了肯定自己直接排队等待；如果前驱&gt;0（其实就是1取消状态），把每一个取消的移除；如果前驱=0，设置为-1；只有第一种为-1才会返回true，才会执行下面4. parkAndCheckInterrupt挂起线程，使用`LockSupport.park(this)`，然后就停在这里了，等待被唤醒# 解锁操作release(1)1. 判断state==0，设置AOS中线程为null；不为0就减一2. 最后操作state设置为0，移除node节点，LockSupport.unpark(s.thread)唤醒 总结： 使用LockSupport来挂起和释放线程 加锁先用addWaiter加入队列，如果没有head就初始化head，把节点放入最后面。如果当前节点是第一个节点又会尝试获取一下锁，如果还是失败调用acquireQueued。 acquireQueued先会前驱等待状态，为1移除；为0就设置为-1；如果前驱为-1表示前驱都在等待了，自己就直接挂起。调用parkAndCheckInterrupt使用LockSupport.park(this)挂起 摘自https://javadoop.com/post/AbstractQueuedSynchronizer 123456789101112131415// 头结点，你直接把它当做 当前持有锁的线程 可能是最好理解的private transient volatile Node head;// 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个链表private transient volatile Node tail;// 这个是最重要的，代表当前锁的状态，0代表没有被占用，大于 0 代表有线程持有当前锁// 这个值可以大于 1，是因为锁可以重入，每次重入都加上 1private volatile int state;// 代表当前持有独占锁的线程，举个最重要的使用例子，因为锁可以重入// reentrantLock.lock()可以嵌套调用多次，所以每次用这个来判断当前线程是否已经拥有了锁// if (currentThread == getExclusiveOwnerThread()) {state++}private transient Thread exclusiveOwnerThread; //继承自AbstractOwnableSynchronizer 12345678910111213141516171819202122232425262728293031323334353637static final class Node { // 标识节点当前在共享模式下 static final Node SHARED = new Node(); // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 代码此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 本文不分析condition，所以略过吧，下一篇文章会介绍这个 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ // 同样的不分析，略过吧 static final int PROPAGATE = -3; // ===================================================== // 取值为上面的1、-1、-2、-3，或者0(以后会讲到) // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // ps: 半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程本尊 volatile Thread thread;} 下面，我们开始说 ReentrantLock 的公平锁。再次强调，我说的阻塞队列不包含 head 节点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; // 争锁 final void lock() { acquire(1); } // 来自父类AQS，我直接贴过来这边，下面分析的时候同样会这样做，不会给读者带来阅读压力 // 我们看到，这个方法，如果tryAcquire(arg) 返回true, 也就结束了。 // 否则，acquireQueued方法会将线程压到队列中 public final void acquire(int arg) { // 此时 arg == 1 // 首先调用tryAcquire(1)一下，名字上就知道，这个只是试一试 // 因为有可能直接就成功了呢，也就不需要进队列排队了， // 对于公平锁的语义就是：本来就没人持有锁，根本没必要进队列等待(又是挂起，又是等待被唤醒的) if (!tryAcquire(arg) &amp;&amp; // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) { selfInterrupt(); } } /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ // 尝试直接获取锁，返回值是boolean，代表是否获取到锁 // 返回true：1.没有线程在等待锁；2.重入锁，线程本来就持有锁，也就可以理所当然可以直接获取 protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // state == 0 此时此刻没有线程持有锁 if (c == 0) { // 虽然此时此刻锁是可以用的，但是这是公平锁，既然是公平，就得讲究先来后到， // 看看有没有别人在队列中等了半天了 if (!hasQueuedPredecessors() &amp;&amp; // 如果没有线程在等待，那就用CAS尝试一下，成功了就获取到锁了， // 不成功的话，只能说明一个问题，就在刚刚几乎同一时刻有个线程抢先了 =_= // 因为刚刚还没人的，我判断过了 compareAndSetState(0, acquires)) { // 到这里就是获取到锁了，标记一下，告诉大家，现在是我占用了锁 setExclusiveOwnerThread(current); return true; } } // 会进入这个else if分支，说明是重入了，需要操作：state=state+1 // 这里不存在并发问题 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } // 如果到这里，说明前面的if和else if都没有返回true，说明没有获取到锁 // 回到上面一个外层调用方法继续看: // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); return false; } // 假设tryAcquire(arg) 返回false，那么代码将执行： // acquireQueued(addWaiter(Node.EXCLUSIVE), arg)， // 这个方法，首先需要执行：addWaiter(Node.EXCLUSIVE) /** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ // 此方法的作用是把线程包装成node，同时进入到队列中 // 参数mode此时是Node.EXCLUSIVE，代表独占模式 private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后 Node pred = tail; // tail!=null =&gt; 队列不为空(tail==head的时候，其实队列是空的，不过不管这个吧) if (pred != null) { // 将当前的队尾节点，设置为自己的前驱 node.prev = pred; // 用CAS把自己设置为队尾, 如果成功后，tail == node 了，这个节点成为阻塞队列新的尾巴 if (compareAndSetTail(pred, node)) { // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连， // 上面已经有 node.prev = pred，加上下面这句，也就实现了和之前的尾节点双向连接了 pred.next = node; // 线程入队了，可以返回了 return node; } } // 仔细看看上面的代码，如果会到这里， // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队) // 读者一定要跟上思路，如果没有跟上，建议先不要往下读了，往回仔细看，否则会浪费时间的 enq(node); return node; } /** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */ // 采用自旋的方式入队 // 之前说过，到这个方法只有两种可能：等待队列为空，或者有线程竞争入队， // 自旋在这边的语义是：CAS设置tail过程中，竞争一次竞争不到，我就多次竞争，总会排到的 private Node enq(final Node node) { for (;;) { Node t = tail; // 之前说过，队列为空也会进来这里 if (t == null) { // Must initialize // 初始化head节点 // 细心的读者会知道原来 head 和 tail 初始化的时候都是 null 的 // 还是一步CAS，你懂的，现在可能是很多线程同时进来呢 if (compareAndSetHead(new Node())) // 给后面用：这个时候head节点的waitStatus==0, 看new Node()构造方法就知道了 // 这个时候有了head，但是tail还是null，设置一下， // 把tail指向head，放心，马上就有线程要来了，到时候tail就要被抢了 // 注意：这里只是设置了tail=head，这里可没return哦，没有return，没有return // 所以，设置完了以后，继续for循环，下次就到下面的else分支了 tail = head; } else { // 下面几行，和上一个方法 addWaiter 是一样的， // 只是这个套在无限循环里，反正就是将当前线程排到队尾，有线程竞争的话排不上重复排 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } // 现在，又回到这段代码了 // if (!tryAcquire(arg) // &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); // 下面这个方法，参数node，经过addWaiter(Node.EXCLUSIVE)，此时已经进入阻塞队列 // 注意一下：如果acquireQueued(addWaiter(Node.EXCLUSIVE), arg))返回true的话， // 意味着上面这段代码将进入selfInterrupt()，所以正常情况下，下面应该返回false // 这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列 // 所以当前节点可以去试抢一下锁 // 这里我们说一下，为什么可以去试试： // 首先，它是队头，这个是第一个条件，其次，当前的head有可能是刚刚初始化的node， // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程 // 也就是说，当前的head不属于任何一个线程，所以作为队头，可以去试一试， // tryAcquire已经分析过了, 忘记了请往前看一下，就是简单用CAS试操作一下state if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 到这里，说明上面的if分支没有成功，要么当前node本来就不是队头， // 要么就是tryAcquire(arg)没有抢赢别人，继续往下看 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { // 什么时候 failed 会为 true??? // tryAcquire() 方法抛异常的情况 if (failed) cancelAcquire(node); } } /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */ // 刚刚说过，会到这里就是没有抢到锁呗，这个方法说的是：&quot;当前线程没有抢到锁，是否需要挂起当前线程？&quot; // 第一个参数是前驱节点，第二个参数才是代表当前线程的节点 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点 waitStatus大于0 ，之前说过，大于0 说明前驱节点取消了排队。 // 这里需要知道这点：进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。 // 所以下面这块代码说的是将当前节点的prev指向waitStatus&lt;=0的节点， // 简单说，就是为了找个好爹，因为你还得依赖它来唤醒呢，如果前驱节点取消了排队， // 找前驱节点的前驱节点做爹，往前遍历总能找到一个好爹的 if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 仔细想想，如果进入到这个分支意味着什么 // 前驱节点的waitStatus不等于-1和1，那也就是只可能是0，-2，-3 // 在我们前面的源码中，都没有看到有设置waitStatus的，所以每个新的node入队时，waitStatu都是0 // 正常情况下，前驱节点是之前的 tail，那么它的 waitStatus 应该是 0 // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } // 这个方法返回 false，那么会再走一次 for 循序， // 然后再次进来此方法，此时会从第一个分支返回 true return false; } // private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) // 这个方法结束根据返回值我们简单分析下： // 如果返回true, 说明前驱节点的waitStatus==-1，是正常情况，那么当前线程需要被挂起，等待以后被唤醒 // 我们也说过，以后是被前驱节点唤醒，就等着前驱节点拿到锁，然后释放锁的时候叫你好了 // 如果返回false, 说明当前不需要被挂起，为什么呢？往后看 // 跳回到前面是这个方法 // if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // parkAndCheckInterrupt()) // interrupted = true; // 1. 如果shouldParkAfterFailedAcquire(p, node)返回true， // 那么需要执行parkAndCheckInterrupt(): // 这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的 // 这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒======= private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } // 2. 接下来说说如果shouldParkAfterFailedAcquire(p, node)返回false的情况 // 仔细看shouldParkAfterFailedAcquire(p, node)，我们可以发现，其实第一次进来的时候，一般都不会返回true的，原因很简单，前驱节点的waitStatus=-1是依赖于后继节点设置的。也就是说，我都还没给前驱设置-1呢，怎么可能是true呢，但是要看到，这个方法是套在循环里的，所以第二次进来的时候状态就是-1了。 // 解释下为什么shouldParkAfterFailedAcquire(p, node)返回false的时候不直接挂起线程： // =&gt; 是为了应对在经过这个方法后，node已经是head的直接后继节点了。剩下的读者自己想想吧。} 最后，就是还需要介绍下唤醒的动作了。我们知道，正常情况下，如果线程没获取到锁，线程会被 LockSupport.park(this); 挂起停止，等待被唤醒。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 唤醒的代码还是比较简单的，你如果上面加锁的都看懂了，下面都不需要看就知道怎么回事了public void unlock() { sync.release(1);}public final boolean release(int arg) { // 往后看吧 if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;}// 回到ReentrantLock看tryRelease方法protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 是否完全释放锁 boolean free = false; // 其实就是重入的问题，如果c==0，也就是说没有嵌套锁了，可以释放了，否则还不能释放掉 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;}/** * Wakes up node's successor, if one exists. * * @param node the node */// 唤醒后继节点// 从上面调用处知道，参数node是head头结点private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 如果head节点当前waitStatus&lt;0, 将其修改为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 下面的代码就是唤醒后继节点，但是有可能后继节点取消了等待（waitStatus==1） // 从队尾往前找，找到waitStatus&lt;=0的所有节点中排在最前面的 Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; // 从后往前找，仔细看代码，不必担心中间有节点取消(waitStatus==1)的情况 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) // 唤醒线程 LockSupport.unpark(s.thread);} 唤醒线程以后，被唤醒的线程将从以下代码中继续往前走： 123456private final boolean parkAndCheckInterrupt() { LockSupport.park(this); // 刚刚线程被挂起在这里了 return Thread.interrupted();}// 又回到这个方法了：acquireQueued(final Node node, int arg)，这个时候，node的前驱是head了","link":"/blog/2020/04/01/%E5%B9%B6%E5%8F%913.ReentrantLock/"},{"title":"RabbitMQ1","text":"RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。以前用于金融起家 消息队列作用 解耦：不同系统之前使用消息队列来通信 冗余：数据处理失败的时候保存在消息队列，重新处理 扩展性 削峰：突发流量可以持久化到消息队列中，慢慢处理 可恢复性：就算消息队列挂了，恢复后还是可以处理之前的数据 顺序保证：大部分消息中间件都支持一定程度的顺序性 缓冲 异步通信：不需要及时处理消息 rabbitMQ优点 可靠性：持久化，传输确认，发布确认等 灵活路由 扩展性：多个rabbitMQ可以组成一个集群，还可以动态扩展节点 高可用：可以在集群机器上设置镜像，部分节点出现问题队列依旧可用 多协议：支持原生AMQP协议，还支持STOMP，MQTT等多种 多语言客户端支持 管理界面 插件机制 高级消息队列协议即Advanced Message Queuing Protocol（AMQP）是面向消息中间件提供的开放的应用层协议，其设计目标是对于消息的排序、路由（包括点对点和订阅-发布）、保持可靠性、保证安全性 docker安装1234docker pull rabbitmq //(镜像未配有控制台)docker pull rabbitmq:management //(镜像配有控制台)docker run --name rabbitmq -d -p 15672:15672 -p 5672:5672 rabbitmq:management http://localhost:15672/ 默认用户名guest，guest 栗子一个消息一个消费者去消费 生产者 123456789101112131415161718192021222324252627public class Producer { private final static String QUEUE_NAME = &quot;queue_name&quot;; public static void main(String[] args) throws IOException, TimeoutException { //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;127.0.0.1&quot;);// factory.setUsername(&quot;guest&quot;);// factory.setUsername(&quot;guest&quot;); //创建连接 Connection connection = factory.newConnection(); //创建一个信道 Channel channel = connection.createChannel(); //声明一个对列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //发送消息到队列 for (int i = 0; i &lt; 100; i++) { String message = &quot;这是第&quot; + i + &quot;条消息了&quot;; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;)); } //关闭 channel.close(); connection.close(); }} 消费者A 12345678910111213141516171819202122232425262728293031323334353637383940public class ConsumerA { private final static String QUEUE_NAME = &quot;queue_name&quot;; public static void main(String[] argv) throws Exception { // 创建连接工厂 ConnectionFactory factory = new ConnectionFactory();// 设置RabbitMQ地址 factory.setHost(&quot;localhost&quot;);// 创建一个新的连接 Connection connection = factory.newConnection();// 创建一个频道 final Channel channel = connection.createChannel();// 声明要关注的队列, 参数2(durable)表示此队列不要持久化,如果rabbitMQ服务器挂了数据丢失 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 每次从队列中只能获取一个消息, 避免一次强占多个消息. 消费完才能再次获取消息 channel.basicQos(1);// DefaultConsumer类实现了Consumer接口，通过传入一个频道，告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery Consumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(java.lang.String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;);// System.out.println(&quot;A 收到消息:&quot; + message); try { Thread.sleep(1000); System.out.println(&quot;A 处理消息完毕:&quot; + message); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 消息处理完成确认 channel.basicAck(envelope.getDeliveryTag(), false); } } }; // 消息消费完成确认 channel.basicConsume(QUEUE_NAME, false, consumer); }} 在创建一个ConsumerB和消费者A一样, 启动生产者之后依次启动A B 运行ConsumerA和ConsumerB之后在启动Producer可以发现AB分别消费掉所有数据 原理 AMQP协议中的几个重要概念 Queue 是RabbitMQ的内部对象，用于存储消息。RabbitMQ中的消息只能存储在 Queue 中，消费者从 Queue 中获取消息并消费。 Exchange 生产者将消息发送到 Exchange，由 Exchange 根据一定的规则将消息路由到一个或多个 Queue 中（或者丢弃）。 Binding RabbitMQ中通过 Binding 将 Exchange 与 Queue 关联起来。 Binding key 在绑定（Binding） Exchange 与 Queue 的同时，一般会指定一个 binding key。 Routing key 生产者在将消息发送给 Exchange 的时候，一般会指定一个 routing key，来指定这个消息的路由规则。 Exchange 会根据 routing key 和 Exchange Type 以及 Binding key 的匹配情况来决定把消息路由到哪个 Queue。 Exchange Types RabbitMQ常用的Exchange Type有 fanout、 direct、 topic、 headers 这四种。 fanout 这种类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中，这时 Routing key 不起作用。 direct 这种类型的Exchange路由规则也很简单，它会把消息路由到那些 binding key 与 routing key完全匹配的Queue中。 topic 这种类型的Exchange的路由规则支持 binding key 和 routing key 的模糊匹配，会把消息路由到满足条件的Queue。 binding key 中可以存在两种特殊字符 *与 #，用于做模糊匹配，其中 * 用于匹配一个单词，# 用于匹配多个单词（可以是零个），单词以 .为分隔符。 headers 这种类型的Exchange不依赖于 routing key 与 binding key 的匹配规则来路由消息，而是根据发送的消息内容中的 headers 属性进行匹配。完全匹配才会发送, 而且性能很差, 一般不用 信道的作用就是减少TCP的数目, 使得一个TCP连接中多个信道, 就不用频繁建立或者销毁TPC连接了 使用使用自带的队列 123channel.exchangeDeclare(exchangeName, &quot;direct&quot;, true);String queueName = channel.queueDeclare().getQueue();channel.queueBind(queueName, exchangeName, routingKey); Channel.exchangeDeclare 参数123456String exchange, BuiltinExchangeType type, boolean durable, boolean autoDelete, boolean internal, Map&lt;String, Object&gt; arguments channel.exchangeDeclare() type : direct、fanout、topic durable : 服务器重启是否保留Exchange. 警告：仅设置此选项，不代表消息持久化。即不保证重启后消息还在 autoDelete : 已经没有消费者时,服务器是否可以删除该Exchange internal 是否内置,如果设置 为true,则表示是内置的交换器,客户端程序无法直接发送消息到这个交换器中,只能通过交换器路由到交换器的方式 arguments 如query chanel.basicQos() prefetchSize : 0 prefetchCount：会告诉RabbitMQ不要同时给一个消费者推送多于N个消息，即一旦有N个消息还没有ack，则该consumer将block掉，直到有消息ackglobal：true\\false 是否将上面设置应用于channel，简单点说，就是上面限制是channel级别的还是consumer级别 channel.basicPublish() routingKey：路由键，#匹配0个或多个单词，*匹配一个单词，在topic exchange做消息转发用 mandatory：true：如果exchange根据自身类型和消息routeKey无法找到一个符合条件的queue，那么会调用basic.return方法将消息返还给生产者。false：出现上述情形broker会直接将消息扔掉 immediate：true：如果exchange在将消息route到queue(s)时发现对应的queue上没有消费者，那么这条消息不会放入队列中。当与消息routeKey关联的所有queue(一个或多个)都没有消费者时，该消息会通过basic.return方法返还给生产者。 BasicProperties ：需要注意的是BasicProperties.deliveryMode，0:不持久化 1：持久化 这里指的是消息的持久化，配合channel(durable=true),queue(durable)可以实现，即使服务器宕机，消息仍然保留简单来说：mandatory标志告诉服务器至少将该消息route到一个队列中，否则将消息返还给生产者；immediate标志告诉服务器如果该消息关联的queue上有消费者，则马上将消息投递给它，如果所有queue都没有消费者，直接把消息返还给生产者，不用将消息入队列等待消费者了。 channel.basicAck() deliveryTag:该消息的index multiple：是否批量.true:将一次性ack所有小于deliveryTag的消息。 channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, true) deliveryTag:该消息的index multiple：是否批量.true:将一次性拒绝所有小于deliveryTag的消息。 requeue：被拒绝的是否重新入队列 channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false) deliveryTag:该消息的index requeue：被拒绝的是否重新入队列 channel.basicConsume(QUEUE_NAME, true, consumer) autoAck：是否自动ack，如果不自动ack，需要使用channel.ack、channel.nack、channel.basicReject 进行消息应答 chanel.exchangeBind() channel.queueBind(queueName, EXCHANGE_NAME, bindingKey);用于通过绑定bindingKey将queue到Exchange，之后便可以进行消息接收 channel.queueDeclare(QUEUE_NAME, false, false, false, null) durable：true、false true：在服务器重启时，能够存活 exclusive ：是否为当前连接的专用队列，在连接断开后，会自动删除该队列，生产环境中应该很少用到吧。 autodelete：当没有任何消费者使用时，自动删除该队列 channel.basicNack 与 channel.basicReject 的区别在于basicNack可以拒绝多条消息，而basicReject一次只能拒绝一条消息 Channel.queueDeclare 参数 queue: 队列名称 durable： 是否持久化, 队列的声明默认是存放到内存中的，如果rabbitmq重启会丢失，如果想重启之后还存在就要使队列持久化，保存到Erlang自带的Mnesia数据库中，当rabbitmq重启之后会读取该数据库 exclusive：是否排外的，有两个作用，一：当连接关闭时connection.close()该队列是否会自动删除；二：该队列是否是私有的private，如果不是排外的，可以使用两个消费者都访问同一个队列，没有任何问题，如果是排外的，会对当前队列加锁，其他通道channel是不能访问的，如果强制访问会报异常：com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=405, reply-text=RESOURCE_LOCKED - cannot obtain exclusive access to locked queue ‘queue_name’ in vhost ‘/‘, class-id=50, method-id=20)一般等于true的话用于一个队列只能有一个消费者来消费的场景 autoDelete：是否自动删除，当最后一个消费者断开连接之后队列是否自动被删除，可以通过RabbitMQ Management，查看某个队列的消费者数量，当consumers = 0时队列就会自动删除 arguments：队列中的消息什么时候会自动被删除？ Message TTL(x-message-ttl)：设置队列中的所有消息的生存周期(统一为整个队列的所有消息设置生命周期), 也可以在发布消息的时候单独为某个消息指定剩余生存时间,单位毫秒, 类似于redis中的ttl，生存时间到了，消息会被从队里中删除，注意是消息被删除, 而不是队列被删除, 特性Features=TTL, 单独为某条消息设置过期时间12AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties().builder().expiration(&quot;6000&quot;);``channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, properties.build(), message.getBytes(&quot;UTF-8&quot;)); Auto Expire(x-expires): 当队列在指定的时间没有被访问(consume, basicGet, queueDeclare…)就会被删除,Features=Exp Max Length(x-max-length): 限定队列的消息的最大值长度，超过指定长度将会把最早的几条删除掉， 类似于mongodb中的固定集合，例如保存最新的100条消息, Feature=Lim Max Length Bytes(x-max-length-bytes): 限定队列最大占用的空间大小， 一般受限于内存、磁盘的大小, Features=Lim B Dead letter exchange(x-dead-letter-exchange)： 当队列消息长度大于最大长度、或者过期的等，将从队列中删除的消息推送到指定的交换机中去而不是丢弃掉,Features=DLX Dead letter routing key(x-dead-letter-routing-key)：将删除的消息推送到指定交换机的指定路由键的队列中去, Feature=DLK Maximum priority(x-max-priority)：优先级队列，声明队列时先定义最大优先级值(定义最大值一般不要太大)，在发布消息的时候指定该消息的优先级， 优先级更高（数值更大的）的消息先被消费, Lazy mode(x-queue-mode=lazy)： Lazy Queues: 先将消息保存到磁盘上，不放在内存中，当消费者开始消费的时候才加载到内存中 Master locator(x-queue-master-locator) 绑定123Queue.BindOk queueBind(String queue, String exchange , String routingKey) throws IOException;Queue.BindOk queueBind(String queue, String exchange , String routingKey, Map&lt;String, Object&gt; arguments) throws IOException;void queueBindNoWait(String queue, String exchange, String routingKey, Map&lt;String, Object&gt; arguments) throws IOException; queue 队列名称 exchange 交换器的名称 routingKey 用来绑定队列和交换器的路由键 argument 定义绑定的一些参数 解绑是queueUnbind 持久化channel.queueDeclare(QUEUE_NAME, durable, false, false, arguments);这里设置durable为true, 设置了交换器和队列持久化 在发送消息的basicPublish时候设置BasicProperties 123设置消息持久化 AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties().builder();properties.deliveryMode(2); // 设置消息是否持久化，1： 非持久化 2：持久化 就算这样了, 还有一种情况导致消息丢失. 比如autoAck设置为true, 消费者受到消息后还没处理就直接宕机了, 也会丢失. 解决方式就是autoAck设置为false, 手动确认. 消息持久化比较影响性能, 不重要的可以不必要持久化. 持久化的消息还需要一段很短的时间才能存入磁盘中, 如果中途宕机也会导致消息丢失. 所以需要设置镜像队列. 过期查看arguments 属性 单条消息设置过期时间需要在发送的时候设置AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties().builder().expiration(1000 + &quot;&quot;); 消费RabbitMQ 的消费模式分两种: 推(Push)模式和拉(Pull)模式.推模式采用 Basic.Consume进行消费，而拉模式则是调用 Basic.Get 进行消费 push模式 在推模式中，可以通过持续订阅的方式来消费消息.接收消息一般通过实现 Consumer 接口或者继承 DefaultConsumer 类来实现 pull模式 通过channel.basicGet方法可以单条地获取消息，其返回值是 GetRespone 死信交换器DLX(Dead-Letter-Exchange)在队列中消息变成死信(消息被拒绝/消息过期/队列达到最大长度)之后, 死信交换器还可以把它发送到另一个交换器中. 可以利用TTL和DLX设计出延迟队列, 定义A队列设置延迟10s, 消费者订阅B队列(设置DLX). 这时候A队列过期之后消息就到B队列中了, 刚好就实现了10s的延迟处理 优先级队列界面中Pri标识展示.默认优先级为0, 越大越优先 12AMQP.BasicProperties.Builder builder= new AMQP.BasicProperties.Builder() ;builder.priority(5);//设置优先级为5 如果队列中没有消息堆积的话, 优先级也就没有意义了 注意 Connection可以建立多个Channel, 但是多线程共享一个Channel是不安全的 声明完全一致的交换机或者队列时, RabbitMQ会什么都不做并返回成功, 但是如果参数不一致直接报错 如果ack设置为true, 但是返回消费成功的消息, 这个消息就永远不会删除(不会过期). 除非消费端断开连接了, 这个消息将重新发送 重复消费 消费者消费成功之后发送ACK确认消息的时候, 网络断开, 导致消息没有被确认重新发送 生产者使用publisher confirm机制的时候, 消息发送成功, 但是rabbitmq返回发送确认信息的时候网络断开, 导致消息发送两遍.","link":"/blog/2018/02/02/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97b1.rabbitmq/"},{"title":"JVM-垃圾回收","text":"因为JVM自动内存管理机制，将程序员从繁重的内存管理中释放出来，可以更专心地专注于业务开发。所以我们需要了解垃圾回收 判断对象存活引用计数算法对每个对象保存一个整型的引用计数器属性，用于记录对象被引用的情况。Python支持两种 优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。缺点：需要单独的字段存储计数器，并且不能处理循环依赖。 可达性分析算法以根对象集合（GCRoots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。Java、c#支持这种。 GC Roots可以是哪些： 字符串常量池 所有被synchronized持有的对象 基本数据类型对应的Class对象，一些常驻的异常对象 本地方法栈内JNI引用的对象方法区中类静态属性引用的对象 虚拟机栈中引用的对象。比如：各个线程被调用的方法中使用到的参数、局部变量等。 可达性分析必须在一个能保证一致性的快照中进行，所有会stop the world 死亡？ 如果对象到GCRoot没有引用链，标记不可达 判断是否需要执行finalize()方法 对象没有重写finalize()或者finalize()已经被调用过，对象被判定不可触及 对象重写finalize()并且还没有调用过finalize()，对象会被插入队列中，创建一个低优先级的Finalizer线程触发finalize()执行 执行是对象逃脱GC最后机会，如果此方法引用链恢复了就会逃过GC 垃圾回收算法标记-清除算法（Mark-Sweep）过程： 标记：标记所有被引用对象（注意标记的是引用对象，不是垃圾） 清除：从头到尾进行线性的遍历回收没有标记的对象 清除不是真的置空，而是把需要清除的地址保存在空闲地址列表。下次有对象进来直接根据空闲列表覆盖 缺点：效率不高，GC的时候需要停止整个应用程序，内存碎片高，需要维护空闲列表 复制算法（copying）把可达的对象，直接复制到另外一个区域中复制完成后，A区就没有用了，里面的对象可以直接清除掉，其实里面的新生代里面就用到了复制算法 优点：没有标记和清楚过程，简单高效。没有内存碎片化缺点：浪费一半内存，需要每次存活对象很少性能才高 标记-压缩算法（Mark-Compact）标记清除升级版！ 标记：标记所有被引用对象（注意标记的是引用对象，不是垃圾） 压缩：将所有的存活对象压缩到内存的一端，按顺序排放。清理边界外所有的空间。 优点：解决内存碎片问题缺点：效率低于复制算法，移动对象的时候如果被其他对象引用，还需要调整引用地址。移动的时候STW 分代收集算法目前几乎所有的GC都采用分代收集算法执行垃圾回收的 新生代：复制算法老年代：标记清楚/标记压缩算法 增量收集算法如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。 优点：因为和应用线程交替执行，响应时间快缺点：由于线程切换和上下文转换消耗，系统吞吐量下降 分区算法堆空间越大，一次Gc时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。 分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。 垃圾回收器我们主要优化指标： 吞吐量：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% 暂停时间：指一个时间段内应用程序线程暂停，让GC线程执行的状态 按照垃圾分代来分类： 新生代收集器：Serial、ParNew、Parallel Scavenge 老年代收集器：Serial old、Parallel old、CMS 整堆收集器：G1 组合方式为： Serial+SerialOld ParNew+CMS Parallel Scavenge+Parallel old(1.8默认) G1 Serial+CMS(1.8废弃，1.9完全取消) ParNew+Serial old(1.8废弃，1.9完全取消) Parallel Scavenge+Serialold GC(JDK14废弃，JDK9废弃CMS，JDK14删除CMS) Serial+SerialOldSerial使用复制算法、串行回收SerialOld使用标记-压缩算法、串行回收。client模式下默认老年代垃圾回收器 使用场景：单核CPU使用 使用配置： -XX：+UseSerialGC参数可以指定年轻代和老年代都使用串行收集器 ParNew+CMSParNewParNew收集器是serial收集器的多线程版本，除了并行回收新生代之外和Serial无区别。同样采用复制算法 使用配置： -XX：+UseParNewGC参数指定新生代收集器，不影响老年代。 -XX:ParallelGCThreads限制线程数量，默认开启和CPU数据相同的线程数。 CMSConcurrent Mark Sweep 第一次实现了让垃圾收集线程与用户线程同时工作，但是还是有STW。只能匹配Serial/ParNew优点：低延迟 CMS的垃圾收集算法采用标记-清除算法，并且也会”stop-the-world”。 过程： 初始标记：会STW，标记GCRoots能直接关联到的对象。由于直接关联对象比较小，所以这里的速度非常快。 并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，不需要STW。耗时久 重新标记：并发标记阶段因为用户线程一起运行，所以需要重新标记已修改的对象。STW，因为只是改变变化的，所以很快 并发清除：使用标记清除删除标记了的死亡对象，因为不需要移动存活对象，所以也是可以和用户线程同时并发执行的。耗时久 注意：因为在回收的时候用户线程也在运行，所以CMS不能像其他收集器一样等到老年代完全被填满再收集。当堆内存达到一定阈值就开始回收。如果CMS预留的堆内存无法满足程序需要，就会出现Concurrent Mode Failure，这时候CMS启动后被预案使用SerialOld收集，这样停顿时间就很长了 优点：并发收集，低延迟缺点： CMS是基于标记-清除算法实现的，所以在收集结束的时候会有大量的空间碎片产生。 CMS收集器对CPU资源非常敏感 CMS处理器无法处理浮动垃圾 如果CMS预留的堆内存无法满足程序需要启动后备方案停顿时间就很长了 使用配置： -XX：+UseConcMarkSweepGC手动指定使用CMS收集器执行内存回收任务。开启该参数后会自动将-xx：+UseParNewGC打开 -XX:CMSInitiatingOccupanyFraction 设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收。JDK6以上默认92% -XX：+UseCMSCompactAtFullCollection指定在执行完FullGC后对内存空间进行压缩整理，STW，会增加停顿时间 -XX:CMSFullGCsBeforecompaction设置在执行多少次FullGC后对内存空间进行压缩整理 -XX:ParallelcMSThreads设置CMS的线程数量，默认(ParallelGCThreads+3)/4 Parallel Scavenge+Parallel oldParallel Scavenge收集器同样也采用了复制算法、并行回收。 和ParNew区别： 吞吐量优先：适合后台运算比较多而不需要太多交互的任务 自适应调节策略 Parallel old收集器采用了标记-压缩算法，但同样也是基于并行回收和”stop-the-World”机制。 使用配置： -XX：+UseParallelGC 手动指定年轻代使用Parallel并行收集器执行内存回收任务（1.8默认开启） -XX：+UseParallelOldGC 手动指定老年代都是使用并行回收收集器（1.8默认开启） -XX:ParallelGCThreads限制线程数量，默认开启和CPU数据相同的线程数。 -XX:MaxGCPauseMillis设置垃圾收集器最大停顿时间STW（毫秒） -XX:GCTimeRatio垃圾收集时间占总时间的比例。取值范围（0，100）默认值99，和上个设置有矛盾 -XX:+UseAdaptiveSizePolicy 设置Parallel scavenge收集器具有自适应调节策略 12在这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数会被自动调整，已达到在堆大小、吞吐量和停顿时间之间的平衡点。在手动调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMills），让虚拟机自己完成调优工作。 G1https://blog.csdn.net/kuaipao19950507/article/details/105399721?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&amp;spm=1001.2101.3001.4242 https://tech.meituan.com/2016/09/23/g1.html G1（Garbage-First）是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性能特征。JDK9之后默认垃圾回收器 G1将整个Java堆划分成约2048个大小相同的独立Region块，就是有很多个Eden区、S0、S1、Old区、Humongous区（存储大对象，对象操作1.5Region放入）。内存回收是以Region为单位 Remembered Set（记忆集）一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用。比如年轻代对象引用老年代对象，这样还需要去扫描老年代？ 每个Region都有一个对应的Remembered Set；每次引用类型数据写操作时都会检查是否引用对象在其他Region中，如果存在就把他的引用写在RS中。 回收过程G1回收过程一: 年轻代GC 根扫描，跟CMS类似，STW，扫描GC Roots直接对象。 处理Dirty card, 更新RSet. 扫描RSet,扫描RSet中所有old区对扫描到的young区或者survivor去的引用。 拷贝扫描出的存活的对象到survivor2/old区 处理引用队列，软引用，弱引用，虚引用 G1回收过程二: 并发标记过程 初始标记阶段: 标记从根节点直接可达的对象。这个阶段是STW的,并且会触发一次年轻代GC。 根区域扫描(Root Region Scanning): G1 GC扫描survivor区直接可达的老年代区域对象,并标记被引用的对象。这一过程必须在young GC之前完成。 并发标记(Concurrent Marking): 在整个堆中进行并发标记(和应用程序并发执行),此过程可能被youngGC中断。在并发标记阶段,若发现区域对象中的所有对象都是垃圾,那这个区域会被立即回收。同时,并发标记过程中,会计算每个区域的对象活性(区域中存活对象的比例)。 再次标记(Remark): 由于应用程序持续进行,需要修正上一次的标记结果。是STW的。G1中采用了比CMS更快的初始快照法: snapshot-at-the-beginning(SATB)。 独占清理(cleanup,STW): 计算各个区域的存活对象和GC回收比例,并进行排序,识别可以混合回收的区域。为下阶段做铺垫。是STW的。 并发清理阶段: 识别并清理完全空闲的区域。 G1回收过程三: 混合回收 当越来越多的对象晋升到老年代old region时,为了避免堆内存被耗尽,虚拟机会触发一个混合的垃圾收集器,即Mixed GC,该算法并不是一个Old GC,除了回收整个Young Region,还会回收一部分的Old Region。这里需要注意: 是一部分老年代,而不是全部老年代。可以选择哪些Old Region进行收集,从而可以对垃圾回收的耗时时间进行控制。也要注意的是Mixed GC并不是Full GC。 并发标记结束以后,老年代中百分百为垃圾的内存分段被回收了,部分为垃圾的内存分段被计算了出来。默认情况下,这些老年代的内存分段会分8次(可以通过-XX:G1MixedGCCountTarget设置)被回收。 混合回收的回收集(Collection Set)包括八分之一的老年代内存分段,Eden区内存分段,Survivor区内存分段。混合回收的算法和年轻代回收的算法完全一样,只是回收集多了老年代的内存分段。具体过程请参考上面的年轻代回收过程。 由于老年代中的内存分段默认分8次回收,G1会优先回收垃圾多的内存分段。垃圾占内存分段比例越高,越会被先回收。并且有一个阈值会决定内存分段是否被回收。-XX:G1MixedGCLiveThresholdPercent,默认为65%,意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低,意味着存活的对象占比高,在复制的时候会花费更多的时间。 混合回收并不一定要进行8次。有一个阈值-XX:G1HeapWastePercent,默认值为10%,意思是允许整个堆内存中有10%的空间被浪费,意味着如果发现可以回收的垃圾占堆内存的比例低于10%,则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。 FullGC： G1的初衷就是要避免Full GC的出现。按时如果上述方式不能正常工作,G1会停止应用程序的执行(Stop-The-World),使用单线程的内存回收算法进行垃圾回收,性能会非常差,应用程序停顿时间会很长。 导致G1Full GC的原因可能有两个: Evacuation的时候没有足够的to-space来存放晋升的对象; 并发处理过程完成之前空间耗尽。 优点： 空间整合，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内 并行和并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU来缩短stop-The-World停顿时间 分代收集 缺点： 相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（overload）都要比CMS要高。 从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在6-8GB之间。 最主要的应用是需要低GC延迟，并具有大堆的应用程序提供解决方案。如：在堆大小约6GB或更大时，可预测的暂停时间可以低于0.5秒；（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次Gc停顿时间不会过长）。 在下面的情况时，使用G1可能比CMS好： 超过50%的Java堆被活动数据占用 对象分配频率或年代提升频率变化很大 GC停顿时间过长（长于0.5至1秒） 使用配置： -XX:+UseG1GC：手动指定使用G1垃圾收集器执行内存回收任务 -XX:G1HeapRegionSize设置每个Region的大小。值是2的幂，范围是1MB到32MB之间，目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000。 -XX:MaxGCPauseMillis 设置期望达到的最大Gc停顿时间指标（JVM会尽力实现，但不保证达到）。默认值是200ms -XX:+ParallelGcThread设置STW工作线程数的值。最多设置为8 -XX:ConcGCThreads 设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGcThreads）的1/4左右。 -XX:InitiatingHeapOccupancyPercent 设置触发并发Gc周期的Java堆占用率阈值。超过此值，就触发GC。默认值是45。 番外System.gc()在默认情况下，通过system.gc()或Runtime.getRuntime().gc()的调用，会显式触发FullGC。但是不保证立即生效 对象finalization机制垃圾回收此对象之前，总会先调用这个对象的finalize()方法。通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等。 永远不要主动调用对象finalize() 糟糕的finalize()验证影响GC性能 可能导致对象复活 运行时候不保证，完全由GC决定。极端情况下没有GC，这个永远不会调用（如果在里面释放资源） 安全点与安全区域安全点（Safepoint）：程序执行时并非在所有地方都能停顿下来开始GC，只有在特定的位置才能停顿下来开始GC。一般安全点选择为执行指令比较长的，比如方法调用、循环跳转、异常跳转等 方式： 抢先式中断(不用)：中断所有线程，如果线程不在安全点恢复线程继续跑到安全点 主动式中断：设置中断标识，每个线程跑到安全点的时候主动轮询标识。true就中断挂起 但是如果线程处于sleep、blocked状态的时候无法响应JVM中断挂起，就需要用安全区域解决。 安全区域：一段代码中对象引用关系不会发生任何变化，这区域任何位置GC都是安全的 运行到安全区域时线程就会有标示，JVM GC的时候会忽略存在安全区域状态的线程 线程离开安全区域如果GC完成，继续运行。GC还没运行完，等待GC运行完","link":"/blog/2020/04/04/%E8%99%9A%E6%8B%9F%E6%9C%BA-a4%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"springIOC源码","text":"IOC是Spring的一个可谓最重要的功能 整体脉络 先会生成一个DefaultListableBeanFactory容器 读取xml/yml等配置文件,抽象出一个接口 解析之后封装成BeanDefinition，保存在DefaultListableBeanFactory的Map&lt;String, BeanDefinition&gt; beanDefinitionMap中 通过BeanFactoryPostProcessor增强BeanDefinition，比如解析${}占位符 通过反射实例化bean 填充属性,populateBean 检查aware接口并设置相关依赖 BeanPostProcessor前置处理 先调用InitializingBean的afterPropertiesSet 再调用init-method属性指定的初始化方法 BeanPostProcessor后置处理，aop就是通过这个实现的 在初始化前后都会有事件监听事件 前期介绍1234567public class App { public static void main(String[] args) { // 用我们的配置文件来启动一个 ApplicationContext ApplicationContext context = new ClassPathXmlApplicationContext(&quot;classpath:application.xml&quot;); context.getBean(**.class); }} BeanFactory：顶级接口，通过名称、class方式getBean ListableBeanFactory：可以枚举所有的bean实例，就不需要一个个查询 HierarchicalBeanFactory：实现工厂分层，设置BeanFactory父子关系 AutowireCapableBeanFactory：使用注解自动装载bean ApplicationContext：继承ListableBeanFactory、HierarchicalBeanFactory，同时使用组合方式getAutowireCapableBeanFactory()获取AutowireCapableBeanFactory。虽然继承了BeanFactory但是不应该理解为BeanFactory的实现类，而是内部持有了一个实例化DefaultListableBeanFactory。BeanFactory都是委托给DefaultListableBeanFactory处理的 BeanDefinition：就是bean内容的封装对象，实例化之后就是对应的bean BeanDefinition12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement { // 我们可以看到，默认只提供 sington 和 prototype 两种， // 很多读者可能知道还有 request, session, globalSession, application, websocket 这几种， // 不过，它们属于基于 web 的扩展。 String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; // 比较不重要，直接跳过吧 int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; // 设置父 Bean，这里涉及到 bean 继承，不是 java 继承。请参见附录的详细介绍 // 一句话就是：继承父 Bean 的配置信息而已 void setParentName(String parentName); // 获取父 Bean String getParentName(); // 设置 Bean 的类名称，将来是要通过反射来生成实例的 void setBeanClassName(String beanClassName); // 获取 Bean 的类名称 String getBeanClassName(); // 设置 bean 的 scope void setScope(String scope); String getScope(); // 设置是否懒加载 void setLazyInit(boolean lazyInit); boolean isLazyInit(); // 设置该 Bean 依赖的所有的 Bean，注意，这里的依赖不是指属性依赖(如 @Autowire 标记的)， // 是 depends-on=&quot;&quot; 属性设置的值。 void setDependsOn(String... dependsOn); // 返回该 Bean 的所有依赖 String[] getDependsOn(); // 设置该 Bean 是否可以注入到其他 Bean 中，只对根据类型注入有效， // 如果根据名称注入，即使这边设置了 false，也是可以的 void setAutowireCandidate(boolean autowireCandidate); // 该 Bean 是否可以注入到其他 Bean 中 boolean isAutowireCandidate(); // 主要的。同一接口的多个实现，如果不指定名字的话，Spring 会优先选择设置 primary 为 true 的 bean void setPrimary(boolean primary); // 是否是 primary 的 boolean isPrimary(); // 如果该 Bean 采用工厂方法生成，指定工厂名称。对工厂不熟悉的读者，请参加附录 // 一句话就是：有些实例不是用反射生成的，而是用工厂模式生成的 void setFactoryBeanName(String factoryBeanName); // 获取工厂名称 String getFactoryBeanName(); // 指定工厂类中的 工厂方法名称 void setFactoryMethodName(String factoryMethodName); // 获取工厂类中的 工厂方法名称 String getFactoryMethodName(); // 构造器参数 ConstructorArgumentValues getConstructorArgumentValues(); // Bean 中的属性值，后面给 bean 注入属性值的时候会说到 MutablePropertyValues getPropertyValues(); // 是否 singleton boolean isSingleton(); // 是否 prototype boolean isPrototype(); // 如果这个 Bean 是被设置为 abstract，那么不能实例化， // 常用于作为 父bean 用于继承，其实也很少用...... boolean isAbstract(); int getRole(); String getDescription(); String getResourceDescription(); BeanDefinition getOriginatingBeanDefinition();} refresh()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@Overridepublic void refresh() throws BeansException, IllegalStateException { //加锁保证refresh单线程进入 synchronized (this.startupShutdownMonitor) { //准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符 prepareRefresh(); //这步比较关键，这步完成后，配置文件就会解析成一个个BeanDefinition，注册到BeanFactory中， // 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了， // 注册也只是将这些信息都保存到了注册中心(说到底核心是一个 beanName-&gt; beanDefinition 的 map) ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean prepareBeanFactory(beanFactory); try { // 【这里需要知道 BeanFactoryPostProcessor 这个知识点，Bean 如果实现了此接口， // 那么在容器初始化以后，Spring 会负责调用里面的 postProcessBeanFactory 方法。】 // 这里是提供给子类的扩展点，到这里的时候，所有的 Bean 都加载、注册完成了，但是都还没有初始化 // 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事 postProcessBeanFactory(beanFactory); // 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 方法 invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别 // 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization // 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化 registerBeanPostProcessors(beanFactory); // 初始化当前 ApplicationContext 的 MessageSource，国际化略 initMessageSource(); // 初始化当前 ApplicationContext 的事件广播器略 initApplicationEventMulticaster(); // 从方法名就可以知道，典型的模板方法(钩子方法)， // 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前） onRefresh(); // 注册事件监听器，监听器需要实现 ApplicationListener 接口。这也不是我们的重点，过 registerListeners(); // 重点，重点，重点 // 初始化所有的 singleton beans //（lazy-init 的除外） finishBeanFactoryInitialization(beanFactory); // 最后，广播事件，ApplicationContext 初始化完成 finishRefresh(); } catch (BeansException ex) { if (logger.isWarnEnabled()) { logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); } // Destroy already created singletons to avoid dangling resources. // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源 destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // 把异常往外抛 throw ex; } finally { // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); } }} obtainFreshBeanFactory()1234567891011protected ConfigurableListableBeanFactory obtainFreshBeanFactory() { // 关闭旧的 BeanFactory (如果有)，创建新的 BeanFactory，加载 Bean 定义、注册 Bean 等等 refreshBeanFactory(); // 返回刚刚创建的 BeanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) { logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); } return beanFactory;} 跟进refreshBeanFactory()-&gt;AbstractRefreshableApplicationContext 1234567891011121314151617181920212223242526272829@Overrideprotected final void refreshBeanFactory() throws BeansException { // 如果 ApplicationContext 中已经加载过 BeanFactory 了，销毁所有 Bean，关闭 BeanFactory // 注意，应用中 BeanFactory 本来就是可以多个的，这里可不是说应用全局是否有 BeanFactory，而是当前 // ApplicationContext 是否有 BeanFactory if (hasBeanFactory()) { destroyBeans(); closeBeanFactory(); } try { // 初始化一个 DefaultListableBeanFactory，为什么用这个，我们马上说。 DefaultListableBeanFactory beanFactory = createBeanFactory(); // 用于 BeanFactory 的序列化，我想不部分人应该都用不到 beanFactory.setSerializationId(getId()); // 下面这两个方法很重要，别跟丢了，具体细节之后说 // 设置 BeanFactory 的两个配置属性：是否允许 Bean 覆盖、是否允许循环引用 customizeBeanFactory(beanFactory); // 加载 Bean 到 BeanFactory 中 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) { this.beanFactory = beanFactory; } } catch (IOException ex) { throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); }} 跟进customizeBeanFactory(beanFactory); 是否bean覆盖：默认情况allowBeanDefinitionOverriding为null，如果在配置文件中使用了相同的id或name，如果同一配置文件会报错；不同配置文件会覆盖 是否循环依赖：默认spring支持set方式的循环依赖，但是不支持构造循环依赖 跟进loadBeanDefinitions(beanFactory);这里给这个BeanFactory实例化一个XmlBeanDefinitionReader 跟进AbstractXmlApplicationContext#loadBeanDefinitions(beanDefinitionReader); 123456789101112@Overridepublic int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException { Assert.notNull(resources, &quot;Resource array must not be null&quot;); int counter = 0; // 注意这里是个 for 循环，也就是每个文件是一个 resource for (Resource resource : resources) { // 继续往下看 counter += loadBeanDefinitions(resource); } // 最后返回 counter，表示总共加载了多少的 BeanDefinition return counter;} 跟进XmlBeanDefinitionReader#loadBeanDefinitions(resource); 跟进XmlBeanDefinitionReader#doLoadBeanDefinitions(inputSource, encodedResource.getResource());这里将xml文件转换为Document对象之后registerBeanDefinitions(doc, resource); 1234567public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); //重点 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;} 跟进DefaultBeanDefinitionDocumentReader#registerBeanDefinitions 12345678910111213141516171819202122232425262728293031protected void doRegisterBeanDefinitions(Element root) { // 我们看名字就知道，BeanDefinitionParserDelegate 必定是一个重要的类，它负责解析 Bean 定义， // 这里为什么要定义一个 parent? 看到后面就知道了，是递归问题， // 因为 &lt;beans /&gt; 内部是可以定义 &lt;beans /&gt; 的，所以这个方法的 root 其实不一定就是 xml 的根节点，也可以是嵌套在里面的 &lt;beans /&gt; 节点，从源码分析的角度，我们当做根节点就好了 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) { // 这块说的是根节点 &lt;beans ... profile=&quot;dev&quot; /&gt; 中的 profile 是否是当前环境需要的， // 如果当前环境配置的 profile 不包含此 profile，那就直接 return 了，不对此 &lt;beans /&gt; 解析 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) { String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) { if (logger.isInfoEnabled()) { logger.info(&quot;Skipped XML bean definition file due to specified profiles [&quot; + profileSpec + &quot;] not matching: &quot; + getReaderContext().getResource()); } return; } } } preProcessXml(root); // 钩子,没有被使用到 // 往下看 parseBeanDefinitions(root, this.delegate); postProcessXml(root); // 钩子,没有被使用到 this.delegate = parent;} 跟进parseBeanDefinitions(root, this.delegate); 123456789101112131415161718192021222324// default namespace 涉及到的就四个标签 &lt;import /&gt;、&lt;alias /&gt;、&lt;bean /&gt; 和 &lt;beans /&gt;，// 其他的属于 custom 的protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { if (delegate.isDefaultNamespace(root)) { NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) { // 解析 default namespace 下面的几个元素 parseDefaultElement(ele, delegate); } else { // 解析其他 namespace 的元素 delegate.parseCustomElement(ele); } } } } else { delegate.parseCustomElement(root); }} 默认标签：parseDefaultElement(ele, delegate)代表解析的节点是&lt;import /&gt;、&lt;alias /&gt;、&lt;bean /&gt;、&lt;beans /&gt;这几个 非默认标签： delegate.parseCustomElement(element)，比如&lt;mvc /&gt;、&lt;task /&gt;、&lt;context /&gt;、&lt;aop /&gt;。如何使用非默认标签： xml 头部的地方也要引入相应的namespace和.xsd文件 代码中需要提供相应的parser来解析，比如对应的MvcNamespaceHandler、TaskNamespaceHandler、ContextNamespaceHandler、AopNamespaceHandler所以以后看spring标签可以看xxNamespaceHandler类 解析这一块略，最后一个&lt;bean /&gt;标签产生了一个BeanDefinitionHolder的实例，这个实例里面也就是一个BeanDefinition的实例和它的beanName、aliases这三个信息。 跟进BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &lt;bean /&gt;会被注册 12345678910111213141516171819//BeanDefinitionReaderUtils public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException { String beanName = definitionHolder.getBeanName(); // 注册这个 Bean registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 如果还有别名的话，也要根据别名全部注册一遍，不然根据别名就会找不到 Bean 了 String[] aliases = definitionHolder.getAliases(); if (aliases != null) { for (String alias : aliases) { // alias -&gt; beanName 保存它们的别名信息，这个很简单，用一个 map 保存一下就可以了， // 获取的时候，会先将 alias 转换为 beanName，然后再查找 registry.registerAlias(beanName, alias); } }} DefaultListableBeanFactory.beanDefinitionMap：放入所有的BeanDefinitionDefaultListableBeanFactory.beanDefinitionNames：放入所有注册的Bean的名字 注册了BeanDefinition但是都没有初始化 prepareBeanFactory(factory)Spring把我们在xml配置的bean都注册以后，会手动注册一些特殊的bean 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) { // 设置BeanFactory的类加载器 beanFactory.setBeanClassLoader(getClassLoader()); // 设置 BeanExpressionResolver beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); // beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 这个processor负责回调ApplicationContextAware、EnvironmentAware、ResourceLoaderAware等 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 下面几行的意思就是，如果某个 bean 依赖于以下几个接口的实现类，在自动装配的时候忽略它们， // Spring 会通过其他方式来处理这些依赖。 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); /** * 下面几行就是为特殊的几个 bean 赋值，如果有 bean 依赖了以下几个，会注入这边相应的值， * 之前我们说过，&quot;当前 ApplicationContext 持有一个 BeanFactory&quot;，这里解释了第一行。 * ApplicationContext 还继承了 ResourceLoader、ApplicationEventPublisher、MessageSource * 所以对于这几个依赖，可以赋值为 this，注意 this 是一个 ApplicationContext * 那这里怎么没看到为 MessageSource 赋值呢？那是因为 MessageSource 被注册成为了一个普通的 bean */ //registerResolvableDependency作用是比如一个接口有多个实现类，可以指定一个实现类注入 beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // 这个 BeanPostProcessor 也很简单，在 bean 实例化后，如果是 ApplicationListener 的子类， // 那么将其添加到 listener 列表中，可以理解成：注册 事件监听器 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // 这里涉及到特殊的 bean，名为：loadTimeWeaver，这不是我们的重点，忽略它 // tips: ltw 是 AspectJ 的概念，指的是在运行期进行织入，这个和 Spring AOP 不一样， // 感兴趣的读者请参考我写的关于 AspectJ 的另一篇文章 https://www.javadoop.com/post/aspectj if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) { beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); } /** * 从下面几行代码我们可以知道，Spring 往往很 &quot;智能&quot; 就是因为它会帮我们默认注册一些有用的 bean， * 我们也可以选择覆盖 */ // 如果没有定义 &quot;environment&quot; 这个 bean，那么 Spring 会 &quot;手动&quot; 注册一个 if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) { beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); } // 如果没有定义 &quot;systemProperties&quot; 这个 bean，那么 Spring 会 &quot;手动&quot; 注册一个 if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) { beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); } // 如果没有定义 &quot;systemEnvironment&quot; 这个 bean，那么 Spring 会 &quot;手动&quot; 注册一个 if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) { beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); }} finishBeanFactoryInitialization(beanFactory)123456789101112131415161718192021222324252627282930313233343536373839// 初始化剩余的 singleton beansprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) { // 初始化conversionService,作用前后端传值类型转换 if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) { beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); } // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) { beanFactory.addEmbeddedValueResolver(new StringValueResolver() { @Override public String resolveStringValue(String strVal) { return getEnvironment().resolvePlaceholders(strVal); } }); } // 先初始化 LoadTimeWeaverAware 类型的 Bean // 之前也说过，这是 AspectJ 相关的内容，放心跳过吧 String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) { getBean(weaverAwareName); } // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // 没什么别的目的，因为到这一步的时候，Spring 已经开始预初始化 singleton beans 了， // 肯定不希望这个时候还出现 bean 定义解析、加载、注册。 beanFactory.freezeConfiguration(); // 开始初始化 beanFactory.preInstantiateSingletons();} 跟进DefaultListableBeanFactory#preInstantiateSingletons 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Overridepublic void preInstantiateSingletons() throws BeansException { if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Pre-instantiating singletons in &quot; + this); } // this.beanDefinitionNames 保存了所有的 beanNames List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); // 下面这个循环，触发所有的非懒加载的 singleton beans 的初始化操作 for (String beanName : beanNames) { // 合并父 Bean 中的配置，注意 &lt;bean id=&quot;&quot; class=&quot;&quot; parent=&quot;&quot; /&gt; 中的 parent，用的不多吧， // 考虑到这可能会影响大家的理解，我在附录中解释了一下 &quot;Bean 继承&quot;，不了解的请到附录中看一下 RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); // 非抽象、非懒加载的 singletons。如果配置了 'abstract = true'，那是不需要初始化的 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { // 处理 FactoryBean(读者如果不熟悉 FactoryBean，请移步附录区了解) if (isFactoryBean(beanName)) { // FactoryBean 的话，在 beanName 前面加上 ‘&amp;’ 符号。再调用 getBean，getBean 方法别急 final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); // 判断当前 FactoryBean 是否是 SmartFactoryBean 的实现，此处忽略，直接跳过 boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) { isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() { @Override public Boolean run() { return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit(); } }, getAccessControlContext()); } else { isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); } if (isEagerInit) { getBean(beanName); } } else { // 对于普通的 Bean，只要调用 getBean(beanName) 这个方法就可以进行初始化了 getBean(beanName); } } } // 到这里说明所有的非懒加载的 singleton beans 已经完成了初始化 // 如果我们定义的 bean 是实现了 SmartInitializingSingleton 接口的，那么在这里得到回调，忽略 for (String beanName : beanNames) { Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) { final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { smartSingleton.afterSingletonsInstantiated(); return null; } }, getAccessControlContext()); } else { smartSingleton.afterSingletonsInstantiated(); } } }} 跟进AbstractBeanFactory#getBean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176@Overridepublic Object getBean(String name) throws BeansException { return doGetBean(name, null, null, false);}// 我们在剖析初始化 Bean 的过程，但是 getBean 方法我们经常是用来从容器中获取 Bean 用的，注意切换思路，// 已经初始化过了就从容器中直接返回，否则就先初始化再返回@SuppressWarnings(&quot;unchecked&quot;)protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException { // 获取一个 “正统的” beanName，处理两种情况，一个是前面说的 FactoryBean(前面带 ‘&amp;’)， // 一个是别名问题，因为这个方法是 getBean，获取 Bean 用的，你要是传一个别名进来，是完全可以的 final String beanName = transformedBeanName(name); // 注意跟着这个，这个是返回值 Object bean; // 检查下是不是已经创建过了 Object sharedInstance = getSingleton(beanName); // 这里说下 args 呗，虽然看上去一点不重要。前面我们一路进来的时候都是 getBean(beanName)， // 所以 args 传参其实是 null 的，但是如果 args 不为空的时候，那么意味着调用方不是希望获取 Bean，而是创建 Bean if (sharedInstance != null &amp;&amp; args == null) { if (logger.isDebugEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.debug(&quot;...&quot;); } else { logger.debug(&quot;Returning cached instance of singleton bean '&quot; + beanName + &quot;'&quot;); } } // 下面这个方法：如果是普通 Bean 的话，直接返回 sharedInstance， // 如果是 FactoryBean 的话，返回它创建的那个实例对象 // (FactoryBean 知识，读者若不清楚请移步附录) bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } else { if (isPrototypeCurrentlyInCreation(beanName)) { // 创建过了此 beanName 的 prototype 类型的 bean，那么抛异常， // 往往是因为陷入了循环引用 throw new BeanCurrentlyInCreationException(beanName); } // 检查一下这个 BeanDefinition 在容器中是否存在 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { // 如果当前容器不存在这个 BeanDefinition，试试父容器中有没有 String nameToLookup = originalBeanName(name); if (args != null) { // 返回父容器的查询结果 return (T) parentBeanFactory.getBean(nameToLookup, args); } else { // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); } } if (!typeCheckOnly) { // typeCheckOnly 为 false，将当前 beanName 放入一个 alreadyCreated 的 Set 集合中。 markBeanAsCreated(beanName); } /* * 稍稍总结一下： * 到这里的话，要准备创建 Bean 了，对于 singleton 的 Bean 来说，容器中还没创建过此 Bean； * 对于 prototype 的 Bean 来说，本来就是要创建一个新的 Bean。 */ try { final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 先初始化依赖的所有 Bean，这个很好理解。 // 注意，这里的依赖指的是 depends-on 中定义的依赖 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { // 检查是不是有循环依赖，这里的循环依赖和我们前面说的循环依赖又不一样，这里肯定是不允许出现的，不然要乱套了，读者想一下就知道了 if (isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between '&quot; + beanName + &quot;' and '&quot; + dep + &quot;'&quot;); } // 注册一下依赖关系 registerDependentBean(dep, beanName); // 先初始化被依赖项 getBean(dep); } } // 如果是 singleton scope 的，创建 singleton 的实例 if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() { @Override public Object getObject() throws BeansException { try { // 执行创建 Bean，详情后面再说 return createBean(beanName, mbd, args); } catch (BeansException ex) { destroySingleton(beanName); throw ex; } } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } // 如果是 prototype scope 的，创建 prototype 的实例 else if (mbd.isPrototype()) { // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try { beforePrototypeCreation(beanName); // 执行创建 Bean prototypeInstance = createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); } // 如果不是 singleton 和 prototype 的话，需要委托给相应的实现类来处理 else { String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException(&quot;No Scope registered for scope name '&quot; + scopeName + &quot;'&quot;); } try { Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() { @Override public Object getObject() throws BeansException { beforePrototypeCreation(beanName); try { // 执行创建 Bean return createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } } }); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new BeanCreationException(beanName, &quot;Scope '&quot; + scopeName + &quot;' is not active for the current thread; consider &quot; + &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;, ex); } } } catch (BeansException ex) { cleanupAfterBeanCreationFailure(beanName); throw ex; } } // 最后，检查一下类型对不对，不对的话就抛异常，对的话就返回了 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isInstance(bean)) { try { return getTypeConverter().convertIfNecessary(bean, requiredType); } catch (TypeMismatchException ex) { if (logger.isDebugEnabled()) { logger.debug(&quot;Failed to convert bean '&quot; + name + &quot;' to required type '&quot; + ClassUtils.getQualifiedName(requiredType) + &quot;'&quot;, ex); } throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); } } return (T) bean;} 跟进AbstractAutowireCapableBeanFactory#createBean 跟进AbstractAutowireCapableBeanFactory#doCreateBean 123456789101112131415161718192021222324252627282930313233protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException { ... if (instanceWrapper == null) { // 说明不是 FactoryBean，这里实例化 Bean，这里非常关键，细节之后再说 instanceWrapper = createBeanInstance(beanName, mbd, args); } // 这个就是 Bean 里面的 我们定义的类 的实例，很多地方我直接描述成 &quot;bean 实例&quot; final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null); // 类型 Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null); mbd.resolvedTargetType = beanType; ... // Initialize the bean instance. Object exposedObject = bean; try { // 这一步也是非常关键的，这一步负责属性装配，因为前面的实例只是实例化了，并没有设值，这里就是设值 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) { // 还记得 init-method 吗？还有 InitializingBean 接口？还有 BeanPostProcessor 接口？ // 这里就是处理 bean 初始化完成后的各种回调 exposedObject = initializeBean(beanName, exposedObject, mbd); } } catch (Throwable ex) { ... } ... return exposedObject;} createBeanInstance实例化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) { // 确保已经加载了此 class Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); // 校验一下这个类的访问权限 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Bean class isn't public, and non-public access not allowed: &quot; + beanClass.getName()); } if (mbd.getFactoryMethodName() != null) { // 采用工厂方法实例化，不熟悉这个概念的读者请看附录，注意，不是 FactoryBean return instantiateUsingFactoryMethod(beanName, mbd, args); } // 如果不是第一次创建，比如第二次创建 prototype bean。 // 这种情况下，我们可以从第一次创建知道，采用无参构造函数，还是构造函数依赖注入 来完成实例化 boolean resolved = false; boolean autowireNecessary = false; if (args == null) { synchronized (mbd.constructorArgumentLock) { if (mbd.resolvedConstructorOrFactoryMethod != null) { resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; } } } if (resolved) { if (autowireNecessary) { // 构造函数依赖注入 return autowireConstructor(beanName, mbd, null, null); } else { // 无参构造函数 return instantiateBean(beanName, mbd); } } // 判断是否采用有参构造函数 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) { // 构造函数依赖注入 return autowireConstructor(beanName, mbd, ctors, args); } // 调用无参构造函数 return instantiateBean(beanName, mbd);} 跟进SimpleInstantiationStrategy#instantiate 123456789101112131415161718192021222324252627282930313233343536373839404142@Overridepublic Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) { // 如果不存在方法覆写，那就使用 java 反射进行实例化，否则使用 CGLIB, // 方法覆写 请参见附录&quot;方法注入&quot;中对 lookup-method 和 replaced-method 的介绍 if (bd.getMethodOverrides().isEmpty()) { Constructor&lt;?&gt; constructorToUse; synchronized (bd.constructorArgumentLock) { constructorToUse = (Constructor&lt;?&gt;) bd.resolvedConstructorOrFactoryMethod; if (constructorToUse == null) { final Class&lt;?&gt; clazz = bd.getBeanClass(); if (clazz.isInterface()) { throw new BeanInstantiationException(clazz, &quot;Specified class is an interface&quot;); } try { if (System.getSecurityManager() != null) { constructorToUse = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Constructor&lt;?&gt;&gt;() { @Override public Constructor&lt;?&gt; run() throws Exception { return clazz.getDeclaredConstructor((Class[]) null); } }); } else { constructorToUse = clazz.getDeclaredConstructor((Class[]) null); } bd.resolvedConstructorOrFactoryMethod = constructorToUse; } catch (Throwable ex) { throw new BeanInstantiationException(clazz, &quot;No default constructor found&quot;, ex); } } } // 利用构造方法进行实例化 return BeanUtils.instantiateClass(constructorToUse); } else { // 存在方法覆写，利用 CGLIB 来完成实例化，需要依赖于 CGLIB 生成子类，这里就不展开了。 // tips: 因为如果不使用 CGLIB 的话，存在 override 的情况 JDK 并没有提供相应的实例化支持 return instantiateWithMethodInjection(bd, beanName, owner); }} populateBean属性注入跟进AbstractAutowireCapableBeanFactory#populateBean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) { // bean 实例的所有属性都在这里了 PropertyValues pvs = mbd.getPropertyValues(); if (bw == null) { if (!pvs.isEmpty()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;); } else { // Skip property population phase for null instance. return; } } // 到这步的时候，bean 实例化完成（通过工厂方法或构造方法），但是还没开始属性设值， // InstantiationAwareBeanPostProcessor 的实现类可以在这里对 bean 进行状态修改， // 我也没找到有实际的使用，所以我们暂且忽略这块吧 boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 如果返回 false，代表不需要进行后续的属性设值，也不需要再经过其他的 BeanPostProcessor 的处理 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) { continueWithPropertyPopulation = false; break; } } } } if (!continueWithPropertyPopulation) { return; } if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) { MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 通过名字找到所有属性值，如果是 bean 依赖，先初始化依赖的 bean。记录依赖关系 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) { autowireByName(beanName, mbd, bw, newPvs); } // 通过类型装配。复杂一些 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) { autowireByType(beanName, mbd, bw, newPvs); } pvs = newPvs; } boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) { PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 这里有个非常有用的 BeanPostProcessor 进到这里: AutowiredAnnotationBeanPostProcessor // 对采用 @Autowired、@Value 注解的依赖进行设值，这里的内容也是非常丰富的，不过本文不会展开说了，感兴趣的读者请自行研究 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) { return; } } } } if (needsDepCheck) { checkDependencies(beanName, mbd, filteredPds, pvs); } } // 设置 bean 实例的属性值 applyPropertyValues(beanName, mbd, bw, pvs);} initializeBean1234567891011121314151617181920212223242526272829303132333435363738protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) { if (System.getSecurityManager() != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { invokeAwareMethods(beanName, bean); return null; } }, getAccessControlContext()); } else { // 如果 bean 实现了 BeanNameAware、BeanClassLoaderAware 或 BeanFactoryAware 接口，回调 invokeAwareMethods(beanName, bean); } Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // BeanPostProcessor 的 postProcessBeforeInitialization 回调 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } try { // 处理 bean 中定义的 init-method， // 或者如果 bean 实现了 InitializingBean 接口，调用 afterPropertiesSet() 方法 invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, &quot;Invocation of init method failed&quot;, ex); } if (mbd == null || !mbd.isSynthetic()) { // BeanPostProcessor 的 postProcessAfterInitialization 回调 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;} 感谢： https://javadoop.com/post/spring-ioc https://www.cnblogs.com/ZhuChangwu/p/11681101.html","link":"/blog/2021/05/01/spring-1.IOC/"},{"title":"springAOP源码","text":"aop核心思想就是通过织入增强代码， 分为动态织入（运行时通过动态代理技术产生代理对象完成增强）和静态织入（不修改源代码，只对class文件修改，AspectJ） 动态代理分为静态代理和动态代理。 静态代理是在写源码的时候为目标去编写一个对应的代理类 动态代理其实是在运行时通过不同技术实现，去创建新的对象。JDK（目标类必须有接口）、CGLIB（只要不是final就可以，使用继承）。 默认JDK，可以指定使用CGLIB。 jdk1.7之前，CGLIB运行比JDK要快，之后效率差不多。但是JDK产生代理对象的效率要高。 spring AOP，即面向切面编程。AOP核心概念： 通知（Advice）:定义了切面(各处业务代码中都需要的逻辑提炼成的一个切面)做什么what+when何时使用。例如：前置通知Before、后置通知After、返回通知After-returning、异常通知After-throwing、环绕通知Around. 连接点（Joint point）：程序执行过程中能够插入切面的点，一般有多个。比如调用方式时、抛出异常时。 切点（Pointcut）:切点定义了连接点，切点包含多个连接点,即where哪里使用通知.通常指定类+方法 或者 正则表达式来匹配 类和方法名称。 切面（Aspect）:切面=通知+切点，即when+where+what何时何地做什么。 引入（Introduction）:允许我们向现有的类添加新方法或属性。 织入（Weaving）:织入是把切面应用到目标对象并创建新的代理对象的过程。 bean有代理对象，spring容器只会存代理对象。CGLIB底层通过ASM字节码工具包实现字节码重写，JDK只是相当于帮程序员在后台写了java文件并编译加载。 JDK和CGLIB产生代理对象的方式是怎么样？ 类加载器 获取完整的代理接口 代理逻辑1public static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 调用原生方法的时候就会调用InvocationHandler # invoke(Object proxy, Method method, Object[] args), 第一个原生对象， 第二个反射获得的Method，第三个方法参数 CGLIB： 123456789//创建增强器Enhancer enhancer = new Enhancer()//设置增强类对象enhancer.setSuperclass(clazz);//设置回调函数enhancer.setCallback(new MyMethodInterceptor());//获取增强之后的代理对象Object object = enhancer.create();return object; JDK和CGLIB产生代理对象的处理步骤是什么样的？调用原生方法的时候就会调用InvocationHandler或者MethodInterceptor去增强功能 Spring AOP的原理很简单，就是动态代理。在IOC调用getBean的时候不返回真实对象，而是返回代理对象。所以IOC没有管理的bean不能使用AOP。Spring采用JDK Proxy或CGLIB动态生成的。它和AspectJ不一样，AspectJ是直接修改掉你的字节码。 栗子123456789101112131415161718192021222324252627282930313233343536373839404142434445public interface AService { public String barA(); public String fooA(String msg);}public class AServiceImpl implements AService { @Override public String barA(){ System.out.println(&quot;AServiceImpl.barA()&quot;); return &quot;返回结果barA啦&quot;; } @Override public String fooA(String msg){ System.out.println(&quot;AServiceImpl.fooA(msg:&quot; + msg + &quot;)&quot;); return &quot;返回结果fooA啦&quot;; }}public class XmlAspect { public void doBefore(){ System.out.println(&quot;前置通知&quot;); } //声明后置通知 public void doAfterReturning(String result){ System.out.println(&quot;返回通知&quot; + &quot;---&quot; + result + &quot;---&quot;); } //声明异常通知 public void doAfterThrowing(Exception e){ System.out.println(&quot;异常通知&quot; + e.getMessage()); } public void doAfter(){ System.out.println(&quot;最终通知&quot;); } public Object doAround(ProceedingJoinPoint pjp) throws Throwable{ System.out.println(&quot;进入方法---环绕通知&quot;); Object o = pjp.proceed(); System.out.println(&quot;退出方法---环绕通知&quot;); return o; }} xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd&quot;&gt;&lt;!-- &lt;context:component-scan base-package=&quot;cn.pisces.cloud.demo.aop&quot;/&gt;--&gt;&lt;!-- &lt;context:annotation-config/&gt;--&gt;&lt;!-- &lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;--&gt; &lt;bean id=&quot;AServiceImpl&quot; class=&quot;cn.pisces.cloud.demo.aop.AServiceImpl&quot; /&gt; &lt;bean id=&quot;xmlAspect&quot; class=&quot;cn.pisces.cloud.demo.aop.XmlAspect&quot; /&gt; &lt;!--xml 配置aop--&gt; &lt;aop:config&gt; &lt;aop:aspect id=&quot;TestAspect&quot; ref=&quot;xmlAspect&quot;&gt; &lt;aop:pointcut id=&quot;pointcut&quot; expression=&quot;execution(* cn.pisces.cloud.demo.aop.*.*(..))&quot;/&gt; &lt;aop:around pointcut-ref=&quot;pointcut&quot; method=&quot;doAround&quot;/&gt; &lt;aop:before pointcut-ref=&quot;pointcut&quot; method=&quot;doBefore&quot;/&gt; &lt;aop:after pointcut-ref=&quot;pointcut&quot; method=&quot;doAfter&quot;/&gt; &lt;aop:after-returning pointcut-ref=&quot;pointcut&quot; method=&quot;doAfterReturning&quot; returning=&quot;result&quot;/&gt; &lt;aop:after-throwing pointcut-ref=&quot;pointcut&quot; method=&quot;doAfterThrowing&quot; throwing=&quot;e&quot;/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; &lt;!--&lt;bean id=&quot;logArgsAdvice&quot; class=&quot;cn.pisces.cloud.demo.aop.LogArgsAdvice&quot; /&gt; &lt;bean id=&quot;logArgsAdvisor&quot; class=&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt; &lt;property name=&quot;advice&quot; ref=&quot;logArgsAdvice&quot;/&gt; &lt;property name=&quot;pattern&quot; value=&quot;cn.pisces.cloud.demo.aop.*.*(..)&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot;/&gt;--&gt;&lt;/beans&gt; test 123456789public class TestAop { @Test public void testAop() { ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;aop-xml.xml&quot;); AService aService = (AService) ac.getBean(&quot;AServiceImpl&quot;); aService.fooA(&quot;test&quot;); }} beanDefinition处理首先aop在加载BeanDefinition的时候会处理一遍 DefaultBeanDefinitionDocumentReader#parseBeanDefinitions 12345678910111213141516171819202122protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { if (delegate.isDefaultNamespace(root)) { NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) { // &lt;bean&gt; parseDefaultElement(ele, delegate); } else { // &lt;aop:config&gt; delegate.parseCustomElement(ele); } } } } else { delegate.parseCustomElement(root); }} 跟进BeanDefinitionParserDelegate#parseCustomElement 123456789101112131415@Nullablepublic BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) { // namespaceUri为http://www.springframework.org/schema/aop String namespaceUri = getNamespaceURI(ele); if (namespaceUri == null) { return null; } // 根据这个Namespace获取对应的NamespaceHandler即Namespace处理器, AopNamespaceHandler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) { error(&quot;Unable to locate Spring NamespaceHandler for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;, ele); return null; } return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));} AopNamespaceHandler继承了NamespaceHandlerSupport，所以进入NamespaceHandlerSupport#parse 123456@Override@Nullablepublic BeanDefinition parse(Element element, ParserContext parserContext) { BeanDefinitionParser parser = findParserForElement(element, parserContext); return (parser != null ? parser.parse(element, parserContext) : null);} 这里对应了一些parser config–&gt;ConfigBeanDefinitionParser aspectj-autoproxy–&gt;AspectJAutoProxyBeanDefinitionParser scoped-proxy–&gt;ScopedProxyBeanDefinitionDecorator spring-configured–&gt;SpringConfiguredBeanDefinitionParser我们这里是&lt;aop:config&gt;所以进入ConfigBeanDefinitionParser#parse 12345678910111213141516171819202122232425262728293031@Override@Nullablepublic BeanDefinition parse(Element element, ParserContext parserContext) { CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), parserContext.extractSource(element)); parserContext.pushContainingComponent(compositeDef); // 重要: // 向Spring容器注册了一个BeanName为org.springframework.aop.config.internalAutoProxyCreator的Bean定义，可以自定义也可以使用Spring提供的（根据优先级来） // Spring默认提供的是org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator，这个类是AOP的核心类 // 在这个方法里面也会根据配置proxy-target-class和expose-proxy，设置是否使用CGLIB进行代理以及是否暴露最终的代理 configureAutoProxyCreator(parserContext, element); List&lt;Element&gt; childElts = DomUtils.getChildElements(element); for (Element elt: childElts) { String localName = parserContext.getDelegate().getLocalName(elt); if (POINTCUT.equals(localName)) { parsePointcut(elt, parserContext); } else if (ADVISOR.equals(localName)) { parseAdvisor(elt, parserContext); } // &lt;aop:config&gt;下的节点为&lt;aop:aspect&gt;所以执行这一行 else if (ASPECT.equals(localName)) { parseAspect(elt, parserContext); } } parserContext.popAndRegisterContainingComponent(); return null;} ConfigBeanDefinitionParser#parseAspect 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private void parseAspect(Element aspectElement, ParserContext parserContext) { //aspectId=TestAspect String aspectId = aspectElement.getAttribute(ID); //aspectName=xmlAspect String aspectName = aspectElement.getAttribute(REF); try { // 标识正在解析Aspect this.parseState.push(new AspectEntry(aspectId, aspectName)); List&lt;BeanDefinition&gt; beanDefinitions = new ArrayList&lt;&gt;(); List&lt;BeanReference&gt; beanReferences = new ArrayList&lt;&gt;(); List&lt;Element&gt; declareParents = DomUtils.getChildElementsByTagName(aspectElement, DECLARE_PARENTS); for (int i = METHOD_INDEX; i &lt; declareParents.size(); i++) { Element declareParentsElement = declareParents.get(i); beanDefinitions.add(parseDeclareParents(declareParentsElement, parserContext)); } // We have to parse &quot;advice&quot; and all the advice kinds in one loop, to get the // ordering semantics right. NodeList nodeList = aspectElement.getChildNodes(); boolean adviceFoundAlready = false; for (int i = 0; i &lt; nodeList.getLength(); i++) { Node node = nodeList.item(i); // for循环只用来处理&lt;aop:aspect&gt;标签下的&lt;aop:before&gt;、&lt;aop:after&gt;、&lt;aop:after-returning&gt;、&lt;aop:after-throwing method=&quot;&quot;&gt;、&lt;aop:around method=&quot;&quot;&gt;这五个标签 if (isAdviceNode(node, parserContext)) { if (!adviceFoundAlready) { adviceFoundAlready = true; if (!StringUtils.hasText(aspectName)) { parserContext.getReaderContext().error( &quot;&lt;aspect&gt; tag needs aspect bean reference via 'ref' attribute when declaring advices.&quot;, aspectElement, this.parseState.snapshot()); return; } beanReferences.add(new RuntimeBeanReference(aspectName)); } // 解析&lt;aop:before&gt;、&lt;aop:after&gt;、&lt;aop:after-returning&gt;、&lt;aop:after-throwing method=&quot;&quot;&gt;、&lt;aop:around method=&quot;&quot;&gt; AbstractBeanDefinition advisorDefinition = parseAdvice( aspectName, i, aspectElement, (Element) node, parserContext, beanDefinitions, beanReferences); beanDefinitions.add(advisorDefinition); } } AspectComponentDefinition aspectComponentDefinition = createAspectComponentDefinition( aspectElement, aspectId, beanDefinitions, beanReferences, parserContext); parserContext.pushContainingComponent(aspectComponentDefinition); List&lt;Element&gt; pointcuts = DomUtils.getChildElementsByTagName(aspectElement, POINTCUT); // 解析&lt;aop:pointcut&gt; for (Element pointcutElement : pointcuts) { parsePointcut(pointcutElement, parserContext); } parserContext.popAndRegisterContainingComponent(); } finally { this.parseState.pop(); }} 解析AdviceConfigBeanDefinitionParser#parseAdvice 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private AbstractBeanDefinition parseAdvice( String aspectName, int order, Element aspectElement, Element adviceElement, ParserContext parserContext, List&lt;BeanDefinition&gt; beanDefinitions, List&lt;BeanReference&gt; beanReferences) { try { this.parseState.push(new AdviceEntry(parserContext.getDelegate().getLocalName(adviceElement))); // create the method factory bean RootBeanDefinition methodDefinition = new RootBeanDefinition(MethodLocatingFactoryBean.class); methodDefinition.getPropertyValues().add(&quot;targetBeanName&quot;, aspectName); methodDefinition.getPropertyValues().add(&quot;methodName&quot;, adviceElement.getAttribute(&quot;method&quot;)); methodDefinition.setSynthetic(true); // create instance factory definition RootBeanDefinition aspectFactoryDef = new RootBeanDefinition(SimpleBeanFactoryAwareAspectInstanceFactory.class); aspectFactoryDef.getPropertyValues().add(&quot;aspectBeanName&quot;, aspectName); aspectFactoryDef.setSynthetic(true); // register the pointcut // 创建的AbstractBeanDefinition实例是RootBeanDefinition，这和普通Bean创建的实例为GenericBeanDefinition不同 // 进入createAdviceDefinition#getAdviceClass可以发现，不同的Bean定义中要对应一个具体的Class，不同的切入方式对应不同的Class // 1. before对应AspectJMethodBeforeAdvice // 2. After对应AspectJAfterAdvice // 3. after-returning对应AspectJAfterReturningAdvice // 4. after-throwing对应AspectJAfterThrowingAdvice // 5. around对应AspectJAroundAdvice AbstractBeanDefinition adviceDef = createAdviceDefinition( adviceElement, parserContext, aspectName, order, methodDefinition, aspectFactoryDef, beanDefinitions, beanReferences); // configure the advisor // 将上一步adviceDef包装一下生成一个新的RootBeanDefinition，Class类型是org.springframework.aop.aspectj.AspectJPointcutAdvisor RootBeanDefinition advisorDefinition = new RootBeanDefinition(AspectJPointcutAdvisor.class); advisorDefinition.setSource(parserContext.extractSource(adviceElement)); advisorDefinition.getConstructorArgumentValues().addGenericArgumentValue(adviceDef); if (aspectElement.hasAttribute(ORDER_PROPERTY)) { advisorDefinition.getPropertyValues().add( ORDER_PROPERTY, aspectElement.getAttribute(ORDER_PROPERTY)); } // register the final advisor // advisorDefinition的BeanDefinition注册到DefaultListableBeanFactory // 注册的名称为Class全路径+&quot;#&quot;+全局计数器，比如org.springframework.aop.aspectj.AspectJPointcutAdvisor#0、org.springframework.aop.aspectj.AspectJPointcutAdvisor#1 parserContext.getReaderContext().registerWithGeneratedName(advisorDefinition); return advisorDefinition; } finally { this.parseState.pop(); }} 解析pointcut进入ConfigBeanDefinitionParser#parsePointcut 123456789101112131415161718192021222324252627282930313233343536private AbstractBeanDefinition parsePointcut(Element pointcutElement, ParserContext parserContext) { // 获取&lt;aop:pointcut&gt;标签下的&quot;id&quot;属性与&quot;expression&quot;属性 String id = pointcutElement.getAttribute(ID); String expression = pointcutElement.getAttribute(EXPRESSION); AbstractBeanDefinition pointcutDefinition = null; try { // 推送一个PointcutEntry，表示当前Spring上下文正在解析Pointcut标签 this.parseState.push(new PointcutEntry(id)); // &lt;aop:pointcut&gt;标签对应解析出来的BeanDefinition是RootBeanDefinition，且RootBenaDefinitoin中的Class是org.springframework.aop.aspectj.AspectJExpressionPointcut // &lt;aop:pointcut&gt;标签对应的Bean是prototype即原型的 pointcutDefinition = createPointcutDefinition(expression); // 为空跳过 pointcutDefinition.setSource(parserContext.extractSource(pointcutElement)); String pointcutBeanName = id; // 如果&lt;aop:pointcut&gt;标签中配置了id属性就执行 if (StringUtils.hasText(pointcutBeanName)) { parserContext.getRegistry().registerBeanDefinition(pointcutBeanName, pointcutDefinition); } else { // 没有默认为org.springframework.aop.aspectj.AspectJExpressionPointcut#序号 pointcutBeanName = parserContext.getReaderContext().registerWithGeneratedName(pointcutDefinition); } parserContext.registerComponent( new PointcutComponentDefinition(pointcutBeanName, pointcutDefinition, expression)); } finally { // &lt;aop:pointcut&gt;标签解析完毕后，让之前推送至栈顶的PointcutEntry出栈，表示此次&lt;aop:pointcut&gt;标签解析完毕 this.parseState.pop(); } return pointcutDefinition;} beanDefinition处理总结这时候我们beanDefinitionMap中 1234567891011121314151617&quot;org.springframework.aop.aspectj.AspectJPointcutAdvisor#4&quot; -&gt; {RootBeanDefinition@2488} &quot;Root bean: class [org.springframework.aop.aspectj.AspectJPointcutAdvisor]; scope=; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;org.springframework.aop.aspectj.AspectJPointcutAdvisor#2&quot; -&gt; {RootBeanDefinition@2490} &quot;Root bean: class [org.springframework.aop.aspectj.AspectJPointcutAdvisor]; scope=; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;org.springframework.aop.aspectj.AspectJPointcutAdvisor#3&quot; -&gt; {RootBeanDefinition@2492} &quot;Root bean: class [org.springframework.aop.aspectj.AspectJPointcutAdvisor]; scope=; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;org.springframework.aop.aspectj.AspectJPointcutAdvisor#0&quot; -&gt; {RootBeanDefinition@2349} &quot;Root bean: class [org.springframework.aop.aspectj.AspectJPointcutAdvisor]; scope=; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;org.springframework.aop.aspectj.AspectJPointcutAdvisor#1&quot; -&gt; {RootBeanDefinition@2495} &quot;Root bean: class [org.springframework.aop.aspectj.AspectJPointcutAdvisor]; scope=; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;org.springframework.aop.config.internalAutoProxyCreator&quot; -&gt; {RootBeanDefinition@2497} &quot;Root bean: class [org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator]; scope=; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;xmlAspect&quot; -&gt; {GenericBeanDefinition@2499} &quot;Generic bean: class [cn.pisces.cloud.demo.aop.XmlAspect]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in class path resource [aop-xml.xml]&quot;&quot;pointcut&quot; -&gt; {RootBeanDefinition@2500} &quot;Root bean: class [org.springframework.aop.aspectj.AspectJExpressionPointcut]; scope=prototype; abstract=false; lazyInit=null; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null&quot;&quot;AServiceImpl&quot; -&gt; {GenericBeanDefinition@2502} &quot;Generic bean: class [cn.pisces.cloud.demo.aop.AServiceImpl]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in class path resource [aop-xml.xml]&quot; 实例化处理org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator这个类是Spring提供给开发者的AOP的核心类，就是AspectJAwareAdvisorAutoProxyCreator完成了类/接口–&gt;代理的转换过程。AspectJAwareAdvisorAutoProxyCreator是BeanPostProcessor接口的实现类，具体实现在父类AbstractAutoProxyCreator中。postProcessBeforeInitialization是一个空实现，增强代码在postProcessAfterInitialization中。 在每个Bean初始化之后，如果需要，调用AspectJAwareAdvisorAutoProxyCreator中的postProcessBeforeInitialization为Bean生成代理 跟进源码 AbstractApplicationContext#finishBeanFactoryInitialization DefaultListableBeanFactory#preInstantiateSingletons AbstractBeanFactory#doGetBean AbstractAutowireCapableBeanFactory#createBean AbstractAutowireCapableBeanFactory#doCreateBean AbstractAutowireCapableBeanFactory#initializeBean AbstractAutowireCapableBeanFactory#applyBeanPostProcessorsAfterInitialization，其中有一个processor就是AspectJAwareAdvisorAutoProxyCreator AbstractAutoProxyCreator#postProcessAfterInitialization AbstractAutoProxyCreator#wrapIfNecessary 进入wrapIfNecessary 1234567891011121314151617181920212223242526protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) { if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) { return bean; } if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) { return bean; } if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) { this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; } // Create proxy if we have advice. // 这里会把所有Advices实例化到IOC中 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) { this.advisedBeans.put(cacheKey, Boolean.TRUE); Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; } this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;} 123456789101112131415161718192021222324252627// 因为配置文件里面有很多Bean，肯定不能对每个Bean都生成代理，因此需要一套规则判断Bean是不是需要生成代理@Override@Nullableprotected Object[] getAdvicesAndAdvisorsForBean( Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) { List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) { return DO_NOT_PROXY; } return advisors.toArray();}protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) { // 寻找候选Advisors, 在XML解析的时候已经被转换生成了RootBeanDefinition会被注入到IOC中 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 寻找可以使用的Advisor // 1. 目标类必须满足expression的匹配规则 // 2. 目标类中的方法必须满足expression的匹配规则，当然这里方法不是全部需要满足expression的匹配规则，有一个方法满足即可 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); // 向候选Advisor链的开头添加一个org.springframework.aop.support.DefaultPointcutAdvisor extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) { eligibleAdvisors = sortAdvisors(eligibleAdvisors); } return eligibleAdvisors;} 这时候回到wrapIfNecessary的Object proxy = createProxy(bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); 1234567891011121314151617181920212223242526272829303132protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) { if (this.beanFactory instanceof ConfigurableListableBeanFactory) { AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); } // 创建代理工厂 ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); // 判断的内容是&lt;aop:config&gt;这个节点中proxy-target-class=&quot;false&quot;或者proxy-target-class不配置，即不使用CGLIB生成代理 if (!proxyFactory.isProxyTargetClass()) { if (shouldProxyTargetClass(beanClass, beanName)) { proxyFactory.setProxyTargetClass(true); } else { // 这些接口Class对象都添加到ProxyFactory中 evaluateProxyInterfaces(beanClass, proxyFactory); } } // 向ProxyFactory中添加一些参数, 略 Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) { proxyFactory.setPreFiltered(true); } // 实际代理对象 return proxyFactory.getProxy(getProxyClassLoader());} 123public Object getProxy(@Nullable ClassLoader classLoader) { return createAopProxy().getProxy(classLoader);} createAopProxy默认使用JdkDynamicAopProxy，三种情况除外： ProxyConfig的isOptimize方法为true，这表示让Spring自己去优化而不是用户指定 ProxyConfig的isProxyTargetClass方法为true，这表示配置了proxy-target-class=”true” ProxyConfig满足hasNoUserSuppliedProxyInterfaces方法执行结果为true，这表示对象没有实现任何接口或者实现的接口是SpringProxy接口 来看一下JdkDynamicAopProxy#getProxy的实现 123456789101112@Overridepublic Object getProxy(@Nullable ClassLoader classLoader) { if (logger.isTraceEnabled()) { logger.trace(&quot;Creating JDK dynamic proxy: &quot; + this.advised.getTargetSource()); } // 拿到所有要代理的接口 Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); // 尝试寻找这些接口方法里面有没有equals方法和hashCode方法，同时都有的话打个标记，寻找结束，equals方法和hashCode方法有特殊处理 findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); // 获取接口/类对应的代理对象，Proxy是JDK原生支持的生成代理的方式 return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);} 由于JdkDynamicAopProxy本身实现了InvocationHandler接口，因此具体代理前后处理的逻辑在invoke方法中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100@Override@Nullablepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try { // 表示equals方法与hashCode方法即使满足expression规则，也不会为之产生代理内容，调用的是JdkDynamicAopProxy的equals方法与hashCode方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) { // The target does not implement the equals(Object) method itself. return equals(args[0]); } else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) { // The target does not implement the hashCode() method itself. return hashCode(); } // 表示方法所属的Class是一个接口并且方法所属的Class是AdvisedSupport的父类或者父接口，直接通过反射调用该方法 else if (method.getDeclaringClass() == DecoratingProxy.class) { // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); } // 判断是否将代理暴露出去的，由&lt;aop:config&gt;标签中的expose-proxy=&quot;true/false&quot;配置 else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) { // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); } Object retVal; if (this.advised.exposeProxy) { // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; } // Get as late as possible to minimize the time we &quot;own&quot; the target, // in case it comes from a pool. target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // Get the interception chain for this method. // 获取AdvisedSupport中的所有拦截器和动态拦截器列表，用于拦截方法，具体到我们的实际代码. 这时候存在6个 // 0 = {ExposeInvocationInterceptor@2756} // 1 = {AspectJAfterThrowingAdvice@2757} &quot;org.springframework.aop.aspectj.AspectJAfterThrowingAdvice: advice method [public void cn.pisces.cloud.demo.aop.XmlAspect.doAfterThrowing(java.lang.Exception)]; aspect name 'xmlAspect'&quot; // 2 = {AfterReturningAdviceInterceptor@2758} // 3 = {AspectJAfterAdvice@2759} &quot;org.springframework.aop.aspectj.AspectJAfterAdvice: advice method [public void cn.pisces.cloud.demo.aop.XmlAspect.doAfter()]; aspect name 'xmlAspect'&quot; // 4 = {AspectJAroundAdvice@2434} &quot;org.springframework.aop.aspectj.AspectJAroundAdvice: advice method [public java.lang.Object cn.pisces.cloud.demo.aop.XmlAspect.doAround(org.aspectj.lang.ProceedingJoinPoint) throws java.lang.Throwable]; aspect name 'xmlAspect'&quot; // 5 = {MethodBeforeAdviceInterceptor@2760} List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. // 如果拦截器列表为空，很正常，因为某个类/接口下的某个方法可能不满足expression的匹配规则，因此此时通过反射直接调用该方法 if (chain.isEmpty()) { // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); } else { // We need to create a method invocation... // 如果拦截器列表不为空，按照注释的意思，需要一个ReflectiveMethodInvocation，并通过proceed方法对原方法进行拦截 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); } // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) { // Special case: it returned &quot;this&quot; and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; } else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) { throw new AopInvocationException( &quot;Null return value from advice does not match primitive return type for: &quot; + method); } return retVal; } finally { if (target != null &amp;&amp; !targetSource.isStatic()) { // Must have come from TargetSource. targetSource.releaseTarget(target); } if (setProxyContext) { // Restore old proxy. AopContext.setCurrentProxy(oldProxy); } }} MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);这里我们看一下invocation有什么 1234567891011121314proxy = {$Proxy6@2381} &quot;cn.pisces.cloud.demo.aop.AServiceImpl@674bd420&quot;target = {AServiceImpl@2232} method = {Method@2382} &quot;public abstract java.lang.String cn.pisces.cloud.demo.aop.AService.fooA(java.lang.String)&quot;arguments = {Object[1]@2383} targetClass = {Class@2228} &quot;class cn.pisces.cloud.demo.aop.AServiceImpl&quot;userAttributes = nullinterceptorsAndDynamicMethodMatchers = {ArrayList@2836} size = 6 0 = {ExposeInvocationInterceptor@2883} 1 = {AspectJAfterThrowingAdvice@2884} &quot;org.springframework.aop.aspectj.AspectJAfterThrowingAdvice: advice method [public void cn.pisces.cloud.demo.aop.XmlAspect.doAfterThrowing(java.lang.Exception)]; aspect name 'xmlAspect'&quot; 2 = {AfterReturningAdviceInterceptor@2885} 3 = {AspectJAfterAdvice@2886} &quot;org.springframework.aop.aspectj.AspectJAfterAdvice: advice method [public void cn.pisces.cloud.demo.aop.XmlAspect.doAfter()]; aspect name 'xmlAspect'&quot; 4 = {AspectJAroundAdvice@2887} &quot;org.springframework.aop.aspectj.AspectJAroundAdvice: advice method [public java.lang.Object cn.pisces.cloud.demo.aop.XmlAspect.doAround(org.aspectj.lang.ProceedingJoinPoint) throws java.lang.Throwable]; aspect name 'xmlAspect'&quot; 5 = {MethodBeforeAdviceInterceptor@2888} currentInterceptorIndex = -1 之后invocation.proceed(); 1234567891011121314151617181920212223242526272829303132@Override@Nullablepublic Object proceed() throws Throwable { // We start with an index of -1 and increment early. if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) { return invokeJoinpoint(); } // 使用下标获取chain，之后下标+1 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) { // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) { return dm.interceptor.invoke(this); } else { // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. return proceed(); } } else { // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); }} 第一次肯定是ExposeInvocationInterceptor，直接invoke。里面没有实现什么逻辑，直接继续调用MethodInvocation的proceed()。之后就是每次调用完chain里面的proceed()。最后每个chain链调用完了进入invokeJoinpoint()，这个方法就是调用原方法的逻辑（没有加强的原来逻辑），之后再一层层返回。 所有通知调用完之后调用本身逻辑, 之前调用调用的advice只是为了指定通知执行顺序, 把链中的执行顺序逻辑罗列清楚, 按照具体的方法进行返回操作.执行完本身逻辑之后又按照原路返回回去 ReflectiveMethodInvocation使用interceptorsAndDynamicMethodMatchers保存了chain的引用, 链条顺序由AspectJAwareAdvisorAutoProxyCreator#sortAdvisors决定(topo-sort拓扑排序). 每次顺序不一定一致. 为什么不能用硬编码直接确定顺序, 比如自定义一个不就能在硬编码中使用, 因为更灵活 主流程 解析aop:config节点 1.1 DefaultListableBeanFactory中注册AspectJAwareAdvisorAutoProxyCreator 1.2 解析aop:aspect 1.2.1 解析&lt;aop:before&gt;、&lt;aop:after&gt;、&lt;aop:after-returning&gt;、&lt;aop:after-throwing method=&quot;&quot;&gt;、&lt;aop:around method=&quot;&quot;&gt; 1234567RootBeanDefinition// 1. before对应AspectJMethodBeforeAdvice// 2. After对应AspectJAfterAdvice// 3. after-returning对应AspectJAfterReturningAdvice// 4. after-throwing对应AspectJAfterThrowingAdvice// 5. around对应AspectJAroundAdvice再次包装AspectJPointcutAdvisor，注册为org.springframework.aop.aspectj.AspectJPointcutAdvisor#0、org.springframework.aop.aspectj.AspectJPointcutAdvisor#1 1.2.2 解析&lt;aop:pointcut&gt; RootBeanDefinition AspectJExpressionPointcut getBean调用postProcessBeforeInitialization 2.1 查找符合条件的Advisors，找到之后再chain开头添加DefaultPointcutAdvisor 2.2 判断使用JDK代理还是CGLIB代理 2.3 递归调用chain链的invocation.proceed() 参考：https://cloud.tencent.com/developer/article/1497770https://www.cnblogs.com/xrq730/p/6753160.htmlhttps://blog.csdn.net/weixin_43767015/article/details/109851001","link":"/blog/2021/05/04/spring-3.aop/"},{"title":"mysql-死锁","text":"mysql死锁 select version();8.0.16 模拟 12345678// 窗口1，这时候锁住user_id = 1start transaction;update sys_user set username='aaa' where user_id = 1;// 窗口2，等待user_id = 1锁释放，死锁start transaction;update sys_user set username='aaa' where user_id = 1; 12345678// 查看当前的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;// 查看当前锁定的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;SELECT * FROM performance_schema.data_locks; -- 8.0以上// 查看当前等锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; SELECT * FROM performance_schema.data_lock_waits; -- 8.0以上 123456789// 查看死锁等待时间，默认50sshow GLOBAL VARIABLES like '%innodb_lock_wait_timeout%';// 设置大小值看系统情况set GLOBAL innodb_lock_wait_timeout=100;show variables like '%dead%';Variable_name Valueinnodb_deadlock_detect ON //释放开启死锁检测innodb_print_all_deadlocks OFF //释放打印死锁 处理死锁 12345678910select trx_mysql_thread_id from information_schema.innodb_trx it JOIN information_schema.INNODB_LOCK_WAITS ilw on ilw.blocking_trx_id = it.trx_id;//8.0之后select trx_mysql_thread_id from information_schema.innodb_trx it JOIN performance_schema.data_lock_waits ilw on ilw.REQUESTING_ENGINE_TRANSACTION_ID = it.trx_id;kill [trx_mysql_thread_id] //kill之后事务会回滚，所以问题不大 查看死锁配置 事务中涉及多个表，或者涉及多行记录时，每个事务的操作顺序都要保持一致 添加索引减少锁住概率 避免长事务 降低事务隔离级别，例如用RC级别，降低死锁发生概率，也可以降低锁定粒度","link":"/blog/2021/05/13/mysql-A5.%E6%AD%BB%E9%94%81/"},{"title":"spring-Event源码","text":"这里我们看一下spring中事件通知机制 通常有这几种方式实现监听： IOC的bean实现ApplicationListener 1234@EventListener(classes = ApplicationEvent.class) public void listen(ApplicationEvent event) { System.out.println(&quot;@EventListener：&quot; + event); } 之后context.publishEvent(new ApplicationEvent(&quot;my event&quot;) {}); 源码在refresh中initApplicationEventMulticaster();初始化派发器 1234567891011121314151617181920protected void initApplicationEventMulticaster() { ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // 存在applicationEventMulticaster就直接取出来 if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) { this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isTraceEnabled()) { logger.trace(&quot;Using ApplicationEventMulticaster [&quot; + this.applicationEventMulticaster + &quot;]&quot;); } } else { // 派发器不存在就new一个放入IOC中 this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isTraceEnabled()) { logger.trace(&quot;No '&quot; + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + &quot;' bean, using &quot; + &quot;[&quot; + this.applicationEventMulticaster.getClass().getSimpleName() + &quot;]&quot;); } }} 在refresh中registerListeners(); 将BeanFactory监听器注册到派发器中 将类型为ApplicationListener注册到派发器中 派发器初始化之前的BeanFactory中注册的事件注册到派发器12345678910111213141516171819202122protected void registerListeners() { // Register statically specified listeners first. for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) { getApplicationEventMulticaster().addApplicationListener(listener); } // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) { getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); } // Publish early application events now that we finally have a multicaster... Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (!CollectionUtils.isEmpty(earlyEventsToProcess)) { for (ApplicationEvent earlyEvent : earlyEventsToProcess) { getApplicationEventMulticaster().multicastEvent(earlyEvent); } }} 123456789101112131415161718192021222324252627282930313233343536protected void publishEvent(Object event, @Nullable ResolvableType eventType) { Assert.notNull(event, &quot;Event must not be null&quot;); // Decorate event as an ApplicationEvent if necessary ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) { applicationEvent = (ApplicationEvent) event; } else { applicationEvent = new PayloadApplicationEvent&lt;&gt;(this, event); if (eventType == null) { eventType = ((PayloadApplicationEvent&lt;?&gt;) applicationEvent).getResolvableType(); } } // Multicast right now if possible - or lazily once the multicaster is initialized // 是否延迟多播，即将事件发布到所有监听器中 if (this.earlyApplicationEvents != null) { this.earlyApplicationEvents.add(applicationEvent); } else { // 此处为事件监听处理器的调用关键 getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); } // Publish event via parent context as well... // 是否将事件发布到父容器中 if (this.parent != null) { if (this.parent instanceof AbstractApplicationContext) { ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); } else { this.parent.publishEvent(event); } }} ApplicationEventMulticaster默认实现SimpleApplicationEventMulticaster来触发事件的监听，关键方法为multicastEvent()方法 1234567891011121314151617181920@Overridepublic void multicastEvent(final ApplicationEvent event, ResolvableType eventType) { // 获取事件类型 ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) {//依次遍历事件监听器 // 获取线程池 Executor executor = getTaskExecutor(); if (executor != null) {//线程池不为null，则异步调用监听器 executor.execute(new Runnable() { @Override public void run() { invokeListener(listener, event); } }); } else {// 同步调用监听器 invokeListener(listener, event); } }} spring内置了几个Event，ContextRefreshedEvent、ContextStartedEvent、ContextStoppedEvent、ContextClosedEvent内部会自己调用，比如AbstractApplicationContext#finishRefresh中publishEvent(new ContextRefreshedEvent(this));","link":"/blog/2021/05/07/spring-5.event/"},{"title":"ioc注入方式","text":"包扫描+@Component @Import @Import直接导入 ImportSelector：返回需要导入的组件的全类名数组 ImportBeanDefinitionRegistrar：手动注册bean到容器中 @Import12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;cn.pisces.cloud.demo&quot;/&gt; &lt;context:annotation-config/&gt;&lt;/beans&gt; 12345678910@Configuration@Import({ A.class, B.class })public class MainConfig {}ApplicationContext context = new ClassPathXmlApplicationContext(&quot;ioc.xml&quot;);String[] definitionNames = context.getBeanDefinitionNames();for (String name : definitionNames) { System.out.println(name);} ImportSelector1234567891011@Configuration@Import(MyImportSelector.class)public class MainConfig {}public class MyImportSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { return new String[]{A.class.getName(), B.class.getName()}; }} ImportBeanDefinitionRegistrar12345678910111213@Configuration@Import(MyImportBeanDefinitionRegistrar.class)public class MainConfig {}public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { RootBeanDefinition beanDefinition = new RootBeanDefinition(A.class); registry.registerBeanDefinition(A.class.getName(), beanDefinition); }} https://mingyang.blog.csdn.net/article/details/108861915https://blog.csdn.net/woshilijiuyi/article/details/85268659这三个方式都可以注入A，B","link":"/blog/2018/01/05/spring-a1.ioc%E6%B3%A8%E5%85%A5%E6%96%B9%E5%BC%8F/"},{"title":"springcloud-OAuth2理解","text":"OAuth2理解 参考文章 https://www.cnblogs.com/xuwenjin/p/12669791.html https://blog.csdn.net/qq_35755863/article/details/93025305 https://zhuanlan.zhihu.com/p/164688581 https://www.iocoder.cn/Spring-Security/laoxu/OAuth2-2/ 流程 重要类： TokenEndpoint存在/oauth/token逻辑 CheckTokenEndpoint存在/oauth/check_token逻辑 AuthorizationEndpoint存在/oauth/authorize逻辑 TokenStore保存token的接口 TokenEnhancertoken增强器 资源校验流程OAuth2AuthenticationProcessingFilter#doFilter -&gt; OAuth2AuthenticationManager#authenticate -&gt; DefaultTokenServices#loadAuthentication RemoteTokenServices用于向远程认证服务器验证token，同时获取token对应的用户的信息，只有资源服务器的时候会自动注入。而DefaultTokenServices用于存在的默认url使用，如/oauth/token等 验证client信息的时候AbstractUserDetailsAuthenticationProvider#authenticate,我这里继承了PiscesClientDetailsServiceImpl extends JdbcClientDetailsService所以使用的是DaoAuthenticationProvider AuthenticationManager顶级身份管理者，只有一个authenticate接口。实现类一般是ProviderManager，里面内部维护了一个List&lt;AuthenticationProvider&gt; providers。 AuthenticationProvider就是用来验证身份的，比如有DaoAuthenticationProvider等。里面list只要有一个验证成功就成功了 请求/oauth/token之前会先到ClientCredentialsTokenEndpointFilter拦截器将client的id+secret封装成UsernamePasswordAuthenticationToken AuthorizationServerTokenServices用于创建刷新token，一般实现是DefaultTokenServices。 注意 如果要使用密码模式，必须得配置AuthenticationManager(原因可查看源码AuthorizationServerEndpointsConfigurer的getDefaultTokenGranters方法) token模式默认存储在内存中，服务重启后就没了 如果使用的是PasswordEncoderFactories.createDelegatingPasswordEncoder();密码模式， 传递参数必须原生密码。加密之后的密码需要添加{noop}类似id才能正常解密 使用1POST /oauth/authorize 授权码模式认证授权接口 密码模式 获取token 1234567891011121314151617181920postlocalhost:9999/auth/oauth/token请求Body x-www：username:adminpassword:admingrant_type:passwordscope:serverclient_id:testclient_secret:test响应：{ &quot;access_token&quot;: &quot;43615044-1dbf-4325-97e6-e797da8898f5&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;68574a10-7437-409d-b73d-660257420848&quot;, &quot;expires_in&quot;: 43199, &quot;scope&quot;: &quot;server&quot;} 检查token/获取保存token信息 12345678910111213141516171819postlocalhost:9999/auth/oauth/check_token请求Body x-www：token:462025ed-922c-451d-ac9e-c5d3881fe5b5响应：{ &quot;exp&quot;: 1616456686, &quot;user_name&quot;: &quot;$2a$10$fpCppbm.QQBXFlZfp.0CYOhG0Uzv6RWCPZA0T1dSV2d3ZUiWFWfQW&quot;, &quot;authorities&quot;: [ &quot;ROLE_1&quot; ], &quot;client_id&quot;: &quot;pig&quot;, &quot;scope&quot;: [ &quot;server&quot; ]} 资源获取 1localhost:9999/auth/AuthApplication?access_token=25d48425-75b5-4e77-a8d4-fcdb8e9cdaa8","link":"/blog/2017/06/11/springcloud-10.oauth2%E7%90%86%E8%A7%A3/"},{"title":"springcloud-入门学习","text":"最近在学SpringCloud, 所以还是记录一下. 所有的都是基于Finchley版本. 这个版本的SpringBoot必须2.0以上 官方网址 核心 服务治理 服务注册 服务发现 服务注销 服务状态监控 负载均衡 服务网关 微服务映射 服务路由管理 请求过滤 AB测试 金丝雀测试 微服务容错 服务降级 熔断机制 超时管理 回退机制 服务限流 微服务通信 基于RESTful协议 消息中间件整合 发布-订阅模式 远程事件 微服务监控 日志聚合 日志监控 调用链监控 可视化分析 健康检查 Metrics监控 统一配置 加载与刷新 配置存储 版本管理 加密与解密 微服务安全 Session管理 单点登录 OAuth认证 JWT授权 微服务部署与编排 Docker K8s 服务编排 自动发布 application 和 bootstrap区别SpringCloud默认配置文件有application.yml和bootstrap.yml, 当然还有properties格式的, 但是其实只是格式区别, 其他的一样. 执行顺序 bootstrap.yml用来程序引导时执行，应用于更加早期配置信息读取，如可以使用来配置application.yml中使用到参数等 application.yml应用程序特有配置信息，可以用来配置后续各个模块中需使用的公共参数等。 bootstrap.yml 先于 application.yml 加载 配置区别 bootstrap.yml 可以理解成系统级别的一些参数配置，这些参数一般是不会变动的。 application.yml 可以用来定义应用级别的，如果搭配 spring-cloud-config 使用 application.yml 里面定义的文件可以实现动态替换。 bootstrap.yml必须放程序启动前就需要的参数, 比如mysql连接.如果没有这种放在application.yml就启动失败了 使用Spring Cloud Config Server时，应在 bootstrap.yml 中指定 spring.application.name spring.cloud.config.server.git.uri 一些加密/解密信息 因为ConfigServer的配置信息肯定要早于其他的配置信息早加载.","link":"/blog/2017/06/01/springcloud-1.%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"},{"title":"springcloud-Eureka","text":"Eureka 是 Netflix 出品的用于实现服务注册和发现的工具。 Spring Cloud 集成了 Eureka，并提供了开箱即用的支持。其中， Eureka 又可细分为 Eureka Server 和 Eureka Client。 简介基本原理服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者地址，然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存中取，完成一次调用。 当服务注册中心Eureka Server检测到服务提供者因为宕机、网络原因不可用时，则在服务注册中心将服务置为DOWN状态，并把当前服务提供者状态向订阅者发布，订阅过的服务消费者更新本地缓存。 服务提供者在启动后，周期性（默认30秒）向Eureka Server发送心跳，以证明当前服务是可用状态。Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，则认为服务宕机，注销该实例。 服务注册Register服务提供者也是一个Eureka客户端, 启动时会Eureka会提供服务注册相关方法, 向Eureka注册自己的信息. 同时Eureka会维护一个HashMap保存信息, 一层为应用名称对应的服务实例, 二层为服务器实例及注册信息 服务续约Renewclient默认每隔30秒发送一次心跳, 作用是更新自身状态, 在同步到其他Eureka服务节点.对于server来说, 默认3次没有收到客户端心跳, 就从列表中剔除. 不过如果Eureka处于自我保护模式, 就不会清楚该服务实例信息.属性值为这两个, 但是官方不建议我们修改 12eureka.instance.lease-renewal-interval-in-seconds=30eureka.instance.lease-expiration-duration-in-seconds=30 服务下线与剔除实例关闭时, client会给Eureka发送服务下线请求. 发送请求后, 该服务实力信息会从Eureka实例注册列表中删除 获取服务client在启动时会从Eureka中获取注册表信息, 并将其缓存在本地. Eureka客户端会使用改信息查找相应的服务, 并调用. 默认30s从Eureka服务器同步. 默认使用压缩的Json格式来注册列表信息. 自我保护模式就是宁可保留错误注册信息, 也不能盲目注销任何可能健康的服务实例. 这个模式默认开启, 在控制台会有一行红字显示警告信息.可以通过eureka-server.enable-self-preservation=false来禁用该模式 手动指定ip默认情况Eureka客户端会使用Spring框架中InterUtils.findFirstNonLoopbackAddress()来获取服务实例所在宿主服务器主机的ip地址, 如果宿主服务器有多个网卡, 获取到的ip不是想要的, 可以手动指定一个ip. 12eureka.instance.prefer-ip-address=trueeureka.instance.ip-address=192.168.1.1 Eureka服务访问安全默认只要启动8761端口就可以看到管理界面了, 我们可以添加用户认证 添加Maven 12345&lt;!--security--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置信息 12345spring: security: user: name: username password: password 主要修改连接链接defaultZone: http://username:password@${eureka.instance.hostname}:${server.port}/eureka/ 配置/actuator/**路径不要验证, 必须关闭csrf 1234567891011@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests() .antMatchers(&quot;/actuator/**&quot;).permitAll() .anyRequest() .authenticated().and().httpBasic(); }} 和Zookeeper区别著名的CAP理论指出，一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。在此Zookeeper保证的是CP, 而Eureka则是AP。 高可用实例操作根Maven12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;jingrui.com&lt;/groupId&gt; &lt;artifactId&gt;pilafking&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;modules&gt; &lt;module&gt;server-eureka&lt;/module&gt; &lt;module&gt;logic-category&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; Eureka服务端maven1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;pilafking&lt;/artifactId&gt; &lt;groupId&gt;jingrui.com&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;server-eureka&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- Eureka的server服务器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--security--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849---server: port: 8761spring: profiles: peer1 application: name: cloud-eurka-server cloud: config: enabled: false security: user: name: root password: rooteureka: instance: hostname: peer1 client: fetch-registry: false register-with-eureka: false serviceUrl: defaultZone: http://root:root@peer2:8762/eureka/---server: port: 8762spring: profiles: peer2 application: name: cloud-eurka-server cloud: config: enabled: false security: user: name: root password: rooteureka: instance: hostname: peer2 client: fetch-registry: false register-with-eureka: false serviceUrl: defaultZone: http://root:root@peer1:8761/eureka/ EurekaServerApplication123456789101112131415package server.eureka;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServer //必须加上这个public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run( EurekaServerApplication.class, args ); }} 添加配置WebSecurityConfig12345678910111213141516171819package server.eureka.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@Configurationpublic class WebSecurityConfig { @EnableWebSecurity public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests().anyRequest().authenticated().and().httpBasic().and().csrf().disable(); } }} Eureka客户端maven1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;pilafking&lt;/artifactId&gt; &lt;groupId&gt;jingrui.com&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;logic-category&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- Eureka的client --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml123456789101112server: port: 8771spring: application: name: logic-category# 添加eureka的地址信息, registerWithEureka和fetchRegistry默认为trueeureka: client: service-url: defaultZone: http://root:root@peer1:8761/eureka/,http://root:root@peer2:8762/eureka/ LogicCategoryApplication123456789101112131415package logic.category;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@EnableEurekaClient@SpringBootApplicationpublic class LogicCategoryApplication { public static void main(String[] args) { SpringApplication.run( LogicCategoryApplication.class, args); }} 注意启动这边配置一个两个Application, Program arguments为--spring.profiles.active=peer2 之后浏览器http://peer1:8761/,http://peer2:8762/","link":"/blog/2017/06/02/springcloud-2.eureka/"},{"title":"springcloud-Zuul","text":"Zuul作为微服务系统的网关组件，用于构建边界服务，致力于动态路由、过滤、监控、弹性伸缩和安全。 优点: Zuul、Ribbon以及Eureka结合可以实现智能路由和负载均衡的功能； 网关将所有服务的API接口统一聚合，统一对外暴露。外界调用API接口时，不需要知道微服务系统中各服务相互调用的复杂性，保护了内部微服务单元的API接口； 网关可以做用户身份认证和权限认证，防止非法请求操作API接口； 网关可以实现监控功能，实时日志输出，对请求进行记录； 网关可以实现流量监控，在高流量的情况下，对服务降级；API接口从内部服务分离出来，方便做测试。 Zuul通过Servlet来实现，通过自定义的ZuulServlet来对请求进行控制。核心是一系列过滤器，可以在Http请求的发起和响应返回期间执行一系列过滤器。Zuul采取了动态读取、编译和运行这些过滤器。过滤器之间不能直接通信，而是通过RequestContext对象来共享数据，每个请求都会创建一个RequestContext对象。 生命周期: 当一个客户端Request请求进入Zuul网关服务时，网关先进入”pre filter“，进行一系列的验证、操作或者判断。 然后交给”routing filter“进行路由转发，转发到具体的服务实例进行逻辑处理、返回数据。 当具体的服务处理完成后，最后由”post filter“进行处理，该类型的处理器处理完成之后，将Request信息返回客户端。 pom.xml 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- zuul网关 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; Application启动类使用注解@EnableZuulProxy开启网关代理 bootstrap.yml配置 123456789zuul: routes: categoryapi: path: /category/** # 默认为true, true就是去掉category前缀 stripPrefix: false # 千万注意, 这里需要在eureka.instance.instance-id=${spring.application.name}自定义 serviceId: logic-category # prefix: /v1 # 会在所有api前加一个接口 http://localhost:8880/v1/category/list 含义就是我们请求/category/**路径, 就直接转发到logic-category服务上去了. serviceId就是服务名称, 如果不填默认就是categoryapi这里填写的名称. 而且zuul默认自动负载均衡 可以在Application启动类中注解一个BeanPreFilter过滤器 1234@Beanpublic PreFilter preFilter() { return new PreFilter();} 内容为: 123456789101112131415161718192021222324252627282930313233public class PreFilter extends ZuulFilter { private static Logger log = LoggerFactory.getLogger(PreFilter.class); @Override public String filterType() { // Zuul内置的filter类型有四种，pre, route，post，error，分别代表请求处理前，处理时，处理后和出错后 return &quot;pre&quot;; } @Override public int filterOrder() { //指定了该过滤器执行的顺序 return 1; } @Override public boolean shouldFilter() { //是否开启此过滤器 return true; } @Override public Object run() throws ZuulException { //过滤器的业务逻辑 RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); log.info(String.format(&quot;%s 方式请求 %s&quot;, request.getMethod(), request.getRequestURL().toString())); return null; }} 感谢","link":"/blog/2017/06/03/springcloud-3.zuul/"},{"title":"springcloud-RestTemplate+Ribbon","text":"RestTemplate主要用于网络请求, Ribbon主要用于负载均衡 负载均衡是分布式的重点, 决定了整个服务集群的性能与稳定. 这边直接来说下Ribbon Ribbon是Netflix下的负载均衡项目, 主要实现中间层应用程序的负债均衡. 使用Spring自带的RestTemplate请求 特性: 支持插拔式的负债均衡规则 对多协议提供支持, 如HTTP/TCP/UDP 集成了负债均衡功能的客户端 Ribbon主要有三大子模块: ribbon-core: 核心, 包括负载均衡器接口定义, 客户端接口定义, 内置的负债均衡实现等API ribbon-eureka: 为Eureka客户端提供的负债均衡实现类 ribbon-httpclient: 对Apache的HttpClient进行封装, 提供了含有负载均衡功能的REST客户端 7种负载均衡策略: BestAvailableRule: 选择一个最小的并发请求的server. 逐个考察Server，如果Server被tripped了，则忽略，在选择其中ActiveRequestsCount最小的server AvailabilityFilteringRule: 过滤掉那些因为一直连接失败的被标记为circuit tripped的后端server，并过滤掉那些高并发的的后端server（active connections 超过配置的阈值）.使用一个AvailabilityPredicate来包含过滤server的逻辑，其实就就是检查status里记录的各个server的运行状态 WeightedResponseTimeRule: 根据响应时间分配一个weight，响应时间越长，weight越小，被选中的可能性越低。一个后台线程定期的从status里面读取评价响应时间，为每个server计算一个weight。Weight的计算也比较简单responsetime 减去每个server自己平均的responsetime是server的权重。当刚开始运行，没有形成status时，使用roubine策略选择server。 RetryRule: 对选定的负载均衡策略机上重试机制。在一个配置时间段内当选择server不成功，则一直尝试使用subRule的方式选择一个可用的server RoundRobinRule: roundRobin方式轮询选择server. 轮询index，选择index对应位置的server RandomRule: 随机选择一个server. 在index上随机，选择index对应位置的server ZoneAvoidanceRule: 复合判断server所在区域的性能和server的可用性选择server. 使用ZoneAvoidancePredicate和AvailabilityPredicate来判断是否选择某个server，前一个判断判定一个zone的运行性能是否可用，剔除不可用的zone（的所有server），AvailabilityPredicate用于过滤掉连接数过多的Server。 修改方式 配置文件123logic-category: ribbon: NFLoadBalancerRuleClassName:com.netflix.loadbalancer.RandomRule 通过java注解配置12345678@Configurationpublic class RibbonConfiguration{ @Bean public IRule ribbonRule(){ //随机负载 return new RandomRule(); }} 通过注解@RibbonClient为特定的服务配置负载均衡策略1234@Configuration@RibbonClient(name=&quot;hello&quot;, configuration=RibbonConfiguration.class)public class TestRibbonConfiguration{} 没有使用Eureka1234567891011ribbon: eureka: enabled: falseuser-provider: ribbon: listOfServers: localhost:8080user-provider-2: ribbon: listOfServers: localhost:8083,localhost:8082 以上配置都是在服务消费者中配置。 例子这边注册中心就忽略不写了, 就直接两个client来实现 logic-wallpapermaven 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;pilafking&lt;/artifactId&gt; &lt;groupId&gt;jingrui.com&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;logic-wallpaper&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- Eureka的client --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 这边写一个测试controller 123456789@RestController@RequestMapping(value = &quot;/wallpaper&quot;)public class WallpaperController { @GetMapping(value = &quot;/test&quot;) public String test() { return &quot;this is WallpaperController return !&quot;; }} logic-category现在用logic-category来调用 maven 12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;pilafking&lt;/artifactId&gt; &lt;groupId&gt;jingrui.com&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;logic-category&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- Eureka的client --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 写一个service调用 12345678910@Servicepublic class CmsCategoryService { @Autowired private RestTemplate restTemplate; public String getPort() { return restTemplate.getForObject(&quot;http://LOGIC-WALLPAPER/wallpaper/test&quot;, String.class); }} 测试类 1234567891011121314151617181920212223242526@RunWith(SpringRunner.class)@SpringBootTest//由于是Web项目，Junit需要模拟ServletContext，因此我们需要给我们的测试类加上@WebAppConfiguration。@WebAppConfigurationpublic class MyServiceTest { @Autowired private CmsCategoryService cmsCategoryService; @Before public void init() { System.out.println(&quot;开始测试-----------------&quot;); } @After public void after() { System.out.println(&quot;测试结束-----------------&quot;); } @Test public void testGetEntFileById(){ String port = cmsCategoryService.getPort(); System.out.println(&quot;port:&quot;+port); }} RestTemplate相关API请看这里https://juejin.im/post/5b717eab6fb9a0096e21cc24","link":"/blog/2017/06/04/springcloud-4.Ribbon+RestTemplate/"},{"title":"springcloud-Hystrix","text":"断路器(Hystrix)就是避免在服务不可用时会出现线程阻塞, 此时若有大量的请求涌入，Servlet容器的线程资源会被消耗完毕，导致服务瘫痪。Netflix开源了Hystrix组件，实现了断路器模式，SpringCloud对这一组件进行了整合。 在微服务架构中，一个请求需要调用多个服务是非常常见的. 默认在20s内失败5次就会打开断路器, 进行降级处理 ribbon使用断路器 maven 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 断路器图形化界面 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; @EnableHystrix注解包含了@EnableCircuitBreaker注解, 我们只写@EnableHystrix注解开启断路器就行了 在程序的启动类ServiceRibbonApplication 加@EnableHystrix注解开启Hystrix 1234567891011121314151617@SpringBootApplication@EnableEurekaClient@EnableHystrix # 开启断路器@EnableHystrixDashboard # 开启断路器仪表盘public class ServiceRibbonApplication { public static void main(String[] args) { SpringApplication.run( ServiceRibbonApplication.class, args ); } @Bean @LoadBalanced RestTemplate restTemplate() { return new RestTemplate(); }} 在Service方法上加上@HystrixCommand注解。该注解对该方法创建了熔断器的功能，并指定了fallbackMethod熔断方法，熔断方法直接返回了一个字符串 12345678910111213141516@Servicepublic class HelloService { @Autowired RestTemplate restTemplate; @HystrixCommand(fallbackMethod = &quot;hiError&quot;) public String hiService(String name) { return restTemplate.getForObject(&quot;http://SERVICE-HI/hi?name=&quot;+name,String.class); } public String hiError(String name) { return &quot;hi,&quot;+name+&quot;,sorry,error!&quot;; }} Feign中使用断路器Feign是自带断路器的，在D版本的Spring Cloud之后，它没有默认打开。需要在配置文件中配置打开它，在配置文件加以下代码： 123feign: hystrix: enabled: true 需要在FeignClient的的注解中加上fallback的指定类就行了 123456@FeignClient(value = &quot;logic-system&quot;, fallback = CategoryHystrix.class)public interface CategoryInteractor { @GetMapping(&quot;/test&quot;) String test();} CategoryHystrix需要实现CategoryInteractor接口，并注入到Ioc容器中 12345678@Componentpublic class CategoryHystrix implements CategoryInteractor { @Override public String test() { return &quot;断路器返回的&quot;; }} 图形界面查看打开http://localhost:8762/actuator/hystrix.stream打开locahost:8762/hystrix 可以看见以下界面： 当我们有很多个服务的时候，这就需要聚合所以服务的Hystrix Dashboard的数据了。这就需要用到Spring Cloud的另一个组件了，即Hystrix Turbine。https://blog.csdn.net/forezp/article/details/81041125","link":"/blog/2017/06/05/springcloud-5.hystrix/"},{"title":"springcloud-Feign","text":"Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。 使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果。 Feign 采用的是基于接口的注解 Feign 整合了ribbon，具有负载均衡的能力 整合了Hystrix，具有熔断的能力 实例 maven中spring-cloud-starter-netflix-ribbon换成spring-cloud-starter-openfeign application 12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClients # 开启Feignpublic class LogicCategoryApplication { public static void main(String[] args) { SpringApplication.run(LogicCategoryApplication.class, args); }} service定义一个feign接口，通过@FeignClient(“服务名”)，来指定调用哪个服务。里面的接口就定义成和调用的controller格式一样就行了, 只是没实现的接口而已. 123456@FeignClient(value = &quot;logic-system&quot;) //value为指定服务名, path为路劲前缀public interface CategoryInteractor { @GetMapping(&quot;/test&quot;) String test();} 调用方@Autowired, idea会报错提示不能注入, 因为这个是一开始就检测的, 可以忽略. 如果调用的地址是单独编译在一个Jar包中， 和主应用不在同一个包， 那么需要用@EnableFeignClients(basePackages=&quot;com.**&quot;)指定包名 常见问题@RequetMapping中的method将请求方式指定为GET，那么所有未标注解的参数将会被忽略.注意, 如果GET请求中没有加注解, 默认会自动放到request body, 只要有body就会被当成post请求 123456@FeignClient(value = &quot;logic-system&quot;) //value为指定服务名, path为路劲前缀public interface CategoryInteractor { @GetMapping(&quot;/test&quot;) String test(@PathVariable(&quot;age&quot;) Integer age, @RequestParam(&quot;name&quot;) String name, String obj);} 此时因为声明的是GET请求没有请求体，所以obj参数就会被忽略。 更换HttpClientFeign在默认情况下使用的是JDK原生的URLConnection发送HTTP请求，没有连接池，但是对每个地址会保持一个长连接，即利用HTTP的persistence connection. 替换OkHttp maven 1234&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 12feign.httpclient.enabled=falsefeign.okhttp.enabled=true 配置 12345678910111213141516171819@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig { @Autowired OkHttpLoggingInterceptor okHttpLoggingInterceptor; @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() .readTimeout(60, TimeUnit.SECONDS) .connectTimeout(60, TimeUnit.SECONDS) .writeTimeout(120, TimeUnit.SECONDS) .connectionPool(new ConnectionPool()) // .addInterceptor(); .build(); }}","link":"/blog/2017/06/06/springcloud-6.feign/"},{"title":"springcloud-Cloud","text":"分布式配置中心(Spring Cloud Config)为分布式系统提供了配置服务器（简称服务器）和配置客户端 （简称客户端），通过对它们的配置，可以很好地管理集群中的配置文件 。 配置 spring.profiles.active可配置git(默认), subversion,native(本地文件系统中读取配置文件), vault(去Vault中读取配置文件) spring.cloud.config.server.default-label配置默认指定目录,可以已使用spring.cloud.config.label来覆盖default-label属性, 理解为分支 spring.cloud.config.name来指定读取的文件名, 如果没有这个就会使用spring.application.name来读取, 如果这个还是没有, 默认读取application.yml spring.cloud.config.profile指定读取的配置, 比如3中会读取到***-dev.yml 这个配置会去读取git目录下的label文件夹下, 叫name的文件名, 如果有profile就会在name-profile.yml 对应关系application代表配置文件名(不带后缀, 不带-后面的)profile 代表配置dev, test, prod之类的spring.cloud.config.server.git.uri：配置git仓库地址spring.cloud.config.server.git.searchPaths：配置仓库路径spring.cloud.config.label：配置仓库的分支spring.cloud.config.server.git.username：访问git仓库的用户名spring.cloud.config.server.git.password：访问git仓库的用户密码 config所有访问路径: 12345../{application}/{profile}[/{label}]../{application}-{profile}.yml../{label}/{application}-{profile}.yml../{application}-{profile}.properties../{label}/{application}-{profile}.properties 比如: /{application}/{profile}[/{label}] 访问路劲是http://localhost:${server.port}/${search-paths}/${profile}/${label} 注意: 如果任何{application} 的文件名都会默认包含application.yml的内容(如果有这个文件的话) //如果你ConfigServer配置了 spring.cloud.config.server.search-paths: springcloud-config,那么你在ConfigClient中spring.cloud.config.name: springcloud-config, 必须配置成一致. Config Server pom.xml 12345678910&lt;!-- config-server --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- eureka-client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; Application类加上@EnableConfigServer注解开启配置服务器的功能 123456789@SpringBootApplication@EnableConfigServer@EnableEurekaClientpublic class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} bootstrap.yml文件配置以下 123456789101112131415161718192021debug: @debug@server: port: 8771spring: application: name: cloud-config-server cloud: config: server: git: uri: @config.server.git.uri@ username: @config.server.git.username@ password: @config.server.git.password@ profile: @cloud.profile@eureka: client: serviceUrl: defaultZone: http://@eureka.server.hostname@:@eureka.server.port@/eureka/ Config Client pom.xml 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件application.yml 123456789101112131415161718192021debug: trueserver: port: 8900spring: application: name: logic-system cloud: config: discovery: enabled: true service-id: cloud-config-server profile: dev name: application # 指定配置文件名eureka: client: serviceUrl: defaultZone: http://@eureka.server.hostname@:@eureka.server.port@/eureka/ spring.cloud.config.label 指明远程仓库的分支spring.cloud.config.profile dev开发环境配置文件test测试环境pro正式环境spring.cloud.config.uri= http://localhost:8888/ 指明配置服务中心的网址。 当然也可以配置中心加载本地开发环境 1234567891011spring: application: name: @artifactId@ profiles: active: native # 配置中心 cloud: config: server: native: search-locations: classpath:/config/ 然后直接在config项目resources目录下新建config文件夹, 里面放入配置文件","link":"/blog/2017/06/07/springcloud-7.config/"},{"title":"springcloud-Sleuth","text":"一般的，一个分布式服务跟踪系统，主要有三部分：数据收集、数据存储和数据展示。根据系统大小不同，每一部分的结构又有一定变化。譬如，对于大规模分布式系统，数据存储可分为实时数据和全量数据两部分，实时数据用于故障排查（troubleshooting），全量数据用于系统优化；数据收集除了支持平台无关和开发语言无关系统的数据收集，还包括异步数据收集（需要跟踪队列中的消息，保证调用的连贯性），以及确保更小的侵入性；数据展示又涉及到数据挖掘和分析。 简介Spring Cloud Sleuth服务追踪的追踪单元是从客户发起请求（request）抵达被追踪系统的边界开始，到被追踪系统向客户返回响应（response）为止的过程，称为一个“trace”。每个 trace 中会调用若干个服务，为了记录调用了哪些服务，以及每次调用的消耗时间等信息，在每次调用服务时，埋入一个调用记录，称为一个“span”。这样，若干个有序的 span 就组成了一个 trace。在系统向外界提供服务的过程中，会不断地有请求和响应发生，也就会不断生成 trace，把这些带有span 的 trace 记录下来，就可以描绘出一幅系统的服务拓扑图。附带上 span 中的响应时间，以及请求成功与否等信息，就可以在发生问题的时候，找到异常的服务；根据历史数据，还可以从系统整体层面分析出哪里性能差，定位性能优化的目标。 Spring Cloud Sleuth为服务之间调用提供链路追踪。通过Sleuth可以很清楚的了解到一个服务请求经过了哪些服务，每个服务处理花费了多长。从而让我们可以很方便的理清各微服务间的调用关系。此外Sleuth可以帮助我们： 耗时分析: 通过Sleuth可以很方便的了解到每个采样请求的耗时，从而分析出哪些服务调用比较耗时; 可视化错误: 对于程序未捕捉的异常，可以通过集成Zipkin服务界面上看到; 链路优化: 对于调用比较频繁的服务，可以针对这些服务实施一些优化措施。 spring cloud sleuth可以结合zipkin，将信息发送到zipkin，利用zipkin的存储来存储信息，利用zipkin ui来展示数据。 ZipKinZipkin 是一个开放源代码分布式的跟踪系统，由Twitter公司开源，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。 每个服务向zipkin报告计时数据，zipkin会根据调用关系通过Zipkin UI生成依赖关系图，显示了多少跟踪请求通过每个服务，该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。 Zipkin提供了可插拔数据存储方式：In-Memory、MySql、Cassandra以及Elasticsearch。接下来的测试为方便直接采用In-Memory方式进行存储，生产推荐Elasticsearch。 操作新建zipkin子模块 12345678&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&lt;/dependency&gt; 启动Application上面添加@EnableZipkinServer 配置文件 123456789eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/server: port: 9000spring: application: name: zipkin-server 运行后http://localhost:9000/zipkin/访问zipkin界面 其他项目连接zipkin 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; Spring应用在监测到Java依赖包中有sleuth和zipkin后，会自动在RestTemplate的调用过程中向HTTP请求注入追踪信息，并向Zipkin Server发送这些信息。 同时配置文件中添加如下代码： 123456spring: zipkin: base-url: http://localhost:9000 sleuth: sampler: percentage: 1.0 spring.zipkin.base-url指定了Zipkin服务器的地址，spring.sleuth.sampler.percentage将采样比例设置为1.0，也就是全部都需要。 Spring Cloud Sleuth有一个Sampler策略，可以通过这个实现类来控制采样算法。采样器不会阻碍span相关id的产生，但是会对导出以及附加事件标签的相关操作造成影响。 Sleuth默认采样算法的实现是Reservoir sampling，具体的实现类是PercentageBasedSampler，默认的采样比例为: 0.1(即10%)。不过我们可以通过spring.sleuth.sampler.percentage来设置，所设置的值介于0.0到1.0之间，1.0则表示全部采集。 之后就可以访问查看一下链路追踪了 参考: 纯洁的微笑 - 使用Spring Cloud Sleuth和Zipkin进行分布式链路跟踪","link":"/blog/2017/06/08/springcloud-7.sleuth/"},{"title":"springcloud-OAuth2概述","text":"OAuth2是一种协议, 我们经常看到qq微信等等会在第三方登录的时候授权, 然后就登录成功了, 其实这就是使用OAuth2协议来实现的. 概述名词 client : 比如说就是知乎客户端 Resource Owner : 比如说就是你自己啦 Authorization Server : 授权服务器 Resource Server : 资源服务器 授权模式授权码模式 (authorization code)授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与”服务提供商”的认证服务器进行互动。 就是说你自己的api要给别人用, 一般都是用这种模式, 比如第三方登录之类的 流程 : 用户访问客户端，后者将前者导向认证服务器。 用户选择是否给予客户端授权。 假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。 客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。 A步骤中，客户端申请认证的URI，包含以下参数： response_type：表示授权类型，必选项，此处的值固定为”code” client_id：表示客户端的ID，必选项 redirect_uri：表示重定向URI，可选项 scope：表示申请的权限范围，可选项 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。 123GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com 3步骤中，服务器回应客户端的URI，包含以下参数： code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 123HTTP/1.1 302 FoundLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA &amp;state=xyz 4步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数： grant_type：表示使用的授权模式，必选项，此处的值固定为”authorization_code”。 code：表示上一步获得的授权码，必选项。 redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。 client_id：表示客户端ID，必选项。 1234567POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb 5步骤中，认证服务器发送的HTTP回复，包含以下参数： access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 123456789101112HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;, &quot;token_type&quot;:&quot;example&quot;, &quot;expires_in&quot;:3600, &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;, &quot;example_parameter&quot;:&quot;example_value&quot; } 密码模式 (resource owner password credentials)密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向”服务商提供商”索要授权。 比如自己有一套用户系统, 现在api自己给自己用, 可以使用这样的模式来实现权限的认证 流程 : 用户向客户端提供用户名和密码。 客户端将用户名和密码发给认证服务器，向后者请求令牌。 认证服务器确认无误后，向客户端提供访问令牌。 2步骤中，客户端发出的HTTP请求，包含以下参数： grant_type：表示授权类型，此处的值固定为”password”，必选项。 username：表示用户名，必选项。 password：表示用户的密码，必选项。 scope：表示权限范围，可选项。 123456POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=password&amp;username=johndoe&amp;password=A3ddj3w 3步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。 123456789101112HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;, &quot;token_type&quot;:&quot;example&quot;, &quot;expires_in&quot;:3600, &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;, &quot;example_parameter&quot;:&quot;example_value&quot; } 客户端模式 (client credentials)客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向”服务提供商”进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求”服务提供商”提供服务，其实不存在授权问题。 就是没有用户系统, 直接在数据库里面保存client的各种信息, 认证的时候就直接查看传输的用户传递的client是否正确, 只要client信息正确就认证通过. 简化模式 (implicit)简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了”授权码”这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。 一般不用 更新令牌如果用户访问的时候，客户端的”访问令牌”已经过期，则需要使用”更新令牌”申请一个新的访问令牌。 客户端发出更新令牌的HTTP请求，包含以下参数： granttype：表示使用的授权模式，此处的值固定为”refreshtoken”，必选项。 refresh_token：表示早前收到的更新令牌，必选项。 scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致 123456POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=refresh_token&amp;refresh_token=tGzv3JOkF0XG5Qx2TlKWIA 阮一峰三篇文字： OAuth2.0解释 理解OAuth 2.0 OAuth 2.0 的四种方式 还可以看一下 Spring security OAuth2 深入解析 实际操作可以借鉴 central-platform","link":"/blog/2017/06/09/springcloud-8.oauth2%E6%A6%82%E8%BF%B0/"},{"title":"springcloud-OAuth2实现","text":"OAuth2网上文章比较多, 但是实战写的比较详细的很少, 方法不知道具体什么意思. 在这里先感谢 程序员DD的从零开始的Spring Security Oauth2 代码pom.xml123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;2.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 将token存储在redis中 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; OAuth2ServerConfig这个配置ResourceServer, 哪些资源需要鉴权. 配置oauth客户端相关信息, 他会根据oauth/token请求携带的参数去比对这里配置的参数, 如果正确就认定通过. client_secret是明文传输, 然后会根据配置的加密方式去加密, 比对这边配置的secret. 配置token保存方式和用户名密码鉴别方式userDetailsService 密码加密方式: 用 BCrypt 对密码编码 String finalSecret = new BCryptPasswordEncoder().encode(&quot;123456&quot;); 支持多种编码，通过密码的前缀区分编码方式 String finalSecret = &quot;{bcrypt}&quot; + new BCryptPasswordEncoder().encode(&quot;123456&quot;); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Configurationpublic class OAuth2ServerConfig { private static final String DEMO_RESOURCE_ID = &quot;order&quot;; @Autowired private UserDetailsService userDetailsService; @Configuration @EnableResourceServer protected static class ResourceServerConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { } @Override public void configure(HttpSecurity http) throws Exception { //TODO http.authorizeRequests() .antMatchers(&quot;/product/**&quot;).permitAll() .anyRequest() .authenticated();//配置order访问控制，必须认证过后才可以访问 } } @Configuration @EnableAuthorizationServer protected class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter { @Autowired AuthenticationManager authenticationManager; @Autowired RedisConnectionFactory redisConnectionFactory; //配置oauth客户端相关信息 @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { String finalSecret = new BCryptPasswordEncoder().encode(&quot;123456&quot;); //配置两个客户端,一个用于password认证一个用于client认证 clients.inMemory().withClient(&quot;client_1&quot;) .resourceIds(DEMO_RESOURCE_ID) .authorizedGrantTypes(&quot;client_credentials&quot;, &quot;refresh_token&quot;) .scopes(&quot;select&quot;) .authorities(&quot;oauth2&quot;) .secret(finalSecret) .and().withClient(&quot;client_2&quot;) .resourceIds(DEMO_RESOURCE_ID) .authorizedGrantTypes(&quot;password&quot;, &quot;refresh_token&quot;) .scopes(&quot;select&quot;) .authorities(&quot;oauth2&quot;) .secret(finalSecret); } //配置token保存方式, 这里使用redis保存. authorizedGrantTypes为`password`的时候就需要配置userDetailsService去判断传输的用户名和密码是否正确 @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .tokenStore(new RedisTokenStore(redisConnectionFactory)) .authenticationManager(authenticationManager) //用户db查询 .userDetailsService(userDetailsService) .allowedTokenEndpointRequestMethods(HttpMethod.GET, HttpMethod.POST); } @Override public void configure(AuthorizationServerSecurityConfigurer oauthServer) { //允许表单认证 oauthServer.allowFormAuthenticationForClients(); } }} SecurityConfiguration1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Configuration@EnableWebSecuritypublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {// @Override// protected void configure(AuthenticationManagerBuilder auth) throws Exception {// auth.inMemoryAuthentication().passwordEncoder(new BCryptPasswordEncoder());// }//这里是内存保存用户名和密码的操作方式/* @Bean @Override protected UserDetailsService userDetailsService(){ BCryptPasswordEncoder bCryptPasswordEncoder = new BCryptPasswordEncoder(); String finalPassword = &quot;{bcrypt}&quot;+bCryptPasswordEncoder.encode(&quot;123456&quot;); InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(&quot;user_1&quot;).password(finalPassword).authorities(&quot;USER&quot;).build()); manager.createUser(User.withUsername(&quot;user_2&quot;).password(finalPassword).authorities(&quot;USER&quot;).build()); return manager; }*///这里配置的是前面对应的加密方式// password 方案一：明文存储，用于测试，不能用于生产// @Bean// PasswordEncoder passwordEncoder(){// return NoOpPasswordEncoder.getInstance();// }// password 方案二：用 BCrypt 对密码编码// @Bean// PasswordEncoder passwordEncoder(){// return new BCryptPasswordEncoder();// } // password 方案三：支持多种编码，通过密码的前缀区分编码方式,推荐 @Bean PasswordEncoder passwordEncoder(){// return PasswordEncoderFactories.createDelegatingPasswordEncoder(); return new BCryptPasswordEncoder(); }//// /**// * 这一步的配置是必不可少的，否则SpringBoot会自动配置一个AuthenticationManager,覆盖掉内存中的用户// */ @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { AuthenticationManager manager = super.authenticationManagerBean(); return manager; } @Override protected void configure(HttpSecurity http) throws Exception { // @formatter:off http .requestMatchers().anyRequest() .and() .authorizeRequests() .antMatchers(&quot;/oauth/**&quot;).permitAll(); // @formatter:on }} 验证密码获取token 127.0.0.1:8764/oauth/token?username=admin&amp;password=admin&amp;grant_type=password&amp;scope=select&amp;client_id=client_2&amp;client_secret=123456 正常会获取到这些数据 1234567{ &quot;access_token&quot;: &quot;db3e51a7-c86a-4ca2-adce-fac4272d9e30&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;4c8175aa-7494-4d20-ad9e-391b447066c9&quot;, &quot;expires_in&quot;: 43199, &quot;scope&quot;: &quot;select&quot;} 拿到获取获取到的token再去访问资源 http://localhost:8080/order/1?access_token=3f959160-6dd3-4113-b114-f7aa156468b9","link":"/blog/2017/06/11/springcloud-9.oauth2%E5%AE%9E%E7%8E%B0/"}],"tags":[{"name":"docker","slug":"docker","link":"/blog/tags/docker/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/blog/tags/elasticsearch/"},{"name":"mongodb","slug":"mongodb","link":"/blog/tags/mongodb/"},{"name":"mysql","slug":"mysql","link":"/blog/tags/mysql/"},{"name":"redis","slug":"redis","link":"/blog/tags/redis/"},{"name":"spring","slug":"spring","link":"/blog/tags/spring/"},{"name":"源码","slug":"源码","link":"/blog/tags/%E6%BA%90%E7%A0%81/"},{"name":"springboot","slug":"springboot","link":"/blog/tags/springboot/"},{"name":"zookeeper","slug":"zookeeper","link":"/blog/tags/zookeeper/"},{"name":"JPA","slug":"JPA","link":"/blog/tags/JPA/"},{"name":"分布式事务","slug":"分布式事务","link":"/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"分布式锁","slug":"分布式锁","link":"/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"工具","slug":"工具","link":"/blog/tags/%E5%B7%A5%E5%85%B7/"},{"name":"并发","slug":"并发","link":"/blog/tags/%E5%B9%B6%E5%8F%91/"},{"name":"消息队列","slug":"消息队列","link":"/blog/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"算法","slug":"算法","link":"/blog/tags/%E7%AE%97%E6%B3%95/"},{"name":"JVM","slug":"JVM","link":"/blog/tags/JVM/"},{"name":"解决方案","slug":"解决方案","link":"/blog/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"name":"设计模式","slug":"设计模式","link":"/blog/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"springcloud","slug":"springcloud","link":"/blog/tags/springcloud/"}],"categories":[{"name":"后台","slug":"后台","link":"/blog/categories/%E5%90%8E%E5%8F%B0/"}]}